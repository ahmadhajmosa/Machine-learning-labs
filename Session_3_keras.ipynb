{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahmadhajmosa/Machine-learning-labs/blob/master/Session_3_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rmSUExzC-ZBV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1MeHqHUMkiD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgWZldyi-Zef"
   },
   "source": [
    "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
    "## Session 3: Keras\n",
    "\n",
    "### * Intro into Keras\n",
    "\n",
    "### * CNN using Keras\n",
    "\n",
    "### * LSTM using Keras\n",
    "\n",
    "### * Variational Auto encoder using Keras\n",
    "\n",
    "### * Seq2Seq Model with keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uf8EYKGvNX-M"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "q8ccyZJfMlFr",
    "outputId": "3b504a7c-4b50-4a0b-f10f-b796c762b756"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Stefano Probst\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Stefano Probst\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_3 (Dense)       (None, 30)                6030      \n",
      "_________________________________________________________________\n",
      "hidden_layer_4 (Dense)       (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 32)                3232      \n",
      "=================================================================\n",
      "Total params: 36,406\n",
      "Trainable params: 36,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(16,),name=\"input_layer\"))\n",
    "model.add(Dense(100,activation=\"relu\",name=\"hidden_layer_1\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200,activation=\"sigmoid\",name=\"hidden_layer_2\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(30,name=\"hidden_layer_3\"))\n",
    "model.add(Dense(100,name=\"hidden_layer_4\"))\n",
    "\n",
    "# now the model will take as input arrays of shape (*, 16)\n",
    "# and output arrays of shape (*, 32)\n",
    "\n",
    "# after the first layer, you don't need to specify\n",
    "# the size of the input anymore:\n",
    "model.add(Dense(32,name=\"output_layer\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "KX9SVeTCPvuD",
    "outputId": "eb95aee2-3d0a-47a8-e152-c04cc2d041e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 3, 32, 64)         18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 32, 20)         11540     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1920)              0         \n",
      "=================================================================\n",
      "Total params: 30,036\n",
      "Trainable params: 30,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3),\n",
    "                 input_shape=(3, 32, 32), padding='same',))\n",
    "model.add(Conv2D(20, (3, 3),padding='same'))\n",
    "\n",
    "\n",
    "# now: model.output_shape == (None, 64, 32, 32)\n",
    "# now: model.input_shape == (None, 3, 32, 32)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1330
    },
    "colab_type": "code",
    "id": "ANQ6jNhgSgXc",
    "outputId": "7c4297a7-34c3-413e-abb9-5d630942fd10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 20s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From C:\\Users\\Stefano Probst\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 43s 868us/step - loss: 1.8195 - acc: 0.3313 - val_loss: 1.5716 - val_acc: 0.4336\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 42s 831us/step - loss: 1.5219 - acc: 0.4456 - val_loss: 1.3997 - val_acc: 0.4894\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 1.3898 - acc: 0.4979 - val_loss: 1.2727 - val_acc: 0.5503\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 1.2939 - acc: 0.5345 - val_loss: 1.2042 - val_acc: 0.5760\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 1.2201 - acc: 0.5673 - val_loss: 1.1928 - val_acc: 0.5816\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 1.1597 - acc: 0.5890 - val_loss: 1.0948 - val_acc: 0.6230\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 1.1017 - acc: 0.6104 - val_loss: 1.0352 - val_acc: 0.6416\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 1.0522 - acc: 0.6306 - val_loss: 0.9796 - val_acc: 0.6614\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 1.0108 - acc: 0.6456 - val_loss: 1.0404 - val_acc: 0.6431\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 19s 382us/step - loss: 0.9666 - acc: 0.6636 - val_loss: 0.9131 - val_acc: 0.6861\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 0.9356 - acc: 0.6720 - val_loss: 0.8891 - val_acc: 0.6914\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 0.9052 - acc: 0.6853 - val_loss: 0.8473 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.8767 - acc: 0.6927 - val_loss: 0.8394 - val_acc: 0.7106\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.8578 - acc: 0.7021 - val_loss: 0.8443 - val_acc: 0.7123\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.8310 - acc: 0.7110 - val_loss: 0.7997 - val_acc: 0.7249\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.8166 - acc: 0.7159 - val_loss: 0.8088 - val_acc: 0.7222\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 0.7954 - acc: 0.7242 - val_loss: 0.7757 - val_acc: 0.7317\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.7878 - acc: 0.7273 - val_loss: 0.7605 - val_acc: 0.7389\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.7765 - acc: 0.7327 - val_loss: 0.7560 - val_acc: 0.7433\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7646 - acc: 0.7354 - val_loss: 0.7476 - val_acc: 0.7437\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 0.7549 - acc: 0.7414 - val_loss: 0.7244 - val_acc: 0.7537\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 0.7430 - acc: 0.7447 - val_loss: 0.7258 - val_acc: 0.7564\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.7382 - acc: 0.7471 - val_loss: 0.7230 - val_acc: 0.7591\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.7289 - acc: 0.7514 - val_loss: 0.7760 - val_acc: 0.7430\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.7314 - acc: 0.7515 - val_loss: 0.7059 - val_acc: 0.7582\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 0.7137 - acc: 0.7565 - val_loss: 0.7147 - val_acc: 0.7586\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 0.7153 - acc: 0.7572 - val_loss: 0.7093 - val_acc: 0.7633\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.7128 - acc: 0.7576 - val_loss: 0.7406 - val_acc: 0.7552\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7019 - acc: 0.7603 - val_loss: 0.7478 - val_acc: 0.7493\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 0.7033 - acc: 0.7612 - val_loss: 0.7037 - val_acc: 0.7576\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.6975 - acc: 0.7628 - val_loss: 0.6917 - val_acc: 0.7661\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 0.6934 - acc: 0.7633 - val_loss: 0.6926 - val_acc: 0.7725\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 16s 320us/step - loss: 0.6905 - acc: 0.7650 - val_loss: 0.6984 - val_acc: 0.7664\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 0.6871 - acc: 0.7674 - val_loss: 0.6930 - val_acc: 0.7727\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 0.6823 - acc: 0.7689 - val_loss: 0.6947 - val_acc: 0.7705\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 0.6822 - acc: 0.7692 - val_loss: 0.6795 - val_acc: 0.7741\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.6737 - acc: 0.7728 - val_loss: 0.6556 - val_acc: 0.7800\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 0.6737 - acc: 0.7729 - val_loss: 0.6929 - val_acc: 0.7700\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6702 - acc: 0.7752 - val_loss: 0.7025 - val_acc: 0.7653\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.6691 - acc: 0.7747 - val_loss: 0.6972 - val_acc: 0.7734\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.6660 - acc: 0.7759 - val_loss: 0.6459 - val_acc: 0.7829\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.6671 - acc: 0.7761 - val_loss: 0.6794 - val_acc: 0.7746\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 0.6648 - acc: 0.7764 - val_loss: 0.6725 - val_acc: 0.7823\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 0.6624 - acc: 0.7769 - val_loss: 0.6750 - val_acc: 0.7786\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 0.6508 - acc: 0.7811 - val_loss: 0.6713 - val_acc: 0.7763\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 0.6584 - acc: 0.7802 - val_loss: 0.6781 - val_acc: 0.7740\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.6522 - acc: 0.7813 - val_loss: 0.6620 - val_acc: 0.7767\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 0.6471 - acc: 0.7840 - val_loss: 0.6860 - val_acc: 0.7775\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 0.6499 - acc: 0.7833 - val_loss: 0.6860 - val_acc: 0.7790\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 0.6503 - acc: 0.7825 - val_loss: 0.6864 - val_acc: 0.7820\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6489 - acc: 0.7845 - val_loss: 0.6714 - val_acc: 0.7867\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 0.6437 - acc: 0.7843 - val_loss: 0.6716 - val_acc: 0.7816\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 0.6517 - acc: 0.7829 - val_loss: 0.6485 - val_acc: 0.7890\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6358 - acc: 0.7873 - val_loss: 0.6786 - val_acc: 0.7793\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.6357 - acc: 0.7877 - val_loss: 0.6520 - val_acc: 0.7837\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.6362 - acc: 0.7886 - val_loss: 0.7775 - val_acc: 0.7698\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 0.6360 - acc: 0.7866 - val_loss: 0.6596 - val_acc: 0.7877\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 0.6350 - acc: 0.7887 - val_loss: 0.6715 - val_acc: 0.7775\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.6345 - acc: 0.7891 - val_loss: 0.6858 - val_acc: 0.7832\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6305 - acc: 0.7904 - val_loss: 0.6518 - val_acc: 0.7828\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6330 - acc: 0.7890 - val_loss: 0.6880 - val_acc: 0.7805\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6256 - acc: 0.7907 - val_loss: 0.7025 - val_acc: 0.7728\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6317 - acc: 0.7895 - val_loss: 0.6692 - val_acc: 0.7793\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6302 - acc: 0.7906 - val_loss: 0.7770 - val_acc: 0.7662\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6257 - acc: 0.7925 - val_loss: 0.6733 - val_acc: 0.7898\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6254 - acc: 0.7917 - val_loss: 0.6704 - val_acc: 0.7824\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6239 - acc: 0.7937 - val_loss: 0.7197 - val_acc: 0.7768\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6268 - acc: 0.7914 - val_loss: 0.6422 - val_acc: 0.7911\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.6210 - acc: 0.7934 - val_loss: 0.7159 - val_acc: 0.7813\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6204 - acc: 0.7940 - val_loss: 0.7320 - val_acc: 0.7705\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.6202 - acc: 0.7957 - val_loss: 0.7013 - val_acc: 0.7696\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.6262 - acc: 0.7925 - val_loss: 0.6873 - val_acc: 0.7778\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6197 - acc: 0.7953 - val_loss: 0.7041 - val_acc: 0.7766\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6181 - acc: 0.7947 - val_loss: 0.6776 - val_acc: 0.7717\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6206 - acc: 0.7933 - val_loss: 0.6340 - val_acc: 0.7929\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6261 - acc: 0.7939 - val_loss: 0.6700 - val_acc: 0.7820\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6196 - acc: 0.7946 - val_loss: 0.7086 - val_acc: 0.7806\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.6170 - acc: 0.7943 - val_loss: 0.6517 - val_acc: 0.7873\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6167 - acc: 0.7941 - val_loss: 0.6588 - val_acc: 0.7822\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6178 - acc: 0.7943 - val_loss: 0.6718 - val_acc: 0.7834\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6158 - acc: 0.7958 - val_loss: 0.6936 - val_acc: 0.7777\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 0.6147 - acc: 0.7952 - val_loss: 0.6417 - val_acc: 0.7902\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6103 - acc: 0.7982 - val_loss: 0.6817 - val_acc: 0.7735\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6178 - acc: 0.7965 - val_loss: 0.6420 - val_acc: 0.7935\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6145 - acc: 0.7965 - val_loss: 0.6383 - val_acc: 0.7890\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.6104 - acc: 0.7959 - val_loss: 0.6385 - val_acc: 0.7902\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 0.6132 - acc: 0.7959 - val_loss: 0.6553 - val_acc: 0.7864\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 0.6167 - acc: 0.7954 - val_loss: 0.6874 - val_acc: 0.7775\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6148 - acc: 0.7987 - val_loss: 0.7204 - val_acc: 0.7676\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 0.6153 - acc: 0.7966 - val_loss: 0.6499 - val_acc: 0.7862\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6148 - acc: 0.7974 - val_loss: 0.6532 - val_acc: 0.7925\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 0.6136 - acc: 0.7975 - val_loss: 0.7384 - val_acc: 0.7765\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 0.6131 - acc: 0.7984 - val_loss: 0.7476 - val_acc: 0.7539\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 0.6143 - acc: 0.7980 - val_loss: 0.6684 - val_acc: 0.7843\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 0.6142 - acc: 0.7978 - val_loss: 0.6793 - val_acc: 0.7757\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.6123 - acc: 0.7974 - val_loss: 0.6862 - val_acc: 0.7810\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.6159 - acc: 0.7970 - val_loss: 0.8221 - val_acc: 0.7473\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 0.6181 - acc: 0.7958 - val_loss: 0.6839 - val_acc: 0.7789\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 0.6136 - acc: 0.7964 - val_loss: 0.6761 - val_acc: 0.7784\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 0.6108 - acc: 0.7972 - val_loss: 0.7712 - val_acc: 0.7730\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)# labels =[1,2,1,3] --> [[1,0,0],[0,1,0],[0,1,0],[0,0,1]]\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# Model creation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "\n",
    "# binary_corrsentropy for binary classificaiton 2 classes\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# scaling from 0-255 to 0-1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "colab_type": "code",
    "id": "B99kVR80R01G",
    "outputId": "6d8caa13-24ac-4a0a-92b5-128392b42b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           50240       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 64)           704         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           4160        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           4160        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128)          0           dense_10[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           8256        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           4160        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output1 (Dense)                 (None, 10)           650         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output2 (Dense)                 (None, 20)           1300        dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 73,630\n",
      "Trainable params: 73,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "\n",
    "# This returns a tensor\n",
    "inputs_1 = Input(shape=(10,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x_1 = Dense(64, activation='relu')(inputs_1)\n",
    "x_1 = Dense(64, activation='relu')(x_1)\n",
    "\n",
    "\n",
    "merged = Concatenate()([x,x_1])  # x=[1,2,3]  x_1=[4,3,1] Concat->[1,2,4,4,3,1]\n",
    "\n",
    "y = Dense(64, activation='relu')(merged)\n",
    "y = Dense(64, activation='relu')(y)\n",
    "\n",
    "y_plus_1 =Dense(10, activation='softmax',name='output1')(y)\n",
    "y_plus_2 =Dense(20, activation='relu', name='output2')(y)\n",
    "\n",
    "losses=dict()\n",
    "losses['output1'] ='categorical_crossentropy'\n",
    "losses['output2'] ='mse'\n",
    "\n",
    "\n",
    "metrics=dict()\n",
    "metrics['output1'] ='acc'\n",
    "metrics['output2'] ='mse'\n",
    "\n",
    "model = Model([inputs,inputs_1],[y_plus_1,y_plus_2])\n",
    "\n",
    "model.compile(optimizer='adam',loss=losses, metrics=metrics)\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "model.summary()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input1= np.random.rand(1,784)\n",
    "input2= np.random.rand(1,10)\n",
    "\n",
    "\n",
    "output1,output2 = model.predict([input1,input2])\n",
    "\n",
    "display(output1.shape)\n",
    "display(output2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "2l8U7xPUSer1",
    "outputId": "818c86b4-00a5-436e-a031-c2122d5bbe46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 8, 32)             6272      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 23,242\n",
      "Trainable params: 23,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ciUtGM-W_ehP"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": " Session 3 kras.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
