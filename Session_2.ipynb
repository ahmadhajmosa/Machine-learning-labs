{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadhajmosa/Machine-learning-labs/blob/ebrandner/Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSUExzC-ZBV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0kgiLtA6dK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWZldyi-Zef",
        "colab_type": "text"
      },
      "source": [
        "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
        "## Session 1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75NLOuwKXSs",
        "colab_type": "text"
      },
      "source": [
        "#Session 2: 05.06 - 13:00 - 14:30 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUtGM-W_ehP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Intro:\n",
        "\n",
        "Tensorflow is a powerful framework for implementing and deploying large-scale deep learning models. Recently, it has been widely used in both reasearch and production. TF objective is to combine scale and flexibility.\n",
        "\n",
        "In the past session, we will learning the following:\n",
        "\n",
        "1. TF programming stack\n",
        "2. TF programming concepts including computatoin graphs, operations and sessions. \n",
        "3. Implementation of linear regression\n",
        "4. Implementation of feed-forward neural networks\n",
        "\n",
        "## TF stack:\n",
        "\n",
        "TensorFlow is a framework composed of two core building blocks — a library for defining computational graphs and a runtime for executing such graphs on a variety of different hardware\n",
        "\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/layers.png)\n",
        "\n",
        "\n",
        "Before goining into details about the stack, let us talk about computational graphs.\n",
        "\n",
        "### Computational Graphs\n",
        "\n",
        "A directed graph is a data structure consisting of nodes (vertices) and edges. It’s a set of vertices connected pairwise by directed edges.\n",
        "\n",
        "Graphs come in many shapes and sizes and are used to solve many real-life problems, such as representing networks including telephone networks, circuit networks, road networks, and even social networks. \n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*V6aYjD3AxDbEKYahkGqVQw.png)\n",
        "\n",
        "TensorFlow uses directed graphs internally to represent computations, and they call this data flow graphs (or computational graphs).\n",
        "\n",
        "The nodes in TF data flow graph mostly represents operations, variables and placeholders.\n",
        "\n",
        "Take for example the following operation:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "\n",
        "To create a computational graph out of this program, we create nodes for each of the operations in our program, along with the input variables a and b. In fact, a and b could be constants if they don’t change. If one node is used as the input to another operation we draw a directed arrow that goes from one node to another.\n",
        "\n",
        "The computational graph for this program might look like this:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*vPb9E0Yd1QUAD0oFmAgaOw.png)\n",
        "\n",
        "Operations create or manipulate data according to specific rules. In TensorFlow those rules are called Ops, short for operations. Variables on the other hand represent shared, persistent state that can be manipulated by running Ops on those variables.\n",
        "\n",
        "The questions now what are the advantages of representing operations as directed graphs: The main advantage of using directed graphs is the ability to do **parallelism** and what is called **dependency driving scheduling**. \n",
        "For example, consider again the follwoing code:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "At the most fundamental level, most computer programs are mainly composed of two things — primitive operations and an order in which these operations are executed, often sequentially, line by line. This means we would first multiply a and b and only when this expression was evaluated we would take their sum. Computational graphs on the otherhand, exclusively specify the dependencies across the operations.\n",
        "If we look at our computational graph we see that we could execute the multiplication and addition in parallel. That’s because these two operations do not depend on each other.\n",
        " So we can use the topology of the graph to drive the scheduling of operations and execute them in the most efficient manner, e.g. using multiple GPUs on a single machine or even distribute the execution across multiple machines.\n",
        " Another key advantage is portability. The graph is a language-independent representation of our code. So we can build the graph in Python, save the model (TensorFlow uses protocol buffers), and restore the model in a different language, say C++, if you want to go really fast.\n",
        " \n",
        " \n",
        "\n",
        "--------------------------------\n",
        "# References:\n",
        "\n",
        "https://medium.com/@d3lm/understand-tensorflow-by-mimicking-its-api-from-scratch-faa55787170d\n",
        "\n",
        "https://www.tensorflow.org/guide/extend/architecture\n",
        "\n",
        "https://www.tensorflow.org/guide/low_level_intro\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-GFJPVDnEwx",
        "colab_type": "text"
      },
      "source": [
        "# placeholder: tensors are feeded externaly for example inputs tensors + output tensors\n",
        "\n",
        "# variables : tensors represent the parameters of the network/graph ie. nn weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmSCbhtoJBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "\n",
        "num_inputs = 3\n",
        "num_outputs = 4\n",
        "num_samples= 10\n",
        "# Training data\n",
        "x_gr = np.random.rand(num_samples,num_inputs)\n",
        "y_gr = np.random.rand(num_samples,num_outputs)\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "\n",
        "# weights \n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs,num_outputs ]))\n",
        "\n",
        "# model\n",
        "y_p = tf.matmul(x, w_1)\n",
        "\n",
        "\n",
        "# cost\n",
        "\n",
        "cost = tf.reduce_mean(tf.pow(y-y_p,2)) # \n",
        "\n",
        "# optimisation \n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(10):\n",
        "    \n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "    y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    print('predicted ', y_p_p)\n",
        "    print('real ', y_gr)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv2aqi3Fu-AJ",
        "colab_type": "code",
        "outputId": "eabf27bc-af78-4605-b30d-27f8077196c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "sess = tf.Session() \n",
        "sess.run(init)\n",
        "    \n",
        "for i in range(10):\n",
        "    \n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "print('predicted ', y_p_p)\n",
        "print('real ', y_gr)\n",
        "\n",
        "#sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter:  0 cost:  0.5914289\n",
            "iter:  1 cost:  0.590312\n",
            "iter:  2 cost:  0.5891979\n",
            "iter:  3 cost:  0.5880863\n",
            "iter:  4 cost:  0.5869776\n",
            "iter:  5 cost:  0.58587164\n",
            "iter:  6 cost:  0.58476853\n",
            "iter:  7 cost:  0.5836683\n",
            "iter:  8 cost:  0.5825709\n",
            "iter:  9 cost:  0.5814764\n",
            "predicted  [[-0.07052338 -1.4182088  -0.20726368  0.6065073 ]\n",
            " [-0.41022846  0.7640786   1.0915788   0.5919728 ]\n",
            " [-0.07066503 -0.73823565  0.10052644  0.31935224]\n",
            " [-0.2946304  -0.3036949  -0.28762203  1.1227872 ]\n",
            " [-0.57840925  0.8397043   0.8986697   1.1970941 ]\n",
            " [-0.32035732 -0.3043637  -0.03262401  1.0779576 ]\n",
            " [-0.25558242 -0.41777548  0.2828037   0.74326414]\n",
            " [-0.6702078   0.774465    0.18325244  1.8486446 ]\n",
            " [-0.3652569   0.5447639   0.8380182   0.6200657 ]\n",
            " [-0.48676854  1.0157775   1.195501    0.7295743 ]]\n",
            "real  [[0.28427788 0.58920269 0.76702838 0.54495026]\n",
            " [0.10077242 0.44421162 0.08474814 0.63117015]\n",
            " [0.01157148 0.14526119 0.81988115 0.22006669]\n",
            " [0.09844534 0.24078169 0.60496677 0.87281952]\n",
            " [0.21494239 0.5097351  0.2950044  0.82441926]\n",
            " [0.41953509 0.88851562 0.17726813 0.39356474]\n",
            " [0.10843995 0.98875919 0.14346219 0.47484879]\n",
            " [0.40487958 0.82369397 0.90377852 0.66008465]\n",
            " [0.94767349 0.42496532 0.47597419 0.79391048]\n",
            " [0.89124593 0.46764663 0.18470877 0.82758744]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUPSS03avw5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "\n",
        "num_inputs = 3\n",
        "num_h1_n = 4\n",
        "num_h2_n = 10\n",
        "num_outputs = 4\n",
        "\n",
        "num_samples= 10\n",
        "\n",
        "# Training data\n",
        "x_gr = np.random.rand(num_samples,num_inputs)\n",
        "y_gr = np.random.rand(num_samples,num_outputs)\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "\n",
        "# weights \n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs,num_h1_n ]))\n",
        "w_2 = tf.Variable(tf.random_normal([num_h1_n,num_h2_n ]))\n",
        "w_3 = tf.Variable(tf.random_normal([num_h2_n,num_outputs ]))\n",
        "\n",
        "# bias \n",
        "b_1 = tf.Variable(tf.random_normal([num_h1_n]))\n",
        "b_2 = tf.Variable(tf.random_normal([num_h2_n]))\n",
        "b_3 = tf.Variable(tf.random_normal([num_outputs]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# model\n",
        "\n",
        "h1 = tf.nn.sigmoid(tf.add(tf.matmul(x, w_1),b_1)) # model of hidden layer 1\n",
        "h2 = tf.nn.sigmoid(tf.add(tf.matmul(h1, w_2),b_2)) # model of hidden layer 2\n",
        "y_p = tf.add(tf.matmul(h2, w_3),b_3) # model of the output layer\n",
        "\n",
        "\n",
        "\n",
        "# cost\n",
        "\n",
        "cost = tf.reduce_mean(tf.pow(y-y_p,2)) # \n",
        "\n",
        "# optimisation \n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(10):\n",
        "    \n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "    y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    print('predicted ', y_p_p)\n",
        "    print('real ', y_gr)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwhCMk9VyVj-",
        "colab_type": "code",
        "outputId": "1b126578-4215-494a-9389-74ecc8a4706c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "\n",
        "mnist.train.images.shape\n",
        "\n",
        "image =mnist.train.images[0].reshape((28,28))\n",
        "#MNIST data input (img shape: 28*28)\n",
        "imshow(image)\n",
        "\n",
        "print(mnist.train.labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIrwA0ERfiAowg8ERfiBoAg/ENT/AyErW1pw/s8cAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaeRp0T10834",
        "colab_type": "code",
        "outputId": "99360c89-a4e8-4f3e-fd9a-a5355c4e2b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18292
        }
      },
      "source": [
        "# training data\n",
        "X_train = mnist.train.images\n",
        "Y_train = mnist.train.labels\n",
        "\n",
        "# training data\n",
        "X_test = mnist.test.images\n",
        "Y_test = mnist.test.labels\n",
        "\n",
        "# training data\n",
        "X_val = mnist.validation.images\n",
        "Y_val = mnist.validation.labels\n",
        "\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "\n",
        "num_inputs = 784\n",
        "num_h1_n = 100\n",
        "num_h2_n = 100\n",
        "num_outputs = 10\n",
        "\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "\n",
        "# weights \n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs,num_h1_n ]))\n",
        "w_2 = tf.Variable(tf.random_normal([num_h1_n,num_h2_n ]))\n",
        "w_3 = tf.Variable(tf.random_normal([num_h2_n,num_outputs ]))\n",
        "\n",
        "# bias \n",
        "b_1 = tf.Variable(tf.random_normal([num_h1_n]))\n",
        "b_2 = tf.Variable(tf.random_normal([num_h2_n]))\n",
        "b_3 = tf.Variable(tf.random_normal([num_outputs]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# model\n",
        "\n",
        "h1 = tf.nn.sigmoid(tf.add(tf.matmul(x, w_1),b_1)) # model of hidden layer 1\n",
        "h2 = tf.nn.sigmoid(tf.add(tf.matmul(h1, w_2),b_2)) # model of hidden layer 2\n",
        "y_p = tf.add(tf.matmul(h2, w_3),b_3) # model of the output layer\n",
        "\n",
        "\n",
        "\n",
        "# cost\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_p, labels=y)) # cross entropy cost\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(y_p, 1), tf.argmax(y, 1))\n",
        "\n",
        "## 3 images, y_p=[[0.1,0.0,0,0.9],[0.9,0.1,0,0.],[0,0.9,0,0.1]] \n",
        "\n",
        "# tf.argmax(y_p, 1) [3,0,1] \n",
        "\n",
        "# 3 images, y=[[0,0.0,0,1],[0,1,0,0],[0,1,0,0]] \n",
        "\n",
        "# tf.argmax(y, 1) [3,1,1]\n",
        "\n",
        "# tf.equal [True,False,True]--[1,0,1]--- 2/3 \n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "#\n",
        "\n",
        "# optimisation \n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(1000):\n",
        "        \n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        \n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
        "    \n",
        "\n",
        "        train_cost, train_acc  = sess.run([cost,accuracy], feed_dict={x: batch_x,y: batch_y})\n",
        "    \n",
        "        \n",
        "        test_batch_x, test_batch_y = mnist.test.next_batch(batch_size)\n",
        "\n",
        "        test_cost, test_acc  = sess.run([cost,accuracy], feed_dict={x: test_batch_x,y: test_batch_y})\n",
        "        print('iter: ',i, 'train_cost: ', train_cost, 'train_acc: ', train_acc,'test_cost: ', test_cost, 'test_acc: ', test_acc )\n",
        "\n",
        "    \n",
        "    #y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    print('predicted ', y_p_p)\n",
        "    print('real ', y_gr)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-24-027f09fe6c86>:55: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "iter:  0 train_cost:  6.5679855 train_acc:  0.109375 test_cost:  6.6416807 test_acc:  0.0390625\n",
            "iter:  1 train_cost:  6.96553 train_acc:  0.078125 test_cost:  6.658767 test_acc:  0.0703125\n",
            "iter:  2 train_cost:  6.416924 train_acc:  0.078125 test_cost:  6.100772 test_acc:  0.1640625\n",
            "iter:  3 train_cost:  6.3762937 train_acc:  0.078125 test_cost:  6.2070136 test_acc:  0.1015625\n",
            "iter:  4 train_cost:  6.146327 train_acc:  0.1015625 test_cost:  6.6942554 test_acc:  0.09375\n",
            "iter:  5 train_cost:  6.0676374 train_acc:  0.03125 test_cost:  5.914857 test_acc:  0.0859375\n",
            "iter:  6 train_cost:  5.8995156 train_acc:  0.09375 test_cost:  5.5934653 test_acc:  0.0859375\n",
            "iter:  7 train_cost:  5.54004 train_acc:  0.109375 test_cost:  6.219889 test_acc:  0.0625\n",
            "iter:  8 train_cost:  5.33588 train_acc:  0.1328125 test_cost:  5.133644 test_acc:  0.1171875\n",
            "iter:  9 train_cost:  5.350211 train_acc:  0.1171875 test_cost:  5.377776 test_acc:  0.078125\n",
            "iter:  10 train_cost:  5.5952015 train_acc:  0.140625 test_cost:  5.2220755 test_acc:  0.1015625\n",
            "iter:  11 train_cost:  5.166362 train_acc:  0.125 test_cost:  5.7190094 test_acc:  0.078125\n",
            "iter:  12 train_cost:  5.0113354 train_acc:  0.1171875 test_cost:  4.7698197 test_acc:  0.125\n",
            "iter:  13 train_cost:  4.981077 train_acc:  0.125 test_cost:  4.981987 test_acc:  0.15625\n",
            "iter:  14 train_cost:  5.218525 train_acc:  0.1171875 test_cost:  4.7968717 test_acc:  0.1328125\n",
            "iter:  15 train_cost:  5.091277 train_acc:  0.1328125 test_cost:  4.882866 test_acc:  0.0859375\n",
            "iter:  16 train_cost:  4.665082 train_acc:  0.1171875 test_cost:  4.7820663 test_acc:  0.0703125\n",
            "iter:  17 train_cost:  4.8668633 train_acc:  0.1015625 test_cost:  4.527156 test_acc:  0.15625\n",
            "iter:  18 train_cost:  4.5283856 train_acc:  0.1484375 test_cost:  4.819607 test_acc:  0.1640625\n",
            "iter:  19 train_cost:  4.4491186 train_acc:  0.1171875 test_cost:  4.64916 test_acc:  0.1015625\n",
            "iter:  20 train_cost:  4.783654 train_acc:  0.0625 test_cost:  4.703638 test_acc:  0.1015625\n",
            "iter:  21 train_cost:  4.623052 train_acc:  0.125 test_cost:  4.251469 test_acc:  0.1640625\n",
            "iter:  22 train_cost:  4.449676 train_acc:  0.1171875 test_cost:  4.454582 test_acc:  0.0859375\n",
            "iter:  23 train_cost:  4.6281166 train_acc:  0.109375 test_cost:  4.131697 test_acc:  0.125\n",
            "iter:  24 train_cost:  3.61975 train_acc:  0.15625 test_cost:  4.1150966 test_acc:  0.140625\n",
            "iter:  25 train_cost:  4.0952644 train_acc:  0.140625 test_cost:  3.7771525 test_acc:  0.1484375\n",
            "iter:  26 train_cost:  3.879601 train_acc:  0.1484375 test_cost:  3.6761463 test_acc:  0.1640625\n",
            "iter:  27 train_cost:  4.3079453 train_acc:  0.09375 test_cost:  3.894228 test_acc:  0.1484375\n",
            "iter:  28 train_cost:  3.6636255 train_acc:  0.1484375 test_cost:  3.5301929 test_acc:  0.1640625\n",
            "iter:  29 train_cost:  4.018019 train_acc:  0.1015625 test_cost:  3.8847446 test_acc:  0.125\n",
            "iter:  30 train_cost:  3.4575884 train_acc:  0.171875 test_cost:  3.6489396 test_acc:  0.140625\n",
            "iter:  31 train_cost:  3.5959098 train_acc:  0.15625 test_cost:  3.6822648 test_acc:  0.1875\n",
            "iter:  32 train_cost:  3.451345 train_acc:  0.125 test_cost:  3.861592 test_acc:  0.15625\n",
            "iter:  33 train_cost:  3.6371999 train_acc:  0.21875 test_cost:  3.8062415 test_acc:  0.15625\n",
            "iter:  34 train_cost:  3.469547 train_acc:  0.1875 test_cost:  3.4142249 test_acc:  0.15625\n",
            "iter:  35 train_cost:  3.319477 train_acc:  0.1953125 test_cost:  3.4786568 test_acc:  0.1875\n",
            "iter:  36 train_cost:  3.2946796 train_acc:  0.1484375 test_cost:  3.2811077 test_acc:  0.1953125\n",
            "iter:  37 train_cost:  3.8695211 train_acc:  0.125 test_cost:  3.4169676 test_acc:  0.2109375\n",
            "iter:  38 train_cost:  4.013409 train_acc:  0.171875 test_cost:  3.3628473 test_acc:  0.2109375\n",
            "iter:  39 train_cost:  3.768149 train_acc:  0.1328125 test_cost:  3.4691367 test_acc:  0.203125\n",
            "iter:  40 train_cost:  3.1334279 train_acc:  0.1875 test_cost:  3.4993875 test_acc:  0.1328125\n",
            "iter:  41 train_cost:  3.4007497 train_acc:  0.1796875 test_cost:  3.615543 test_acc:  0.125\n",
            "iter:  42 train_cost:  3.6662571 train_acc:  0.1953125 test_cost:  3.3323202 test_acc:  0.1875\n",
            "iter:  43 train_cost:  3.7018268 train_acc:  0.1015625 test_cost:  2.9422936 test_acc:  0.2421875\n",
            "iter:  44 train_cost:  3.4059107 train_acc:  0.1875 test_cost:  3.2266073 test_acc:  0.1953125\n",
            "iter:  45 train_cost:  3.1065338 train_acc:  0.21875 test_cost:  3.2217119 test_acc:  0.2578125\n",
            "iter:  46 train_cost:  3.3957715 train_acc:  0.1875 test_cost:  3.292637 test_acc:  0.2734375\n",
            "iter:  47 train_cost:  2.9855778 train_acc:  0.1796875 test_cost:  3.0958493 test_acc:  0.15625\n",
            "iter:  48 train_cost:  3.039833 train_acc:  0.25 test_cost:  3.2688546 test_acc:  0.234375\n",
            "iter:  49 train_cost:  3.2355406 train_acc:  0.21875 test_cost:  2.9671469 test_acc:  0.21875\n",
            "iter:  50 train_cost:  3.1143093 train_acc:  0.1953125 test_cost:  3.1554685 test_acc:  0.171875\n",
            "iter:  51 train_cost:  3.286821 train_acc:  0.2109375 test_cost:  3.1294892 test_acc:  0.265625\n",
            "iter:  52 train_cost:  2.860374 train_acc:  0.25 test_cost:  2.9072237 test_acc:  0.234375\n",
            "iter:  53 train_cost:  3.2591982 train_acc:  0.28125 test_cost:  2.4371367 test_acc:  0.328125\n",
            "iter:  54 train_cost:  2.8363554 train_acc:  0.234375 test_cost:  2.7222252 test_acc:  0.328125\n",
            "iter:  55 train_cost:  3.1552525 train_acc:  0.2890625 test_cost:  2.8285036 test_acc:  0.2890625\n",
            "iter:  56 train_cost:  2.7043285 train_acc:  0.3046875 test_cost:  3.0171041 test_acc:  0.28125\n",
            "iter:  57 train_cost:  2.8614492 train_acc:  0.2734375 test_cost:  2.6298046 test_acc:  0.2890625\n",
            "iter:  58 train_cost:  3.0621936 train_acc:  0.25 test_cost:  2.5760486 test_acc:  0.328125\n",
            "iter:  59 train_cost:  2.924928 train_acc:  0.2578125 test_cost:  2.9233658 test_acc:  0.2265625\n",
            "iter:  60 train_cost:  2.7863078 train_acc:  0.296875 test_cost:  2.5858145 test_acc:  0.296875\n",
            "iter:  61 train_cost:  3.0005708 train_acc:  0.2890625 test_cost:  2.467584 test_acc:  0.2734375\n",
            "iter:  62 train_cost:  2.3776138 train_acc:  0.3203125 test_cost:  2.618223 test_acc:  0.3203125\n",
            "iter:  63 train_cost:  2.8840997 train_acc:  0.265625 test_cost:  2.8376317 test_acc:  0.1953125\n",
            "iter:  64 train_cost:  2.6032128 train_acc:  0.234375 test_cost:  2.8562737 test_acc:  0.3203125\n",
            "iter:  65 train_cost:  2.6288214 train_acc:  0.3125 test_cost:  2.6647916 test_acc:  0.2578125\n",
            "iter:  66 train_cost:  2.8457146 train_acc:  0.265625 test_cost:  2.9599795 test_acc:  0.296875\n",
            "iter:  67 train_cost:  2.0801573 train_acc:  0.375 test_cost:  2.6447608 test_acc:  0.2578125\n",
            "iter:  68 train_cost:  2.6281736 train_acc:  0.3046875 test_cost:  2.6675508 test_acc:  0.3125\n",
            "iter:  69 train_cost:  2.3853068 train_acc:  0.34375 test_cost:  2.9036627 test_acc:  0.3046875\n",
            "iter:  70 train_cost:  2.428654 train_acc:  0.3515625 test_cost:  2.6158967 test_acc:  0.328125\n",
            "iter:  71 train_cost:  2.5223174 train_acc:  0.3671875 test_cost:  2.5093575 test_acc:  0.359375\n",
            "iter:  72 train_cost:  2.3272023 train_acc:  0.3671875 test_cost:  2.4826455 test_acc:  0.3203125\n",
            "iter:  73 train_cost:  2.322598 train_acc:  0.34375 test_cost:  2.3459597 test_acc:  0.390625\n",
            "iter:  74 train_cost:  2.069013 train_acc:  0.3984375 test_cost:  2.652611 test_acc:  0.2734375\n",
            "iter:  75 train_cost:  2.1416419 train_acc:  0.4296875 test_cost:  2.4705667 test_acc:  0.3203125\n",
            "iter:  76 train_cost:  2.6581125 train_acc:  0.2890625 test_cost:  2.4044619 test_acc:  0.3515625\n",
            "iter:  77 train_cost:  2.1599116 train_acc:  0.3671875 test_cost:  2.2931318 test_acc:  0.3359375\n",
            "iter:  78 train_cost:  2.3688118 train_acc:  0.4375 test_cost:  2.0935984 test_acc:  0.4375\n",
            "iter:  79 train_cost:  2.2798119 train_acc:  0.3359375 test_cost:  2.3444793 test_acc:  0.3359375\n",
            "iter:  80 train_cost:  2.4356372 train_acc:  0.34375 test_cost:  2.366683 test_acc:  0.34375\n",
            "iter:  81 train_cost:  2.588029 train_acc:  0.3359375 test_cost:  2.48166 test_acc:  0.3046875\n",
            "iter:  82 train_cost:  2.1752546 train_acc:  0.390625 test_cost:  2.189179 test_acc:  0.4140625\n",
            "iter:  83 train_cost:  1.9740542 train_acc:  0.4140625 test_cost:  2.2438197 test_acc:  0.34375\n",
            "iter:  84 train_cost:  2.2698622 train_acc:  0.3359375 test_cost:  1.9611306 test_acc:  0.3828125\n",
            "iter:  85 train_cost:  2.6335258 train_acc:  0.3515625 test_cost:  2.1320596 test_acc:  0.421875\n",
            "iter:  86 train_cost:  2.212285 train_acc:  0.390625 test_cost:  2.4851017 test_acc:  0.3203125\n",
            "iter:  87 train_cost:  2.3747067 train_acc:  0.359375 test_cost:  2.1780944 test_acc:  0.390625\n",
            "iter:  88 train_cost:  1.9835136 train_acc:  0.375 test_cost:  2.1308196 test_acc:  0.3671875\n",
            "iter:  89 train_cost:  2.114131 train_acc:  0.4375 test_cost:  2.2111185 test_acc:  0.4453125\n",
            "iter:  90 train_cost:  2.4386032 train_acc:  0.3515625 test_cost:  2.0108218 test_acc:  0.40625\n",
            "iter:  91 train_cost:  1.9202077 train_acc:  0.4375 test_cost:  2.0296855 test_acc:  0.3984375\n",
            "iter:  92 train_cost:  2.2716093 train_acc:  0.3828125 test_cost:  1.8462659 test_acc:  0.46875\n",
            "iter:  93 train_cost:  2.0869696 train_acc:  0.359375 test_cost:  1.9891964 test_acc:  0.375\n",
            "iter:  94 train_cost:  2.3071775 train_acc:  0.3203125 test_cost:  2.374187 test_acc:  0.359375\n",
            "iter:  95 train_cost:  1.9474225 train_acc:  0.4140625 test_cost:  2.0471532 test_acc:  0.4140625\n",
            "iter:  96 train_cost:  2.043305 train_acc:  0.40625 test_cost:  2.1282573 test_acc:  0.4296875\n",
            "iter:  97 train_cost:  1.8603235 train_acc:  0.4921875 test_cost:  1.8941307 test_acc:  0.4296875\n",
            "iter:  98 train_cost:  1.9020855 train_acc:  0.4140625 test_cost:  2.2876356 test_acc:  0.34375\n",
            "iter:  99 train_cost:  2.0852008 train_acc:  0.4375 test_cost:  1.9598621 test_acc:  0.4609375\n",
            "iter:  100 train_cost:  2.0680983 train_acc:  0.3984375 test_cost:  1.9969529 test_acc:  0.4375\n",
            "iter:  101 train_cost:  1.9841461 train_acc:  0.4140625 test_cost:  1.7334104 test_acc:  0.4609375\n",
            "iter:  102 train_cost:  1.9899404 train_acc:  0.3515625 test_cost:  2.0132234 test_acc:  0.4140625\n",
            "iter:  103 train_cost:  1.9438262 train_acc:  0.4609375 test_cost:  1.9994892 test_acc:  0.4375\n",
            "iter:  104 train_cost:  1.9384768 train_acc:  0.4453125 test_cost:  2.1463943 test_acc:  0.390625\n",
            "iter:  105 train_cost:  1.9012864 train_acc:  0.4921875 test_cost:  2.216274 test_acc:  0.4140625\n",
            "iter:  106 train_cost:  1.5432122 train_acc:  0.5234375 test_cost:  1.8279707 test_acc:  0.4453125\n",
            "iter:  107 train_cost:  2.011891 train_acc:  0.4375 test_cost:  2.0872912 test_acc:  0.4453125\n",
            "iter:  108 train_cost:  2.142511 train_acc:  0.390625 test_cost:  1.7753029 test_acc:  0.453125\n",
            "iter:  109 train_cost:  1.8578197 train_acc:  0.46875 test_cost:  1.9953188 test_acc:  0.4375\n",
            "iter:  110 train_cost:  1.9149855 train_acc:  0.4140625 test_cost:  1.8689797 test_acc:  0.4921875\n",
            "iter:  111 train_cost:  1.8819045 train_acc:  0.4453125 test_cost:  1.669631 test_acc:  0.5234375\n",
            "iter:  112 train_cost:  1.9998953 train_acc:  0.4765625 test_cost:  1.7717946 test_acc:  0.46875\n",
            "iter:  113 train_cost:  1.6591308 train_acc:  0.4453125 test_cost:  1.4542499 test_acc:  0.5546875\n",
            "iter:  114 train_cost:  1.9748632 train_acc:  0.4453125 test_cost:  2.246317 test_acc:  0.390625\n",
            "iter:  115 train_cost:  1.7240489 train_acc:  0.5625 test_cost:  1.6630386 test_acc:  0.515625\n",
            "iter:  116 train_cost:  1.9457062 train_acc:  0.4375 test_cost:  1.7544264 test_acc:  0.4921875\n",
            "iter:  117 train_cost:  1.7007406 train_acc:  0.5390625 test_cost:  1.9631088 test_acc:  0.484375\n",
            "iter:  118 train_cost:  1.6410837 train_acc:  0.5078125 test_cost:  1.6684848 test_acc:  0.5234375\n",
            "iter:  119 train_cost:  1.4575117 train_acc:  0.53125 test_cost:  1.876176 test_acc:  0.453125\n",
            "iter:  120 train_cost:  2.0323908 train_acc:  0.40625 test_cost:  1.6427374 test_acc:  0.5234375\n",
            "iter:  121 train_cost:  1.7036068 train_acc:  0.515625 test_cost:  1.5699745 test_acc:  0.53125\n",
            "iter:  122 train_cost:  1.6816497 train_acc:  0.4765625 test_cost:  1.8321636 test_acc:  0.4765625\n",
            "iter:  123 train_cost:  1.6478033 train_acc:  0.5078125 test_cost:  1.5105896 test_acc:  0.546875\n",
            "iter:  124 train_cost:  1.4549708 train_acc:  0.5859375 test_cost:  1.4257817 test_acc:  0.625\n",
            "iter:  125 train_cost:  1.8388398 train_acc:  0.4296875 test_cost:  1.5731539 test_acc:  0.5078125\n",
            "iter:  126 train_cost:  1.5032798 train_acc:  0.546875 test_cost:  1.4547926 test_acc:  0.5859375\n",
            "iter:  127 train_cost:  1.4655062 train_acc:  0.5703125 test_cost:  1.5766995 test_acc:  0.5078125\n",
            "iter:  128 train_cost:  1.678534 train_acc:  0.5 test_cost:  1.573787 test_acc:  0.5546875\n",
            "iter:  129 train_cost:  1.7830006 train_acc:  0.5 test_cost:  1.8005772 test_acc:  0.46875\n",
            "iter:  130 train_cost:  1.651118 train_acc:  0.5234375 test_cost:  1.8330749 test_acc:  0.5078125\n",
            "iter:  131 train_cost:  1.722823 train_acc:  0.4609375 test_cost:  1.6364735 test_acc:  0.546875\n",
            "iter:  132 train_cost:  1.8465341 train_acc:  0.46875 test_cost:  1.6004616 test_acc:  0.4609375\n",
            "iter:  133 train_cost:  1.6230817 train_acc:  0.4609375 test_cost:  1.4877183 test_acc:  0.5078125\n",
            "iter:  134 train_cost:  1.7826866 train_acc:  0.453125 test_cost:  1.5550617 test_acc:  0.53125\n",
            "iter:  135 train_cost:  1.417453 train_acc:  0.5390625 test_cost:  1.425452 test_acc:  0.546875\n",
            "iter:  136 train_cost:  1.4292536 train_acc:  0.5078125 test_cost:  1.7680086 test_acc:  0.4921875\n",
            "iter:  137 train_cost:  1.4708757 train_acc:  0.546875 test_cost:  1.4459547 test_acc:  0.546875\n",
            "iter:  138 train_cost:  1.6098202 train_acc:  0.546875 test_cost:  1.7029867 test_acc:  0.4765625\n",
            "iter:  139 train_cost:  1.7255747 train_acc:  0.5 test_cost:  1.4245701 test_acc:  0.5859375\n",
            "iter:  140 train_cost:  1.4530486 train_acc:  0.5078125 test_cost:  1.6430576 test_acc:  0.484375\n",
            "iter:  141 train_cost:  1.5563636 train_acc:  0.4765625 test_cost:  1.4774566 test_acc:  0.5\n",
            "iter:  142 train_cost:  1.3776498 train_acc:  0.6328125 test_cost:  1.5796559 test_acc:  0.5\n",
            "iter:  143 train_cost:  1.2964047 train_acc:  0.609375 test_cost:  1.5999513 test_acc:  0.546875\n",
            "iter:  144 train_cost:  2.0501838 train_acc:  0.40625 test_cost:  1.4255878 test_acc:  0.5390625\n",
            "iter:  145 train_cost:  1.5172775 train_acc:  0.5625 test_cost:  1.4272611 test_acc:  0.53125\n",
            "iter:  146 train_cost:  1.2894293 train_acc:  0.5859375 test_cost:  1.2576389 test_acc:  0.5546875\n",
            "iter:  147 train_cost:  1.4459357 train_acc:  0.5390625 test_cost:  1.6899453 test_acc:  0.5\n",
            "iter:  148 train_cost:  1.5491493 train_acc:  0.53125 test_cost:  1.9418665 test_acc:  0.4921875\n",
            "iter:  149 train_cost:  1.6540575 train_acc:  0.4609375 test_cost:  1.4377382 test_acc:  0.5390625\n",
            "iter:  150 train_cost:  1.6906481 train_acc:  0.5234375 test_cost:  1.5140325 test_acc:  0.546875\n",
            "iter:  151 train_cost:  1.5850644 train_acc:  0.4921875 test_cost:  1.4941623 test_acc:  0.5546875\n",
            "iter:  152 train_cost:  1.5699776 train_acc:  0.5625 test_cost:  1.3475819 test_acc:  0.578125\n",
            "iter:  153 train_cost:  1.3431569 train_acc:  0.609375 test_cost:  1.5392146 test_acc:  0.4921875\n",
            "iter:  154 train_cost:  1.7227597 train_acc:  0.5234375 test_cost:  1.4354404 test_acc:  0.5859375\n",
            "iter:  155 train_cost:  1.6226132 train_acc:  0.5546875 test_cost:  1.3085779 test_acc:  0.5703125\n",
            "iter:  156 train_cost:  1.3656939 train_acc:  0.5703125 test_cost:  1.7446282 test_acc:  0.5078125\n",
            "iter:  157 train_cost:  1.5099685 train_acc:  0.4921875 test_cost:  1.4331348 test_acc:  0.5859375\n",
            "iter:  158 train_cost:  1.2399389 train_acc:  0.5703125 test_cost:  1.7591743 test_acc:  0.4296875\n",
            "iter:  159 train_cost:  1.6479607 train_acc:  0.4765625 test_cost:  1.6337205 test_acc:  0.46875\n",
            "iter:  160 train_cost:  1.4217341 train_acc:  0.6328125 test_cost:  1.3037531 test_acc:  0.609375\n",
            "iter:  161 train_cost:  1.575284 train_acc:  0.53125 test_cost:  1.6092687 test_acc:  0.515625\n",
            "iter:  162 train_cost:  1.732165 train_acc:  0.546875 test_cost:  1.123342 test_acc:  0.5859375\n",
            "iter:  163 train_cost:  1.6635678 train_acc:  0.4921875 test_cost:  1.3611101 test_acc:  0.59375\n",
            "iter:  164 train_cost:  1.4486927 train_acc:  0.6015625 test_cost:  1.2961247 test_acc:  0.59375\n",
            "iter:  165 train_cost:  1.257809 train_acc:  0.6015625 test_cost:  1.3149102 test_acc:  0.640625\n",
            "iter:  166 train_cost:  1.4900547 train_acc:  0.5234375 test_cost:  1.578495 test_acc:  0.546875\n",
            "iter:  167 train_cost:  1.3020626 train_acc:  0.5703125 test_cost:  1.6556381 test_acc:  0.5625\n",
            "iter:  168 train_cost:  1.4544017 train_acc:  0.5078125 test_cost:  1.3690287 test_acc:  0.6328125\n",
            "iter:  169 train_cost:  1.6043016 train_acc:  0.5390625 test_cost:  1.3445684 test_acc:  0.6015625\n",
            "iter:  170 train_cost:  1.3639429 train_acc:  0.5859375 test_cost:  1.3316656 test_acc:  0.6328125\n",
            "iter:  171 train_cost:  1.3418424 train_acc:  0.5625 test_cost:  1.1183267 test_acc:  0.7109375\n",
            "iter:  172 train_cost:  1.5527997 train_acc:  0.578125 test_cost:  1.3006241 test_acc:  0.5625\n",
            "iter:  173 train_cost:  1.3729149 train_acc:  0.5546875 test_cost:  1.4146245 test_acc:  0.5859375\n",
            "iter:  174 train_cost:  1.4160299 train_acc:  0.5390625 test_cost:  1.2324119 test_acc:  0.609375\n",
            "iter:  175 train_cost:  1.4924033 train_acc:  0.59375 test_cost:  1.5161109 test_acc:  0.5234375\n",
            "iter:  176 train_cost:  1.1663761 train_acc:  0.6171875 test_cost:  1.3131175 test_acc:  0.609375\n",
            "iter:  177 train_cost:  1.1291265 train_acc:  0.6484375 test_cost:  1.1050367 test_acc:  0.671875\n",
            "iter:  178 train_cost:  1.4597752 train_acc:  0.53125 test_cost:  1.2616644 test_acc:  0.5703125\n",
            "iter:  179 train_cost:  1.4782946 train_acc:  0.5234375 test_cost:  1.2743161 test_acc:  0.5625\n",
            "iter:  180 train_cost:  1.3550866 train_acc:  0.5703125 test_cost:  1.2117116 test_acc:  0.578125\n",
            "iter:  181 train_cost:  1.3793379 train_acc:  0.5703125 test_cost:  1.4022912 test_acc:  0.5859375\n",
            "iter:  182 train_cost:  1.3056539 train_acc:  0.6171875 test_cost:  1.1766032 test_acc:  0.6171875\n",
            "iter:  183 train_cost:  1.0758256 train_acc:  0.6484375 test_cost:  1.3741456 test_acc:  0.5703125\n",
            "iter:  184 train_cost:  1.2654189 train_acc:  0.578125 test_cost:  1.1676311 test_acc:  0.6328125\n",
            "iter:  185 train_cost:  1.3153176 train_acc:  0.59375 test_cost:  1.211488 test_acc:  0.640625\n",
            "iter:  186 train_cost:  1.2993045 train_acc:  0.578125 test_cost:  1.4559627 test_acc:  0.625\n",
            "iter:  187 train_cost:  1.3447828 train_acc:  0.578125 test_cost:  1.4694226 test_acc:  0.59375\n",
            "iter:  188 train_cost:  1.2422296 train_acc:  0.625 test_cost:  1.23903 test_acc:  0.6171875\n",
            "iter:  189 train_cost:  1.532997 train_acc:  0.5390625 test_cost:  1.3736825 test_acc:  0.5546875\n",
            "iter:  190 train_cost:  1.2117703 train_acc:  0.6015625 test_cost:  1.1297696 test_acc:  0.578125\n",
            "iter:  191 train_cost:  1.3327614 train_acc:  0.59375 test_cost:  1.4519486 test_acc:  0.546875\n",
            "iter:  192 train_cost:  1.1229563 train_acc:  0.6484375 test_cost:  1.3649932 test_acc:  0.640625\n",
            "iter:  193 train_cost:  1.5400164 train_acc:  0.53125 test_cost:  1.3164413 test_acc:  0.609375\n",
            "iter:  194 train_cost:  1.3669443 train_acc:  0.5859375 test_cost:  1.2246122 test_acc:  0.5859375\n",
            "iter:  195 train_cost:  1.2818553 train_acc:  0.625 test_cost:  1.2420654 test_acc:  0.6171875\n",
            "iter:  196 train_cost:  1.3263469 train_acc:  0.59375 test_cost:  1.1704708 test_acc:  0.625\n",
            "iter:  197 train_cost:  1.4817066 train_acc:  0.578125 test_cost:  1.1799836 test_acc:  0.609375\n",
            "iter:  198 train_cost:  1.2412791 train_acc:  0.5859375 test_cost:  1.3065356 test_acc:  0.5625\n",
            "iter:  199 train_cost:  1.2826071 train_acc:  0.6328125 test_cost:  1.4253991 test_acc:  0.53125\n",
            "iter:  200 train_cost:  1.4239857 train_acc:  0.609375 test_cost:  1.1404212 test_acc:  0.6484375\n",
            "iter:  201 train_cost:  1.4268763 train_acc:  0.5625 test_cost:  1.2640953 test_acc:  0.6171875\n",
            "iter:  202 train_cost:  1.3210167 train_acc:  0.5625 test_cost:  1.1625048 test_acc:  0.65625\n",
            "iter:  203 train_cost:  1.2767926 train_acc:  0.6328125 test_cost:  1.273518 test_acc:  0.6171875\n",
            "iter:  204 train_cost:  1.1917673 train_acc:  0.625 test_cost:  1.3008857 test_acc:  0.6171875\n",
            "iter:  205 train_cost:  1.6672429 train_acc:  0.5 test_cost:  1.3768077 test_acc:  0.5625\n",
            "iter:  206 train_cost:  1.3612859 train_acc:  0.625 test_cost:  1.1106539 test_acc:  0.6875\n",
            "iter:  207 train_cost:  1.1442351 train_acc:  0.609375 test_cost:  1.1111064 test_acc:  0.6796875\n",
            "iter:  208 train_cost:  1.378393 train_acc:  0.5859375 test_cost:  1.3093412 test_acc:  0.609375\n",
            "iter:  209 train_cost:  1.1297204 train_acc:  0.6328125 test_cost:  1.2370942 test_acc:  0.59375\n",
            "iter:  210 train_cost:  1.3202342 train_acc:  0.578125 test_cost:  1.176393 test_acc:  0.609375\n",
            "iter:  211 train_cost:  1.4318048 train_acc:  0.5859375 test_cost:  1.2451682 test_acc:  0.625\n",
            "iter:  212 train_cost:  1.2441216 train_acc:  0.6328125 test_cost:  1.1798667 test_acc:  0.625\n",
            "iter:  213 train_cost:  0.97593325 train_acc:  0.6796875 test_cost:  1.1274033 test_acc:  0.6640625\n",
            "iter:  214 train_cost:  1.0892174 train_acc:  0.6171875 test_cost:  1.0067635 test_acc:  0.6875\n",
            "iter:  215 train_cost:  0.96368164 train_acc:  0.6796875 test_cost:  1.1682398 test_acc:  0.640625\n",
            "iter:  216 train_cost:  1.1263385 train_acc:  0.6328125 test_cost:  1.299448 test_acc:  0.625\n",
            "iter:  217 train_cost:  1.1108955 train_acc:  0.6796875 test_cost:  1.3766584 test_acc:  0.6015625\n",
            "iter:  218 train_cost:  1.2570918 train_acc:  0.609375 test_cost:  1.5745618 test_acc:  0.4921875\n",
            "iter:  219 train_cost:  1.2787185 train_acc:  0.625 test_cost:  1.0240152 test_acc:  0.7109375\n",
            "iter:  220 train_cost:  1.146934 train_acc:  0.6328125 test_cost:  1.2859039 test_acc:  0.578125\n",
            "iter:  221 train_cost:  1.3235033 train_acc:  0.5703125 test_cost:  1.2807914 test_acc:  0.6171875\n",
            "iter:  222 train_cost:  1.3215017 train_acc:  0.609375 test_cost:  1.0247531 test_acc:  0.6796875\n",
            "iter:  223 train_cost:  1.1148236 train_acc:  0.6640625 test_cost:  1.09294 test_acc:  0.640625\n",
            "iter:  224 train_cost:  1.0481961 train_acc:  0.671875 test_cost:  1.4187365 test_acc:  0.5859375\n",
            "iter:  225 train_cost:  1.2101719 train_acc:  0.671875 test_cost:  1.1733733 test_acc:  0.671875\n",
            "iter:  226 train_cost:  1.1333616 train_acc:  0.6640625 test_cost:  1.2160339 test_acc:  0.578125\n",
            "iter:  227 train_cost:  1.0040987 train_acc:  0.6953125 test_cost:  1.0866493 test_acc:  0.6484375\n",
            "iter:  228 train_cost:  0.97039723 train_acc:  0.6875 test_cost:  1.2212839 test_acc:  0.640625\n",
            "iter:  229 train_cost:  1.01548 train_acc:  0.6328125 test_cost:  0.9801331 test_acc:  0.6875\n",
            "iter:  230 train_cost:  1.0942439 train_acc:  0.6640625 test_cost:  1.1355329 test_acc:  0.609375\n",
            "iter:  231 train_cost:  1.2885303 train_acc:  0.6015625 test_cost:  1.2457939 test_acc:  0.5859375\n",
            "iter:  232 train_cost:  1.3670617 train_acc:  0.59375 test_cost:  1.0296996 test_acc:  0.6640625\n",
            "iter:  233 train_cost:  1.253903 train_acc:  0.5859375 test_cost:  0.7970281 test_acc:  0.65625\n",
            "iter:  234 train_cost:  1.1984516 train_acc:  0.578125 test_cost:  1.0750496 test_acc:  0.6875\n",
            "iter:  235 train_cost:  1.0616578 train_acc:  0.65625 test_cost:  1.0490971 test_acc:  0.640625\n",
            "iter:  236 train_cost:  0.97408086 train_acc:  0.71875 test_cost:  1.3316209 test_acc:  0.5859375\n",
            "iter:  237 train_cost:  1.0044376 train_acc:  0.703125 test_cost:  0.97480226 test_acc:  0.6953125\n",
            "iter:  238 train_cost:  0.9785309 train_acc:  0.6796875 test_cost:  1.1958001 test_acc:  0.640625\n",
            "iter:  239 train_cost:  1.1668272 train_acc:  0.6796875 test_cost:  0.9125908 test_acc:  0.71875\n",
            "iter:  240 train_cost:  1.1612852 train_acc:  0.59375 test_cost:  1.2685678 test_acc:  0.609375\n",
            "iter:  241 train_cost:  1.0185412 train_acc:  0.6640625 test_cost:  1.1812048 test_acc:  0.6796875\n",
            "iter:  242 train_cost:  1.2611456 train_acc:  0.6328125 test_cost:  1.058517 test_acc:  0.703125\n",
            "iter:  243 train_cost:  1.0282475 train_acc:  0.6328125 test_cost:  1.1027244 test_acc:  0.7109375\n",
            "iter:  244 train_cost:  0.8891034 train_acc:  0.6953125 test_cost:  1.1968348 test_acc:  0.640625\n",
            "iter:  245 train_cost:  1.0608404 train_acc:  0.671875 test_cost:  1.0995965 test_acc:  0.6875\n",
            "iter:  246 train_cost:  1.0533994 train_acc:  0.671875 test_cost:  0.91261446 test_acc:  0.703125\n",
            "iter:  247 train_cost:  1.0856514 train_acc:  0.671875 test_cost:  1.164124 test_acc:  0.625\n",
            "iter:  248 train_cost:  1.0020778 train_acc:  0.6953125 test_cost:  0.8509114 test_acc:  0.734375\n",
            "iter:  249 train_cost:  1.0896579 train_acc:  0.6640625 test_cost:  1.32545 test_acc:  0.609375\n",
            "iter:  250 train_cost:  1.029996 train_acc:  0.6640625 test_cost:  1.1751423 test_acc:  0.65625\n",
            "iter:  251 train_cost:  1.0531912 train_acc:  0.6484375 test_cost:  0.9664504 test_acc:  0.703125\n",
            "iter:  252 train_cost:  1.1308839 train_acc:  0.59375 test_cost:  1.0366958 test_acc:  0.6328125\n",
            "iter:  253 train_cost:  0.984133 train_acc:  0.6953125 test_cost:  1.0975482 test_acc:  0.671875\n",
            "iter:  254 train_cost:  0.95433074 train_acc:  0.65625 test_cost:  0.9619913 test_acc:  0.71875\n",
            "iter:  255 train_cost:  0.8271551 train_acc:  0.71875 test_cost:  0.90494514 test_acc:  0.765625\n",
            "iter:  256 train_cost:  1.2469704 train_acc:  0.6171875 test_cost:  1.0854999 test_acc:  0.65625\n",
            "iter:  257 train_cost:  1.0054761 train_acc:  0.6640625 test_cost:  1.1040387 test_acc:  0.671875\n",
            "iter:  258 train_cost:  1.0086257 train_acc:  0.6953125 test_cost:  1.1893021 test_acc:  0.609375\n",
            "iter:  259 train_cost:  1.0128139 train_acc:  0.6484375 test_cost:  1.0239831 test_acc:  0.65625\n",
            "iter:  260 train_cost:  1.1534165 train_acc:  0.6484375 test_cost:  1.0580897 test_acc:  0.6796875\n",
            "iter:  261 train_cost:  1.08273 train_acc:  0.6484375 test_cost:  1.1941869 test_acc:  0.625\n",
            "iter:  262 train_cost:  1.2106612 train_acc:  0.6015625 test_cost:  1.085555 test_acc:  0.625\n",
            "iter:  263 train_cost:  1.1296928 train_acc:  0.7109375 test_cost:  0.87566257 test_acc:  0.7265625\n",
            "iter:  264 train_cost:  0.9456067 train_acc:  0.6953125 test_cost:  1.0228742 test_acc:  0.6953125\n",
            "iter:  265 train_cost:  1.117676 train_acc:  0.65625 test_cost:  0.9822237 test_acc:  0.6640625\n",
            "iter:  266 train_cost:  1.0318459 train_acc:  0.6953125 test_cost:  0.91552126 test_acc:  0.6875\n",
            "iter:  267 train_cost:  1.1330593 train_acc:  0.6328125 test_cost:  1.1183991 test_acc:  0.65625\n",
            "iter:  268 train_cost:  0.87724423 train_acc:  0.6875 test_cost:  0.8409548 test_acc:  0.703125\n",
            "iter:  269 train_cost:  1.0648952 train_acc:  0.6328125 test_cost:  0.9370091 test_acc:  0.6875\n",
            "iter:  270 train_cost:  1.0730132 train_acc:  0.6796875 test_cost:  0.9657329 test_acc:  0.6484375\n",
            "iter:  271 train_cost:  0.95145816 train_acc:  0.6796875 test_cost:  0.8633672 test_acc:  0.71875\n",
            "iter:  272 train_cost:  1.1282716 train_acc:  0.65625 test_cost:  0.9609338 test_acc:  0.7109375\n",
            "iter:  273 train_cost:  1.0492699 train_acc:  0.703125 test_cost:  1.0615734 test_acc:  0.65625\n",
            "iter:  274 train_cost:  1.0163987 train_acc:  0.6953125 test_cost:  1.1367738 test_acc:  0.65625\n",
            "iter:  275 train_cost:  1.0335203 train_acc:  0.65625 test_cost:  1.2118045 test_acc:  0.65625\n",
            "iter:  276 train_cost:  1.086036 train_acc:  0.71875 test_cost:  0.94080067 test_acc:  0.71875\n",
            "iter:  277 train_cost:  0.9787885 train_acc:  0.6953125 test_cost:  1.0291439 test_acc:  0.671875\n",
            "iter:  278 train_cost:  1.0672184 train_acc:  0.6953125 test_cost:  1.1076127 test_acc:  0.6953125\n",
            "iter:  279 train_cost:  0.9229209 train_acc:  0.6953125 test_cost:  1.1083771 test_acc:  0.6875\n",
            "iter:  280 train_cost:  1.0187218 train_acc:  0.6640625 test_cost:  1.198602 test_acc:  0.625\n",
            "iter:  281 train_cost:  1.0656509 train_acc:  0.6640625 test_cost:  0.9948807 test_acc:  0.703125\n",
            "iter:  282 train_cost:  1.0883014 train_acc:  0.6328125 test_cost:  1.0372365 test_acc:  0.671875\n",
            "iter:  283 train_cost:  1.1092428 train_acc:  0.671875 test_cost:  1.2402718 test_acc:  0.59375\n",
            "iter:  284 train_cost:  0.8790238 train_acc:  0.7421875 test_cost:  1.1204193 test_acc:  0.703125\n",
            "iter:  285 train_cost:  1.0577025 train_acc:  0.6484375 test_cost:  0.92324257 test_acc:  0.6796875\n",
            "iter:  286 train_cost:  1.035913 train_acc:  0.6640625 test_cost:  0.97621864 test_acc:  0.671875\n",
            "iter:  287 train_cost:  0.94258803 train_acc:  0.703125 test_cost:  0.93552125 test_acc:  0.703125\n",
            "iter:  288 train_cost:  1.0011415 train_acc:  0.6953125 test_cost:  0.80829364 test_acc:  0.7265625\n",
            "iter:  289 train_cost:  0.94652915 train_acc:  0.671875 test_cost:  0.79070836 test_acc:  0.6953125\n",
            "iter:  290 train_cost:  1.1354594 train_acc:  0.6484375 test_cost:  1.0087898 test_acc:  0.7109375\n",
            "iter:  291 train_cost:  0.9509586 train_acc:  0.703125 test_cost:  1.0401092 test_acc:  0.65625\n",
            "iter:  292 train_cost:  0.91345054 train_acc:  0.6953125 test_cost:  0.8914881 test_acc:  0.7421875\n",
            "iter:  293 train_cost:  0.707079 train_acc:  0.75 test_cost:  1.0204818 test_acc:  0.65625\n",
            "iter:  294 train_cost:  0.87890494 train_acc:  0.703125 test_cost:  0.8345304 test_acc:  0.7578125\n",
            "iter:  295 train_cost:  0.92149234 train_acc:  0.734375 test_cost:  1.2038518 test_acc:  0.640625\n",
            "iter:  296 train_cost:  0.9625834 train_acc:  0.6796875 test_cost:  0.94150865 test_acc:  0.6796875\n",
            "iter:  297 train_cost:  0.9177578 train_acc:  0.6875 test_cost:  0.89842945 test_acc:  0.7578125\n",
            "iter:  298 train_cost:  0.96721697 train_acc:  0.7109375 test_cost:  0.8726622 test_acc:  0.7578125\n",
            "iter:  299 train_cost:  1.0334554 train_acc:  0.6796875 test_cost:  0.9476432 test_acc:  0.7109375\n",
            "iter:  300 train_cost:  1.07473 train_acc:  0.6875 test_cost:  0.89999247 test_acc:  0.703125\n",
            "iter:  301 train_cost:  0.8367431 train_acc:  0.71875 test_cost:  0.8364401 test_acc:  0.71875\n",
            "iter:  302 train_cost:  0.88753736 train_acc:  0.6953125 test_cost:  1.1488284 test_acc:  0.5859375\n",
            "iter:  303 train_cost:  1.0558445 train_acc:  0.6484375 test_cost:  0.95992327 test_acc:  0.6953125\n",
            "iter:  304 train_cost:  0.9621669 train_acc:  0.7265625 test_cost:  0.98803663 test_acc:  0.65625\n",
            "iter:  305 train_cost:  0.97344506 train_acc:  0.7109375 test_cost:  0.7094696 test_acc:  0.78125\n",
            "iter:  306 train_cost:  1.0863417 train_acc:  0.6640625 test_cost:  1.1039269 test_acc:  0.703125\n",
            "iter:  307 train_cost:  1.0590217 train_acc:  0.6640625 test_cost:  1.0005932 test_acc:  0.6796875\n",
            "iter:  308 train_cost:  1.0889854 train_acc:  0.65625 test_cost:  0.8140804 test_acc:  0.7890625\n",
            "iter:  309 train_cost:  0.96820796 train_acc:  0.640625 test_cost:  1.0382631 test_acc:  0.65625\n",
            "iter:  310 train_cost:  0.8330733 train_acc:  0.734375 test_cost:  0.7956294 test_acc:  0.734375\n",
            "iter:  311 train_cost:  0.76535374 train_acc:  0.796875 test_cost:  0.7290841 test_acc:  0.78125\n",
            "iter:  312 train_cost:  1.0843697 train_acc:  0.703125 test_cost:  0.82221043 test_acc:  0.734375\n",
            "iter:  313 train_cost:  0.94413173 train_acc:  0.71875 test_cost:  0.7004299 test_acc:  0.75\n",
            "iter:  314 train_cost:  0.9945531 train_acc:  0.7109375 test_cost:  1.1604292 test_acc:  0.6328125\n",
            "iter:  315 train_cost:  0.92002213 train_acc:  0.734375 test_cost:  1.044526 test_acc:  0.671875\n",
            "iter:  316 train_cost:  1.0876799 train_acc:  0.671875 test_cost:  0.9738289 test_acc:  0.7109375\n",
            "iter:  317 train_cost:  0.91740775 train_acc:  0.7421875 test_cost:  0.844923 test_acc:  0.7109375\n",
            "iter:  318 train_cost:  1.2172194 train_acc:  0.6640625 test_cost:  1.1077647 test_acc:  0.640625\n",
            "iter:  319 train_cost:  0.89077413 train_acc:  0.6796875 test_cost:  1.0713718 test_acc:  0.6171875\n",
            "iter:  320 train_cost:  0.7728522 train_acc:  0.7265625 test_cost:  1.1734521 test_acc:  0.6796875\n",
            "iter:  321 train_cost:  1.1078961 train_acc:  0.65625 test_cost:  0.8565304 test_acc:  0.7421875\n",
            "iter:  322 train_cost:  0.9418863 train_acc:  0.7421875 test_cost:  0.7855754 test_acc:  0.7421875\n",
            "iter:  323 train_cost:  0.97353494 train_acc:  0.71875 test_cost:  1.0453031 test_acc:  0.6640625\n",
            "iter:  324 train_cost:  0.76651084 train_acc:  0.7578125 test_cost:  0.80237156 test_acc:  0.75\n",
            "iter:  325 train_cost:  1.2494991 train_acc:  0.640625 test_cost:  0.75866544 test_acc:  0.734375\n",
            "iter:  326 train_cost:  1.0739584 train_acc:  0.6171875 test_cost:  0.96689594 test_acc:  0.6796875\n",
            "iter:  327 train_cost:  0.999605 train_acc:  0.65625 test_cost:  1.0393894 test_acc:  0.6796875\n",
            "iter:  328 train_cost:  0.9892386 train_acc:  0.65625 test_cost:  0.92522335 test_acc:  0.7265625\n",
            "iter:  329 train_cost:  0.85715353 train_acc:  0.734375 test_cost:  0.6648698 test_acc:  0.796875\n",
            "iter:  330 train_cost:  0.804292 train_acc:  0.734375 test_cost:  0.6900242 test_acc:  0.78125\n",
            "iter:  331 train_cost:  0.98050386 train_acc:  0.6796875 test_cost:  0.998559 test_acc:  0.6875\n",
            "iter:  332 train_cost:  0.86341584 train_acc:  0.734375 test_cost:  1.0052453 test_acc:  0.671875\n",
            "iter:  333 train_cost:  0.95855427 train_acc:  0.734375 test_cost:  0.8849946 test_acc:  0.7109375\n",
            "iter:  334 train_cost:  0.94332594 train_acc:  0.6875 test_cost:  1.0231175 test_acc:  0.71875\n",
            "iter:  335 train_cost:  1.1366622 train_acc:  0.6796875 test_cost:  1.0186905 test_acc:  0.671875\n",
            "iter:  336 train_cost:  0.8803731 train_acc:  0.765625 test_cost:  0.7975098 test_acc:  0.75\n",
            "iter:  337 train_cost:  0.90684754 train_acc:  0.734375 test_cost:  0.80920374 test_acc:  0.7265625\n",
            "iter:  338 train_cost:  1.1348411 train_acc:  0.6484375 test_cost:  0.89958113 test_acc:  0.703125\n",
            "iter:  339 train_cost:  1.021188 train_acc:  0.6640625 test_cost:  0.8491115 test_acc:  0.78125\n",
            "iter:  340 train_cost:  0.8498641 train_acc:  0.8125 test_cost:  0.81674147 test_acc:  0.765625\n",
            "iter:  341 train_cost:  1.0563298 train_acc:  0.671875 test_cost:  0.6612911 test_acc:  0.78125\n",
            "iter:  342 train_cost:  0.75979817 train_acc:  0.7734375 test_cost:  0.8433919 test_acc:  0.734375\n",
            "iter:  343 train_cost:  0.9064292 train_acc:  0.6796875 test_cost:  0.6923495 test_acc:  0.7890625\n",
            "iter:  344 train_cost:  0.8145975 train_acc:  0.671875 test_cost:  0.803715 test_acc:  0.765625\n",
            "iter:  345 train_cost:  1.0588048 train_acc:  0.65625 test_cost:  1.0938503 test_acc:  0.6875\n",
            "iter:  346 train_cost:  0.9468739 train_acc:  0.703125 test_cost:  0.92200094 test_acc:  0.703125\n",
            "iter:  347 train_cost:  0.85185707 train_acc:  0.7578125 test_cost:  0.7313924 test_acc:  0.765625\n",
            "iter:  348 train_cost:  0.93275905 train_acc:  0.71875 test_cost:  1.0065958 test_acc:  0.671875\n",
            "iter:  349 train_cost:  0.96054167 train_acc:  0.7109375 test_cost:  0.7890196 test_acc:  0.78125\n",
            "iter:  350 train_cost:  0.98978233 train_acc:  0.6484375 test_cost:  0.7383316 test_acc:  0.7890625\n",
            "iter:  351 train_cost:  0.94827104 train_acc:  0.7109375 test_cost:  0.90471035 test_acc:  0.7109375\n",
            "iter:  352 train_cost:  0.7686493 train_acc:  0.7421875 test_cost:  0.95806897 test_acc:  0.734375\n",
            "iter:  353 train_cost:  1.0029511 train_acc:  0.703125 test_cost:  0.67780423 test_acc:  0.78125\n",
            "iter:  354 train_cost:  0.8935312 train_acc:  0.703125 test_cost:  0.9464366 test_acc:  0.6796875\n",
            "iter:  355 train_cost:  0.8227662 train_acc:  0.7109375 test_cost:  0.9478594 test_acc:  0.71875\n",
            "iter:  356 train_cost:  0.9900304 train_acc:  0.6796875 test_cost:  0.95761526 test_acc:  0.7265625\n",
            "iter:  357 train_cost:  0.72921574 train_acc:  0.765625 test_cost:  1.0236526 test_acc:  0.7109375\n",
            "iter:  358 train_cost:  0.9284972 train_acc:  0.6953125 test_cost:  0.8539376 test_acc:  0.6875\n",
            "iter:  359 train_cost:  0.9924273 train_acc:  0.71875 test_cost:  0.9072108 test_acc:  0.703125\n",
            "iter:  360 train_cost:  0.8584942 train_acc:  0.7578125 test_cost:  0.7523775 test_acc:  0.78125\n",
            "iter:  361 train_cost:  0.8950579 train_acc:  0.734375 test_cost:  0.7633628 test_acc:  0.78125\n",
            "iter:  362 train_cost:  0.74076164 train_acc:  0.7890625 test_cost:  1.0071268 test_acc:  0.65625\n",
            "iter:  363 train_cost:  0.89993036 train_acc:  0.75 test_cost:  0.69772434 test_acc:  0.765625\n",
            "iter:  364 train_cost:  0.8552714 train_acc:  0.7421875 test_cost:  0.83110005 test_acc:  0.703125\n",
            "iter:  365 train_cost:  0.9144845 train_acc:  0.6953125 test_cost:  0.91540337 test_acc:  0.7421875\n",
            "iter:  366 train_cost:  0.82834226 train_acc:  0.71875 test_cost:  0.9573171 test_acc:  0.71875\n",
            "iter:  367 train_cost:  0.631799 train_acc:  0.7734375 test_cost:  1.0049403 test_acc:  0.734375\n",
            "iter:  368 train_cost:  0.81245035 train_acc:  0.7578125 test_cost:  0.8216159 test_acc:  0.734375\n",
            "iter:  369 train_cost:  0.76899946 train_acc:  0.7578125 test_cost:  0.77421945 test_acc:  0.6953125\n",
            "iter:  370 train_cost:  1.0090345 train_acc:  0.6875 test_cost:  0.74180907 test_acc:  0.765625\n",
            "iter:  371 train_cost:  0.96097875 train_acc:  0.6875 test_cost:  0.8478354 test_acc:  0.7109375\n",
            "iter:  372 train_cost:  0.7701378 train_acc:  0.765625 test_cost:  0.7224965 test_acc:  0.8046875\n",
            "iter:  373 train_cost:  0.9645338 train_acc:  0.71875 test_cost:  0.7333547 test_acc:  0.7890625\n",
            "iter:  374 train_cost:  0.8740336 train_acc:  0.7421875 test_cost:  0.7680126 test_acc:  0.734375\n",
            "iter:  375 train_cost:  0.8675564 train_acc:  0.7421875 test_cost:  0.94921905 test_acc:  0.703125\n",
            "iter:  376 train_cost:  1.0573264 train_acc:  0.6484375 test_cost:  0.8517043 test_acc:  0.7578125\n",
            "iter:  377 train_cost:  0.8452896 train_acc:  0.7421875 test_cost:  1.1137865 test_acc:  0.640625\n",
            "iter:  378 train_cost:  0.90270007 train_acc:  0.7421875 test_cost:  0.8338156 test_acc:  0.7421875\n",
            "iter:  379 train_cost:  0.723489 train_acc:  0.765625 test_cost:  0.81501657 test_acc:  0.8125\n",
            "iter:  380 train_cost:  0.98930144 train_acc:  0.703125 test_cost:  0.69848245 test_acc:  0.7421875\n",
            "iter:  381 train_cost:  0.8518288 train_acc:  0.734375 test_cost:  0.60826325 test_acc:  0.7890625\n",
            "iter:  382 train_cost:  0.95640224 train_acc:  0.7109375 test_cost:  0.7830399 test_acc:  0.7578125\n",
            "iter:  383 train_cost:  0.8742178 train_acc:  0.71875 test_cost:  0.94349295 test_acc:  0.703125\n",
            "iter:  384 train_cost:  0.79361343 train_acc:  0.7421875 test_cost:  0.7745768 test_acc:  0.7421875\n",
            "iter:  385 train_cost:  0.75503683 train_acc:  0.734375 test_cost:  0.69336677 test_acc:  0.7578125\n",
            "iter:  386 train_cost:  0.76109606 train_acc:  0.7734375 test_cost:  0.8609897 test_acc:  0.75\n",
            "iter:  387 train_cost:  0.8996802 train_acc:  0.75 test_cost:  0.6861913 test_acc:  0.78125\n",
            "iter:  388 train_cost:  0.82881135 train_acc:  0.75 test_cost:  0.69567645 test_acc:  0.8125\n",
            "iter:  389 train_cost:  0.80120087 train_acc:  0.765625 test_cost:  0.96059144 test_acc:  0.65625\n",
            "iter:  390 train_cost:  0.85326815 train_acc:  0.7421875 test_cost:  0.9648839 test_acc:  0.7265625\n",
            "iter:  391 train_cost:  0.94091827 train_acc:  0.6640625 test_cost:  0.59029055 test_acc:  0.8359375\n",
            "iter:  392 train_cost:  0.89205635 train_acc:  0.703125 test_cost:  1.2101228 test_acc:  0.625\n",
            "iter:  393 train_cost:  0.7292464 train_acc:  0.7265625 test_cost:  0.8050741 test_acc:  0.734375\n",
            "iter:  394 train_cost:  0.910058 train_acc:  0.71875 test_cost:  0.9712782 test_acc:  0.71875\n",
            "iter:  395 train_cost:  0.7422666 train_acc:  0.7734375 test_cost:  0.75423396 test_acc:  0.7890625\n",
            "iter:  396 train_cost:  0.66724265 train_acc:  0.8046875 test_cost:  0.7253661 test_acc:  0.7734375\n",
            "iter:  397 train_cost:  0.9173491 train_acc:  0.765625 test_cost:  1.0848658 test_acc:  0.6953125\n",
            "iter:  398 train_cost:  0.5535761 train_acc:  0.8046875 test_cost:  0.73469627 test_acc:  0.734375\n",
            "iter:  399 train_cost:  1.0423985 train_acc:  0.6796875 test_cost:  0.8668152 test_acc:  0.6796875\n",
            "iter:  400 train_cost:  0.83537006 train_acc:  0.7421875 test_cost:  0.7314613 test_acc:  0.7578125\n",
            "iter:  401 train_cost:  0.94380826 train_acc:  0.671875 test_cost:  0.668343 test_acc:  0.8046875\n",
            "iter:  402 train_cost:  0.83277583 train_acc:  0.7265625 test_cost:  0.81655705 test_acc:  0.71875\n",
            "iter:  403 train_cost:  0.8341866 train_acc:  0.7578125 test_cost:  1.0489697 test_acc:  0.6640625\n",
            "iter:  404 train_cost:  0.93082833 train_acc:  0.7265625 test_cost:  0.79901284 test_acc:  0.7421875\n",
            "iter:  405 train_cost:  0.6392339 train_acc:  0.8125 test_cost:  0.80625457 test_acc:  0.7421875\n",
            "iter:  406 train_cost:  0.8865499 train_acc:  0.71875 test_cost:  0.8230987 test_acc:  0.7421875\n",
            "iter:  407 train_cost:  1.0147303 train_acc:  0.6875 test_cost:  0.93270123 test_acc:  0.71875\n",
            "iter:  408 train_cost:  0.97912085 train_acc:  0.6796875 test_cost:  0.8195383 test_acc:  0.75\n",
            "iter:  409 train_cost:  0.5875225 train_acc:  0.8203125 test_cost:  0.9283062 test_acc:  0.7265625\n",
            "iter:  410 train_cost:  0.9267416 train_acc:  0.65625 test_cost:  0.75124013 test_acc:  0.765625\n",
            "iter:  411 train_cost:  0.8892176 train_acc:  0.7109375 test_cost:  0.7073673 test_acc:  0.7578125\n",
            "iter:  412 train_cost:  0.80708736 train_acc:  0.7109375 test_cost:  0.759405 test_acc:  0.796875\n",
            "iter:  413 train_cost:  0.88650584 train_acc:  0.703125 test_cost:  0.856216 test_acc:  0.71875\n",
            "iter:  414 train_cost:  0.7664856 train_acc:  0.78125 test_cost:  0.53201437 test_acc:  0.8046875\n",
            "iter:  415 train_cost:  0.87864995 train_acc:  0.7265625 test_cost:  0.6959827 test_acc:  0.78125\n",
            "iter:  416 train_cost:  0.9810319 train_acc:  0.7265625 test_cost:  0.6788866 test_acc:  0.75\n",
            "iter:  417 train_cost:  0.89931977 train_acc:  0.71875 test_cost:  0.8245124 test_acc:  0.7890625\n",
            "iter:  418 train_cost:  0.84496766 train_acc:  0.7265625 test_cost:  0.76474935 test_acc:  0.7890625\n",
            "iter:  419 train_cost:  0.66352654 train_acc:  0.7578125 test_cost:  0.7590884 test_acc:  0.8046875\n",
            "iter:  420 train_cost:  0.6605685 train_acc:  0.7578125 test_cost:  0.8271838 test_acc:  0.765625\n",
            "iter:  421 train_cost:  0.74339306 train_acc:  0.75 test_cost:  0.60930264 test_acc:  0.875\n",
            "iter:  422 train_cost:  0.94032073 train_acc:  0.71875 test_cost:  0.7154697 test_acc:  0.796875\n",
            "iter:  423 train_cost:  0.68176097 train_acc:  0.7890625 test_cost:  0.6257072 test_acc:  0.8046875\n",
            "iter:  424 train_cost:  0.83383685 train_acc:  0.6953125 test_cost:  0.8310196 test_acc:  0.75\n",
            "iter:  425 train_cost:  0.6358456 train_acc:  0.7265625 test_cost:  0.63610864 test_acc:  0.8046875\n",
            "iter:  426 train_cost:  0.5822941 train_acc:  0.8125 test_cost:  0.75546646 test_acc:  0.7578125\n",
            "iter:  427 train_cost:  0.91417986 train_acc:  0.7578125 test_cost:  0.82776475 test_acc:  0.7265625\n",
            "iter:  428 train_cost:  0.72184455 train_acc:  0.78125 test_cost:  0.714424 test_acc:  0.7890625\n",
            "iter:  429 train_cost:  0.70648736 train_acc:  0.78125 test_cost:  0.79849124 test_acc:  0.7578125\n",
            "iter:  430 train_cost:  0.78087395 train_acc:  0.7578125 test_cost:  0.66164035 test_acc:  0.78125\n",
            "iter:  431 train_cost:  0.60643786 train_acc:  0.8046875 test_cost:  0.66671354 test_acc:  0.8046875\n",
            "iter:  432 train_cost:  0.58731186 train_acc:  0.8046875 test_cost:  0.59667516 test_acc:  0.8046875\n",
            "iter:  433 train_cost:  0.9737911 train_acc:  0.7578125 test_cost:  0.8461741 test_acc:  0.7734375\n",
            "iter:  434 train_cost:  0.74668 train_acc:  0.7109375 test_cost:  0.83222485 test_acc:  0.765625\n",
            "iter:  435 train_cost:  0.64455885 train_acc:  0.8046875 test_cost:  0.95583 test_acc:  0.71875\n",
            "iter:  436 train_cost:  0.63373375 train_acc:  0.84375 test_cost:  0.69948524 test_acc:  0.7265625\n",
            "iter:  437 train_cost:  0.72261673 train_acc:  0.7890625 test_cost:  0.6034418 test_acc:  0.828125\n",
            "iter:  438 train_cost:  0.86717594 train_acc:  0.734375 test_cost:  0.9272549 test_acc:  0.734375\n",
            "iter:  439 train_cost:  0.66316545 train_acc:  0.75 test_cost:  0.79777366 test_acc:  0.75\n",
            "iter:  440 train_cost:  0.6361573 train_acc:  0.7734375 test_cost:  0.9754391 test_acc:  0.703125\n",
            "iter:  441 train_cost:  0.54483426 train_acc:  0.8203125 test_cost:  0.60901165 test_acc:  0.78125\n",
            "iter:  442 train_cost:  0.75734496 train_acc:  0.7578125 test_cost:  0.55249405 test_acc:  0.7890625\n",
            "iter:  443 train_cost:  0.8781507 train_acc:  0.765625 test_cost:  0.7031788 test_acc:  0.7890625\n",
            "iter:  444 train_cost:  0.81670356 train_acc:  0.765625 test_cost:  0.78242576 test_acc:  0.7734375\n",
            "iter:  445 train_cost:  0.80816007 train_acc:  0.7421875 test_cost:  0.7350441 test_acc:  0.7265625\n",
            "iter:  446 train_cost:  0.5847637 train_acc:  0.796875 test_cost:  0.7649882 test_acc:  0.75\n",
            "iter:  447 train_cost:  0.70031416 train_acc:  0.7578125 test_cost:  0.7602699 test_acc:  0.75\n",
            "iter:  448 train_cost:  0.7022328 train_acc:  0.7890625 test_cost:  0.85631144 test_acc:  0.7578125\n",
            "iter:  449 train_cost:  0.7814684 train_acc:  0.765625 test_cost:  0.87397355 test_acc:  0.71875\n",
            "iter:  450 train_cost:  0.850366 train_acc:  0.7734375 test_cost:  0.7609482 test_acc:  0.7578125\n",
            "iter:  451 train_cost:  0.74407816 train_acc:  0.765625 test_cost:  0.6407873 test_acc:  0.796875\n",
            "iter:  452 train_cost:  0.6948935 train_acc:  0.8125 test_cost:  0.79891425 test_acc:  0.7421875\n",
            "iter:  453 train_cost:  0.742949 train_acc:  0.7734375 test_cost:  0.70183873 test_acc:  0.796875\n",
            "iter:  454 train_cost:  0.7831938 train_acc:  0.7890625 test_cost:  0.53065974 test_acc:  0.7890625\n",
            "iter:  455 train_cost:  0.7929879 train_acc:  0.7421875 test_cost:  0.77334344 test_acc:  0.734375\n",
            "iter:  456 train_cost:  0.79454195 train_acc:  0.7109375 test_cost:  0.66331065 test_acc:  0.75\n",
            "iter:  457 train_cost:  0.61680496 train_acc:  0.8203125 test_cost:  0.8511791 test_acc:  0.7578125\n",
            "iter:  458 train_cost:  0.786335 train_acc:  0.7734375 test_cost:  0.6985429 test_acc:  0.796875\n",
            "iter:  459 train_cost:  0.8002229 train_acc:  0.796875 test_cost:  0.6657248 test_acc:  0.8359375\n",
            "iter:  460 train_cost:  0.8559593 train_acc:  0.703125 test_cost:  0.6404723 test_acc:  0.796875\n",
            "iter:  461 train_cost:  0.5748442 train_acc:  0.84375 test_cost:  0.66070855 test_acc:  0.8515625\n",
            "iter:  462 train_cost:  0.81851095 train_acc:  0.71875 test_cost:  0.83455986 test_acc:  0.7734375\n",
            "iter:  463 train_cost:  0.6951753 train_acc:  0.75 test_cost:  0.7840248 test_acc:  0.703125\n",
            "iter:  464 train_cost:  0.71597874 train_acc:  0.78125 test_cost:  0.8166161 test_acc:  0.7578125\n",
            "iter:  465 train_cost:  0.73299587 train_acc:  0.8046875 test_cost:  0.73639417 test_acc:  0.734375\n",
            "iter:  466 train_cost:  0.609949 train_acc:  0.7890625 test_cost:  0.7907327 test_acc:  0.7578125\n",
            "iter:  467 train_cost:  0.72475827 train_acc:  0.7421875 test_cost:  0.7868867 test_acc:  0.7578125\n",
            "iter:  468 train_cost:  0.71887845 train_acc:  0.7734375 test_cost:  0.65894717 test_acc:  0.796875\n",
            "iter:  469 train_cost:  0.6949911 train_acc:  0.78125 test_cost:  0.78135526 test_acc:  0.8046875\n",
            "iter:  470 train_cost:  0.71293557 train_acc:  0.7734375 test_cost:  0.7143842 test_acc:  0.765625\n",
            "iter:  471 train_cost:  0.8355263 train_acc:  0.75 test_cost:  0.70064545 test_acc:  0.796875\n",
            "iter:  472 train_cost:  0.7604719 train_acc:  0.7578125 test_cost:  0.65362966 test_acc:  0.7734375\n",
            "iter:  473 train_cost:  0.59264433 train_acc:  0.78125 test_cost:  0.6658463 test_acc:  0.78125\n",
            "iter:  474 train_cost:  0.74867463 train_acc:  0.7890625 test_cost:  0.8180177 test_acc:  0.734375\n",
            "iter:  475 train_cost:  0.754126 train_acc:  0.765625 test_cost:  0.62830186 test_acc:  0.8203125\n",
            "iter:  476 train_cost:  0.7515905 train_acc:  0.734375 test_cost:  0.6468021 test_acc:  0.796875\n",
            "iter:  477 train_cost:  0.71581155 train_acc:  0.7890625 test_cost:  1.0136669 test_acc:  0.7109375\n",
            "iter:  478 train_cost:  0.55044514 train_acc:  0.828125 test_cost:  0.6330037 test_acc:  0.75\n",
            "iter:  479 train_cost:  0.6231364 train_acc:  0.8046875 test_cost:  0.7735574 test_acc:  0.765625\n",
            "iter:  480 train_cost:  0.634889 train_acc:  0.8203125 test_cost:  0.6656951 test_acc:  0.796875\n",
            "iter:  481 train_cost:  0.63945115 train_acc:  0.7734375 test_cost:  0.8524257 test_acc:  0.78125\n",
            "iter:  482 train_cost:  0.60212564 train_acc:  0.765625 test_cost:  0.68724084 test_acc:  0.7578125\n",
            "iter:  483 train_cost:  0.81941074 train_acc:  0.6953125 test_cost:  0.7996869 test_acc:  0.8125\n",
            "iter:  484 train_cost:  0.58161014 train_acc:  0.8125 test_cost:  0.69010603 test_acc:  0.7734375\n",
            "iter:  485 train_cost:  0.80906695 train_acc:  0.7109375 test_cost:  0.7557291 test_acc:  0.7890625\n",
            "iter:  486 train_cost:  0.53120625 train_acc:  0.8125 test_cost:  0.7508949 test_acc:  0.796875\n",
            "iter:  487 train_cost:  0.7150719 train_acc:  0.75 test_cost:  0.5594989 test_acc:  0.8515625\n",
            "iter:  488 train_cost:  0.62131333 train_acc:  0.84375 test_cost:  0.8028076 test_acc:  0.75\n",
            "iter:  489 train_cost:  0.6437668 train_acc:  0.7890625 test_cost:  0.7273313 test_acc:  0.796875\n",
            "iter:  490 train_cost:  0.6542581 train_acc:  0.78125 test_cost:  0.7835914 test_acc:  0.78125\n",
            "iter:  491 train_cost:  0.8073815 train_acc:  0.765625 test_cost:  0.75961745 test_acc:  0.765625\n",
            "iter:  492 train_cost:  0.5961899 train_acc:  0.7890625 test_cost:  0.850855 test_acc:  0.78125\n",
            "iter:  493 train_cost:  0.7713887 train_acc:  0.71875 test_cost:  0.615952 test_acc:  0.796875\n",
            "iter:  494 train_cost:  0.83702546 train_acc:  0.734375 test_cost:  0.8500203 test_acc:  0.7265625\n",
            "iter:  495 train_cost:  0.73861486 train_acc:  0.78125 test_cost:  0.63717973 test_acc:  0.7578125\n",
            "iter:  496 train_cost:  0.9780177 train_acc:  0.7109375 test_cost:  0.7091489 test_acc:  0.7890625\n",
            "iter:  497 train_cost:  0.7977218 train_acc:  0.734375 test_cost:  0.64384454 test_acc:  0.8046875\n",
            "iter:  498 train_cost:  0.8351414 train_acc:  0.7265625 test_cost:  0.76060236 test_acc:  0.7890625\n",
            "iter:  499 train_cost:  0.62327385 train_acc:  0.8515625 test_cost:  0.71609414 test_acc:  0.7890625\n",
            "iter:  500 train_cost:  0.76088595 train_acc:  0.7734375 test_cost:  0.7089363 test_acc:  0.78125\n",
            "iter:  501 train_cost:  0.6670797 train_acc:  0.828125 test_cost:  0.74206626 test_acc:  0.734375\n",
            "iter:  502 train_cost:  0.74966633 train_acc:  0.765625 test_cost:  0.75628406 test_acc:  0.7265625\n",
            "iter:  503 train_cost:  0.5204412 train_acc:  0.8359375 test_cost:  0.614059 test_acc:  0.796875\n",
            "iter:  504 train_cost:  0.7949567 train_acc:  0.7734375 test_cost:  0.6304673 test_acc:  0.7890625\n",
            "iter:  505 train_cost:  0.6710493 train_acc:  0.7734375 test_cost:  0.73983264 test_acc:  0.7578125\n",
            "iter:  506 train_cost:  0.70685846 train_acc:  0.75 test_cost:  0.63982654 test_acc:  0.7890625\n",
            "iter:  507 train_cost:  0.5601374 train_acc:  0.8359375 test_cost:  0.7465764 test_acc:  0.765625\n",
            "iter:  508 train_cost:  0.5309484 train_acc:  0.8125 test_cost:  0.57543254 test_acc:  0.796875\n",
            "iter:  509 train_cost:  0.67485195 train_acc:  0.78125 test_cost:  0.6807895 test_acc:  0.7734375\n",
            "iter:  510 train_cost:  0.7304629 train_acc:  0.8046875 test_cost:  0.574947 test_acc:  0.8046875\n",
            "iter:  511 train_cost:  0.71112525 train_acc:  0.7734375 test_cost:  0.6437324 test_acc:  0.78125\n",
            "iter:  512 train_cost:  0.78986627 train_acc:  0.71875 test_cost:  0.84787434 test_acc:  0.765625\n",
            "iter:  513 train_cost:  0.7165027 train_acc:  0.7421875 test_cost:  0.7162358 test_acc:  0.7578125\n",
            "iter:  514 train_cost:  0.5464331 train_acc:  0.8203125 test_cost:  0.6526207 test_acc:  0.7734375\n",
            "iter:  515 train_cost:  0.58869076 train_acc:  0.8203125 test_cost:  0.6158645 test_acc:  0.8046875\n",
            "iter:  516 train_cost:  0.84748304 train_acc:  0.6953125 test_cost:  0.66754025 test_acc:  0.8046875\n",
            "iter:  517 train_cost:  0.7167878 train_acc:  0.7734375 test_cost:  0.70531285 test_acc:  0.7734375\n",
            "iter:  518 train_cost:  0.73718786 train_acc:  0.7578125 test_cost:  0.5799109 test_acc:  0.7890625\n",
            "iter:  519 train_cost:  0.6924074 train_acc:  0.8046875 test_cost:  0.6245042 test_acc:  0.7734375\n",
            "iter:  520 train_cost:  0.6682684 train_acc:  0.7890625 test_cost:  0.48622733 test_acc:  0.8515625\n",
            "iter:  521 train_cost:  0.70132995 train_acc:  0.78125 test_cost:  0.5167403 test_acc:  0.84375\n",
            "iter:  522 train_cost:  0.7898987 train_acc:  0.7890625 test_cost:  0.64169747 test_acc:  0.7890625\n",
            "iter:  523 train_cost:  0.8105867 train_acc:  0.7890625 test_cost:  0.8879708 test_acc:  0.75\n",
            "iter:  524 train_cost:  0.70614517 train_acc:  0.78125 test_cost:  0.5776072 test_acc:  0.8125\n",
            "iter:  525 train_cost:  0.6231791 train_acc:  0.8359375 test_cost:  0.673966 test_acc:  0.78125\n",
            "iter:  526 train_cost:  0.64410305 train_acc:  0.796875 test_cost:  0.6292369 test_acc:  0.8046875\n",
            "iter:  527 train_cost:  0.48441637 train_acc:  0.84375 test_cost:  0.94280076 test_acc:  0.75\n",
            "iter:  528 train_cost:  0.570143 train_acc:  0.8203125 test_cost:  0.6553929 test_acc:  0.8125\n",
            "iter:  529 train_cost:  0.63606274 train_acc:  0.8125 test_cost:  0.8223377 test_acc:  0.7734375\n",
            "iter:  530 train_cost:  0.66151994 train_acc:  0.7890625 test_cost:  0.7610032 test_acc:  0.7890625\n",
            "iter:  531 train_cost:  0.7060049 train_acc:  0.7734375 test_cost:  0.6306633 test_acc:  0.7890625\n",
            "iter:  532 train_cost:  0.61295426 train_acc:  0.796875 test_cost:  0.60814685 test_acc:  0.7890625\n",
            "iter:  533 train_cost:  0.72472763 train_acc:  0.7734375 test_cost:  0.76964134 test_acc:  0.7734375\n",
            "iter:  534 train_cost:  0.6674036 train_acc:  0.796875 test_cost:  0.60207474 test_acc:  0.8203125\n",
            "iter:  535 train_cost:  0.6935187 train_acc:  0.8203125 test_cost:  0.6392322 test_acc:  0.7890625\n",
            "iter:  536 train_cost:  0.6240684 train_acc:  0.7890625 test_cost:  0.6463688 test_acc:  0.8125\n",
            "iter:  537 train_cost:  0.69701785 train_acc:  0.765625 test_cost:  0.7863358 test_acc:  0.7421875\n",
            "iter:  538 train_cost:  0.71459013 train_acc:  0.78125 test_cost:  0.70128703 test_acc:  0.78125\n",
            "iter:  539 train_cost:  0.57949626 train_acc:  0.828125 test_cost:  0.62611496 test_acc:  0.796875\n",
            "iter:  540 train_cost:  0.66476595 train_acc:  0.8125 test_cost:  0.5309458 test_acc:  0.8515625\n",
            "iter:  541 train_cost:  0.729107 train_acc:  0.765625 test_cost:  0.44661918 test_acc:  0.8515625\n",
            "iter:  542 train_cost:  0.62521267 train_acc:  0.8203125 test_cost:  0.473332 test_acc:  0.8359375\n",
            "iter:  543 train_cost:  0.8764231 train_acc:  0.7265625 test_cost:  0.7300471 test_acc:  0.765625\n",
            "iter:  544 train_cost:  0.6725292 train_acc:  0.8125 test_cost:  0.7367144 test_acc:  0.7890625\n",
            "iter:  545 train_cost:  0.6308256 train_acc:  0.7890625 test_cost:  0.73756945 test_acc:  0.78125\n",
            "iter:  546 train_cost:  0.71816474 train_acc:  0.75 test_cost:  0.5504955 test_acc:  0.8203125\n",
            "iter:  547 train_cost:  0.6291295 train_acc:  0.8125 test_cost:  0.6294067 test_acc:  0.8125\n",
            "iter:  548 train_cost:  0.6853152 train_acc:  0.7890625 test_cost:  0.59749323 test_acc:  0.84375\n",
            "iter:  549 train_cost:  0.846105 train_acc:  0.765625 test_cost:  0.6237483 test_acc:  0.8359375\n",
            "iter:  550 train_cost:  0.59171337 train_acc:  0.796875 test_cost:  0.66372645 test_acc:  0.7734375\n",
            "iter:  551 train_cost:  0.54991776 train_acc:  0.8671875 test_cost:  0.6047499 test_acc:  0.8125\n",
            "iter:  552 train_cost:  0.61795247 train_acc:  0.8125 test_cost:  0.61730945 test_acc:  0.7890625\n",
            "iter:  553 train_cost:  0.58778787 train_acc:  0.8046875 test_cost:  0.7442085 test_acc:  0.765625\n",
            "iter:  554 train_cost:  0.76538557 train_acc:  0.7734375 test_cost:  0.6956618 test_acc:  0.78125\n",
            "iter:  555 train_cost:  0.6115531 train_acc:  0.8125 test_cost:  0.6985027 test_acc:  0.7265625\n",
            "iter:  556 train_cost:  0.63492084 train_acc:  0.8046875 test_cost:  0.46842924 test_acc:  0.8515625\n",
            "iter:  557 train_cost:  0.5615655 train_acc:  0.8515625 test_cost:  0.635959 test_acc:  0.765625\n",
            "iter:  558 train_cost:  0.6941015 train_acc:  0.765625 test_cost:  0.64105195 test_acc:  0.7578125\n",
            "iter:  559 train_cost:  0.70124245 train_acc:  0.7734375 test_cost:  0.75526166 test_acc:  0.78125\n",
            "iter:  560 train_cost:  0.64282244 train_acc:  0.7578125 test_cost:  0.5712799 test_acc:  0.8515625\n",
            "iter:  561 train_cost:  0.77377605 train_acc:  0.734375 test_cost:  0.5854161 test_acc:  0.8125\n",
            "iter:  562 train_cost:  0.6149883 train_acc:  0.796875 test_cost:  0.524047 test_acc:  0.8046875\n",
            "iter:  563 train_cost:  0.8055173 train_acc:  0.7578125 test_cost:  0.6178229 test_acc:  0.8046875\n",
            "iter:  564 train_cost:  0.64100647 train_acc:  0.8203125 test_cost:  0.65347415 test_acc:  0.78125\n",
            "iter:  565 train_cost:  0.6881846 train_acc:  0.78125 test_cost:  0.6548794 test_acc:  0.7890625\n",
            "iter:  566 train_cost:  0.6745945 train_acc:  0.828125 test_cost:  0.7922795 test_acc:  0.7421875\n",
            "iter:  567 train_cost:  0.5534681 train_acc:  0.828125 test_cost:  0.5245986 test_acc:  0.8125\n",
            "iter:  568 train_cost:  0.6026964 train_acc:  0.8515625 test_cost:  0.48604962 test_acc:  0.828125\n",
            "iter:  569 train_cost:  0.61949027 train_acc:  0.8203125 test_cost:  0.68805724 test_acc:  0.8125\n",
            "iter:  570 train_cost:  0.76283175 train_acc:  0.78125 test_cost:  0.6892383 test_acc:  0.7890625\n",
            "iter:  571 train_cost:  0.7170605 train_acc:  0.796875 test_cost:  0.46947324 test_acc:  0.859375\n",
            "iter:  572 train_cost:  0.6044996 train_acc:  0.796875 test_cost:  0.5757126 test_acc:  0.796875\n",
            "iter:  573 train_cost:  0.5903088 train_acc:  0.796875 test_cost:  0.47178856 test_acc:  0.8671875\n",
            "iter:  574 train_cost:  0.6071814 train_acc:  0.8359375 test_cost:  0.7637818 test_acc:  0.78125\n",
            "iter:  575 train_cost:  0.6228131 train_acc:  0.8359375 test_cost:  0.71891063 test_acc:  0.8046875\n",
            "iter:  576 train_cost:  0.7676166 train_acc:  0.7578125 test_cost:  0.57555187 test_acc:  0.8359375\n",
            "iter:  577 train_cost:  0.65796757 train_acc:  0.78125 test_cost:  0.8037747 test_acc:  0.796875\n",
            "iter:  578 train_cost:  0.7803427 train_acc:  0.7421875 test_cost:  0.75117713 test_acc:  0.78125\n",
            "iter:  579 train_cost:  0.68062717 train_acc:  0.796875 test_cost:  0.62622774 test_acc:  0.828125\n",
            "iter:  580 train_cost:  0.7697187 train_acc:  0.75 test_cost:  0.84182405 test_acc:  0.734375\n",
            "iter:  581 train_cost:  0.8170129 train_acc:  0.734375 test_cost:  0.5960119 test_acc:  0.8125\n",
            "iter:  582 train_cost:  0.55247647 train_acc:  0.8046875 test_cost:  0.5800649 test_acc:  0.8203125\n",
            "iter:  583 train_cost:  0.6769643 train_acc:  0.765625 test_cost:  0.64152193 test_acc:  0.84375\n",
            "iter:  584 train_cost:  0.6020968 train_acc:  0.796875 test_cost:  0.645218 test_acc:  0.8515625\n",
            "iter:  585 train_cost:  0.7343065 train_acc:  0.765625 test_cost:  0.7040509 test_acc:  0.78125\n",
            "iter:  586 train_cost:  0.56002057 train_acc:  0.8046875 test_cost:  0.58375365 test_acc:  0.84375\n",
            "iter:  587 train_cost:  0.696668 train_acc:  0.7734375 test_cost:  0.63344705 test_acc:  0.8203125\n",
            "iter:  588 train_cost:  0.70042545 train_acc:  0.7734375 test_cost:  0.4436841 test_acc:  0.8515625\n",
            "iter:  589 train_cost:  0.78748894 train_acc:  0.8046875 test_cost:  0.69228166 test_acc:  0.796875\n",
            "iter:  590 train_cost:  0.86857915 train_acc:  0.7421875 test_cost:  0.6296473 test_acc:  0.8125\n",
            "iter:  591 train_cost:  0.7982544 train_acc:  0.78125 test_cost:  0.7067021 test_acc:  0.78125\n",
            "iter:  592 train_cost:  0.8393444 train_acc:  0.75 test_cost:  0.65223145 test_acc:  0.8203125\n",
            "iter:  593 train_cost:  0.5265492 train_acc:  0.8203125 test_cost:  0.6204999 test_acc:  0.8046875\n",
            "iter:  594 train_cost:  0.760528 train_acc:  0.765625 test_cost:  0.53326446 test_acc:  0.8203125\n",
            "iter:  595 train_cost:  0.71012 train_acc:  0.7734375 test_cost:  0.73768014 test_acc:  0.7578125\n",
            "iter:  596 train_cost:  0.67369527 train_acc:  0.7578125 test_cost:  0.6424739 test_acc:  0.78125\n",
            "iter:  597 train_cost:  0.49901015 train_acc:  0.8671875 test_cost:  0.73261976 test_acc:  0.8046875\n",
            "iter:  598 train_cost:  0.49546778 train_acc:  0.84375 test_cost:  0.56690264 test_acc:  0.8203125\n",
            "iter:  599 train_cost:  0.7236873 train_acc:  0.7734375 test_cost:  0.6643245 test_acc:  0.796875\n",
            "iter:  600 train_cost:  0.73855036 train_acc:  0.7578125 test_cost:  0.59726006 test_acc:  0.8359375\n",
            "iter:  601 train_cost:  0.5857886 train_acc:  0.8046875 test_cost:  0.8218336 test_acc:  0.75\n",
            "iter:  602 train_cost:  0.65843993 train_acc:  0.78125 test_cost:  0.7012212 test_acc:  0.7890625\n",
            "iter:  603 train_cost:  0.6492361 train_acc:  0.8046875 test_cost:  0.7325636 test_acc:  0.7734375\n",
            "iter:  604 train_cost:  0.6074132 train_acc:  0.8125 test_cost:  0.7106391 test_acc:  0.7421875\n",
            "iter:  605 train_cost:  0.61200315 train_acc:  0.8203125 test_cost:  0.56609577 test_acc:  0.8125\n",
            "iter:  606 train_cost:  0.6696878 train_acc:  0.828125 test_cost:  0.56166124 test_acc:  0.8203125\n",
            "iter:  607 train_cost:  0.66778564 train_acc:  0.78125 test_cost:  0.6888135 test_acc:  0.7890625\n",
            "iter:  608 train_cost:  0.4918254 train_acc:  0.828125 test_cost:  0.54960394 test_acc:  0.8203125\n",
            "iter:  609 train_cost:  0.5608827 train_acc:  0.8203125 test_cost:  0.43656078 test_acc:  0.859375\n",
            "iter:  610 train_cost:  0.49660477 train_acc:  0.828125 test_cost:  0.5387563 test_acc:  0.8203125\n",
            "iter:  611 train_cost:  0.71021855 train_acc:  0.78125 test_cost:  0.8821838 test_acc:  0.703125\n",
            "iter:  612 train_cost:  0.44677582 train_acc:  0.859375 test_cost:  0.56882536 test_acc:  0.828125\n",
            "iter:  613 train_cost:  0.4601494 train_acc:  0.8671875 test_cost:  0.45153546 test_acc:  0.8671875\n",
            "iter:  614 train_cost:  0.6467305 train_acc:  0.8203125 test_cost:  0.62206787 test_acc:  0.8203125\n",
            "iter:  615 train_cost:  0.5622357 train_acc:  0.8515625 test_cost:  0.70335037 test_acc:  0.7421875\n",
            "iter:  616 train_cost:  0.4851513 train_acc:  0.859375 test_cost:  0.77509475 test_acc:  0.7578125\n",
            "iter:  617 train_cost:  0.6042348 train_acc:  0.78125 test_cost:  0.7169507 test_acc:  0.8125\n",
            "iter:  618 train_cost:  0.7083665 train_acc:  0.796875 test_cost:  0.56212616 test_acc:  0.8125\n",
            "iter:  619 train_cost:  0.4174688 train_acc:  0.84375 test_cost:  0.67565835 test_acc:  0.78125\n",
            "iter:  620 train_cost:  0.78253996 train_acc:  0.796875 test_cost:  0.3727168 test_acc:  0.890625\n",
            "iter:  621 train_cost:  0.67848885 train_acc:  0.796875 test_cost:  0.90120417 test_acc:  0.71875\n",
            "iter:  622 train_cost:  0.51318675 train_acc:  0.8671875 test_cost:  0.59861755 test_acc:  0.8203125\n",
            "iter:  623 train_cost:  0.6955093 train_acc:  0.7890625 test_cost:  0.639437 test_acc:  0.8125\n",
            "iter:  624 train_cost:  0.68927574 train_acc:  0.75 test_cost:  0.7231325 test_acc:  0.7734375\n",
            "iter:  625 train_cost:  0.6955474 train_acc:  0.8046875 test_cost:  0.569265 test_acc:  0.8046875\n",
            "iter:  626 train_cost:  0.7398231 train_acc:  0.8125 test_cost:  0.6544624 test_acc:  0.8046875\n",
            "iter:  627 train_cost:  0.61820644 train_acc:  0.796875 test_cost:  0.50695795 test_acc:  0.8125\n",
            "iter:  628 train_cost:  0.60248613 train_acc:  0.8046875 test_cost:  0.54342175 test_acc:  0.8359375\n",
            "iter:  629 train_cost:  0.5924224 train_acc:  0.8046875 test_cost:  0.6147614 test_acc:  0.8046875\n",
            "iter:  630 train_cost:  0.6472896 train_acc:  0.7578125 test_cost:  0.49672922 test_acc:  0.8671875\n",
            "iter:  631 train_cost:  0.71235436 train_acc:  0.78125 test_cost:  0.6059136 test_acc:  0.8359375\n",
            "iter:  632 train_cost:  0.6904126 train_acc:  0.78125 test_cost:  0.6395352 test_acc:  0.8125\n",
            "iter:  633 train_cost:  0.6521262 train_acc:  0.8046875 test_cost:  0.5438066 test_acc:  0.828125\n",
            "iter:  634 train_cost:  0.6676587 train_acc:  0.8203125 test_cost:  0.712074 test_acc:  0.796875\n",
            "iter:  635 train_cost:  0.49235123 train_acc:  0.84375 test_cost:  0.58555806 test_acc:  0.7734375\n",
            "iter:  636 train_cost:  0.47703815 train_acc:  0.859375 test_cost:  0.65608424 test_acc:  0.796875\n",
            "iter:  637 train_cost:  0.64797264 train_acc:  0.8046875 test_cost:  0.639308 test_acc:  0.8125\n",
            "iter:  638 train_cost:  0.6804187 train_acc:  0.75 test_cost:  0.5875809 test_acc:  0.8125\n",
            "iter:  639 train_cost:  0.5103132 train_acc:  0.8359375 test_cost:  0.57075125 test_acc:  0.8203125\n",
            "iter:  640 train_cost:  0.45092756 train_acc:  0.8515625 test_cost:  0.41833562 test_acc:  0.8984375\n",
            "iter:  641 train_cost:  0.48464486 train_acc:  0.84375 test_cost:  0.67222846 test_acc:  0.7890625\n",
            "iter:  642 train_cost:  0.50195897 train_acc:  0.828125 test_cost:  0.54516613 test_acc:  0.84375\n",
            "iter:  643 train_cost:  0.6688525 train_acc:  0.7734375 test_cost:  0.6796888 test_acc:  0.84375\n",
            "iter:  644 train_cost:  0.4845872 train_acc:  0.875 test_cost:  0.5719774 test_acc:  0.84375\n",
            "iter:  645 train_cost:  0.5433575 train_acc:  0.8515625 test_cost:  0.68925667 test_acc:  0.7890625\n",
            "iter:  646 train_cost:  0.52352726 train_acc:  0.828125 test_cost:  0.6567356 test_acc:  0.796875\n",
            "iter:  647 train_cost:  0.54509187 train_acc:  0.8359375 test_cost:  0.74559397 test_acc:  0.7890625\n",
            "iter:  648 train_cost:  0.66677475 train_acc:  0.765625 test_cost:  0.53363746 test_acc:  0.8671875\n",
            "iter:  649 train_cost:  0.6775961 train_acc:  0.765625 test_cost:  0.5301027 test_acc:  0.828125\n",
            "iter:  650 train_cost:  0.76427525 train_acc:  0.7421875 test_cost:  0.7100727 test_acc:  0.7890625\n",
            "iter:  651 train_cost:  0.6070497 train_acc:  0.828125 test_cost:  0.8654299 test_acc:  0.765625\n",
            "iter:  652 train_cost:  0.61676013 train_acc:  0.8125 test_cost:  0.68599033 test_acc:  0.84375\n",
            "iter:  653 train_cost:  0.65452987 train_acc:  0.7578125 test_cost:  0.6440676 test_acc:  0.828125\n",
            "iter:  654 train_cost:  0.5703769 train_acc:  0.859375 test_cost:  0.79386604 test_acc:  0.78125\n",
            "iter:  655 train_cost:  0.4507699 train_acc:  0.828125 test_cost:  0.47827107 test_acc:  0.8515625\n",
            "iter:  656 train_cost:  0.5017481 train_acc:  0.828125 test_cost:  0.38028216 test_acc:  0.890625\n",
            "iter:  657 train_cost:  0.5113171 train_acc:  0.84375 test_cost:  0.6606113 test_acc:  0.78125\n",
            "iter:  658 train_cost:  0.6185673 train_acc:  0.796875 test_cost:  0.585408 test_acc:  0.8125\n",
            "iter:  659 train_cost:  0.59403294 train_acc:  0.8359375 test_cost:  0.5122587 test_acc:  0.828125\n",
            "iter:  660 train_cost:  0.6431852 train_acc:  0.796875 test_cost:  0.59923446 test_acc:  0.78125\n",
            "iter:  661 train_cost:  0.67754245 train_acc:  0.7578125 test_cost:  0.64035857 test_acc:  0.828125\n",
            "iter:  662 train_cost:  0.5663314 train_acc:  0.8125 test_cost:  0.49764025 test_acc:  0.828125\n",
            "iter:  663 train_cost:  0.4245112 train_acc:  0.875 test_cost:  0.63436776 test_acc:  0.7890625\n",
            "iter:  664 train_cost:  0.6543201 train_acc:  0.796875 test_cost:  0.5336521 test_acc:  0.8125\n",
            "iter:  665 train_cost:  0.45824078 train_acc:  0.84375 test_cost:  0.729192 test_acc:  0.78125\n",
            "iter:  666 train_cost:  0.51736796 train_acc:  0.8515625 test_cost:  0.5509831 test_acc:  0.8359375\n",
            "iter:  667 train_cost:  0.73738486 train_acc:  0.765625 test_cost:  0.65755403 test_acc:  0.7578125\n",
            "iter:  668 train_cost:  0.47683728 train_acc:  0.84375 test_cost:  0.51377285 test_acc:  0.84375\n",
            "iter:  669 train_cost:  0.48516563 train_acc:  0.859375 test_cost:  0.47653198 test_acc:  0.828125\n",
            "iter:  670 train_cost:  0.5564203 train_acc:  0.859375 test_cost:  0.45560712 test_acc:  0.859375\n",
            "iter:  671 train_cost:  0.684332 train_acc:  0.7578125 test_cost:  0.765502 test_acc:  0.75\n",
            "iter:  672 train_cost:  0.567174 train_acc:  0.828125 test_cost:  0.68067145 test_acc:  0.84375\n",
            "iter:  673 train_cost:  0.6185158 train_acc:  0.8515625 test_cost:  0.6674308 test_acc:  0.8046875\n",
            "iter:  674 train_cost:  0.60298574 train_acc:  0.828125 test_cost:  0.60004437 test_acc:  0.8203125\n",
            "iter:  675 train_cost:  0.825622 train_acc:  0.765625 test_cost:  0.4996624 test_acc:  0.828125\n",
            "iter:  676 train_cost:  0.429577 train_acc:  0.84375 test_cost:  0.56490123 test_acc:  0.7578125\n",
            "iter:  677 train_cost:  0.5650462 train_acc:  0.8203125 test_cost:  0.52615106 test_acc:  0.8515625\n",
            "iter:  678 train_cost:  0.3982014 train_acc:  0.8515625 test_cost:  0.7264513 test_acc:  0.8125\n",
            "iter:  679 train_cost:  0.5511223 train_acc:  0.859375 test_cost:  0.48451698 test_acc:  0.8203125\n",
            "iter:  680 train_cost:  0.6038883 train_acc:  0.8046875 test_cost:  0.5501188 test_acc:  0.8515625\n",
            "iter:  681 train_cost:  0.7213577 train_acc:  0.796875 test_cost:  0.5778688 test_acc:  0.8203125\n",
            "iter:  682 train_cost:  0.5898367 train_acc:  0.828125 test_cost:  0.46562368 test_acc:  0.859375\n",
            "iter:  683 train_cost:  0.68384683 train_acc:  0.8203125 test_cost:  0.93643445 test_acc:  0.703125\n",
            "iter:  684 train_cost:  0.6057577 train_acc:  0.8046875 test_cost:  0.6448537 test_acc:  0.8203125\n",
            "iter:  685 train_cost:  0.7198206 train_acc:  0.78125 test_cost:  0.4548128 test_acc:  0.8125\n",
            "iter:  686 train_cost:  0.567299 train_acc:  0.8203125 test_cost:  0.6373253 test_acc:  0.75\n",
            "iter:  687 train_cost:  0.60092986 train_acc:  0.8828125 test_cost:  0.54353935 test_acc:  0.828125\n",
            "iter:  688 train_cost:  0.80846393 train_acc:  0.765625 test_cost:  0.6085251 test_acc:  0.7890625\n",
            "iter:  689 train_cost:  0.69535744 train_acc:  0.8046875 test_cost:  0.48752266 test_acc:  0.8515625\n",
            "iter:  690 train_cost:  0.69524753 train_acc:  0.7421875 test_cost:  0.54581773 test_acc:  0.8515625\n",
            "iter:  691 train_cost:  0.48733747 train_acc:  0.84375 test_cost:  0.53753424 test_acc:  0.8671875\n",
            "iter:  692 train_cost:  0.592058 train_acc:  0.796875 test_cost:  0.45241347 test_acc:  0.8515625\n",
            "iter:  693 train_cost:  0.47717953 train_acc:  0.8046875 test_cost:  0.4924924 test_acc:  0.8359375\n",
            "iter:  694 train_cost:  0.6235594 train_acc:  0.8125 test_cost:  0.5297761 test_acc:  0.84375\n",
            "iter:  695 train_cost:  0.393804 train_acc:  0.8515625 test_cost:  0.574255 test_acc:  0.84375\n",
            "iter:  696 train_cost:  0.69560635 train_acc:  0.78125 test_cost:  0.5266944 test_acc:  0.8203125\n",
            "iter:  697 train_cost:  0.6105478 train_acc:  0.8125 test_cost:  0.6353607 test_acc:  0.7890625\n",
            "iter:  698 train_cost:  0.8143352 train_acc:  0.7421875 test_cost:  0.6145786 test_acc:  0.84375\n",
            "iter:  699 train_cost:  0.62777567 train_acc:  0.78125 test_cost:  0.59714705 test_acc:  0.8046875\n",
            "iter:  700 train_cost:  0.6064142 train_acc:  0.828125 test_cost:  0.8314647 test_acc:  0.75\n",
            "iter:  701 train_cost:  0.59934074 train_acc:  0.8359375 test_cost:  0.46062696 test_acc:  0.8515625\n",
            "iter:  702 train_cost:  0.59921056 train_acc:  0.8359375 test_cost:  0.6321143 test_acc:  0.796875\n",
            "iter:  703 train_cost:  0.418508 train_acc:  0.8671875 test_cost:  0.7025125 test_acc:  0.8046875\n",
            "iter:  704 train_cost:  0.5374761 train_acc:  0.8671875 test_cost:  0.5128437 test_acc:  0.8046875\n",
            "iter:  705 train_cost:  0.45374972 train_acc:  0.859375 test_cost:  0.56185883 test_acc:  0.828125\n",
            "iter:  706 train_cost:  0.48213884 train_acc:  0.8359375 test_cost:  0.5437727 test_acc:  0.8515625\n",
            "iter:  707 train_cost:  0.53544825 train_acc:  0.8359375 test_cost:  0.5348946 test_acc:  0.8203125\n",
            "iter:  708 train_cost:  0.6157466 train_acc:  0.78125 test_cost:  0.6908349 test_acc:  0.7890625\n",
            "iter:  709 train_cost:  0.71188724 train_acc:  0.765625 test_cost:  0.48304254 test_acc:  0.8515625\n",
            "iter:  710 train_cost:  0.53221387 train_acc:  0.828125 test_cost:  0.6753226 test_acc:  0.765625\n",
            "iter:  711 train_cost:  0.6306893 train_acc:  0.7890625 test_cost:  0.5692709 test_acc:  0.8125\n",
            "iter:  712 train_cost:  0.6594409 train_acc:  0.765625 test_cost:  0.48509663 test_acc:  0.8671875\n",
            "iter:  713 train_cost:  0.74468577 train_acc:  0.8046875 test_cost:  0.4397499 test_acc:  0.8828125\n",
            "iter:  714 train_cost:  0.37143415 train_acc:  0.90625 test_cost:  0.39535984 test_acc:  0.8671875\n",
            "iter:  715 train_cost:  0.5101074 train_acc:  0.828125 test_cost:  0.54266346 test_acc:  0.8125\n",
            "iter:  716 train_cost:  0.4876804 train_acc:  0.8125 test_cost:  0.47862494 test_acc:  0.8515625\n",
            "iter:  717 train_cost:  0.5399593 train_acc:  0.796875 test_cost:  0.5439296 test_acc:  0.8671875\n",
            "iter:  718 train_cost:  0.41869953 train_acc:  0.8671875 test_cost:  0.4455247 test_acc:  0.8125\n",
            "iter:  719 train_cost:  0.53399336 train_acc:  0.828125 test_cost:  0.6167886 test_acc:  0.8203125\n",
            "iter:  720 train_cost:  0.6168991 train_acc:  0.8125 test_cost:  0.8346571 test_acc:  0.7734375\n",
            "iter:  721 train_cost:  0.72085166 train_acc:  0.7890625 test_cost:  0.49152452 test_acc:  0.859375\n",
            "iter:  722 train_cost:  0.5083995 train_acc:  0.8671875 test_cost:  0.654134 test_acc:  0.7578125\n",
            "iter:  723 train_cost:  0.40350273 train_acc:  0.859375 test_cost:  0.50433224 test_acc:  0.8359375\n",
            "iter:  724 train_cost:  0.5317378 train_acc:  0.828125 test_cost:  0.61354584 test_acc:  0.7890625\n",
            "iter:  725 train_cost:  0.46271014 train_acc:  0.8359375 test_cost:  0.5222446 test_acc:  0.8515625\n",
            "iter:  726 train_cost:  0.48468024 train_acc:  0.890625 test_cost:  0.53036 test_acc:  0.828125\n",
            "iter:  727 train_cost:  0.7134526 train_acc:  0.8125 test_cost:  0.4526561 test_acc:  0.8671875\n",
            "iter:  728 train_cost:  0.44329834 train_acc:  0.875 test_cost:  0.7295558 test_acc:  0.796875\n",
            "iter:  729 train_cost:  0.5516933 train_acc:  0.84375 test_cost:  0.5848004 test_acc:  0.796875\n",
            "iter:  730 train_cost:  0.51643133 train_acc:  0.8671875 test_cost:  0.5549112 test_acc:  0.8671875\n",
            "iter:  731 train_cost:  0.502034 train_acc:  0.859375 test_cost:  0.64572597 test_acc:  0.8203125\n",
            "iter:  732 train_cost:  0.68473643 train_acc:  0.78125 test_cost:  0.44023645 test_acc:  0.8203125\n",
            "iter:  733 train_cost:  0.5840394 train_acc:  0.828125 test_cost:  0.6134799 test_acc:  0.8125\n",
            "iter:  734 train_cost:  0.32277623 train_acc:  0.890625 test_cost:  0.5725842 test_acc:  0.828125\n",
            "iter:  735 train_cost:  0.54362464 train_acc:  0.8046875 test_cost:  0.6437105 test_acc:  0.8359375\n",
            "iter:  736 train_cost:  0.55802405 train_acc:  0.8125 test_cost:  0.6329516 test_acc:  0.828125\n",
            "iter:  737 train_cost:  0.6123626 train_acc:  0.8203125 test_cost:  0.57469666 test_acc:  0.828125\n",
            "iter:  738 train_cost:  0.7064979 train_acc:  0.78125 test_cost:  0.74050885 test_acc:  0.7890625\n",
            "iter:  739 train_cost:  0.63174874 train_acc:  0.8046875 test_cost:  0.5320546 test_acc:  0.78125\n",
            "iter:  740 train_cost:  0.42155692 train_acc:  0.8671875 test_cost:  0.45739436 test_acc:  0.8515625\n",
            "iter:  741 train_cost:  0.7300596 train_acc:  0.78125 test_cost:  0.47489876 test_acc:  0.8515625\n",
            "iter:  742 train_cost:  0.51545095 train_acc:  0.8203125 test_cost:  0.54480946 test_acc:  0.8046875\n",
            "iter:  743 train_cost:  0.79413265 train_acc:  0.71875 test_cost:  0.69216037 test_acc:  0.8125\n",
            "iter:  744 train_cost:  0.5572041 train_acc:  0.8125 test_cost:  0.4178726 test_acc:  0.8359375\n",
            "iter:  745 train_cost:  0.50444376 train_acc:  0.8671875 test_cost:  0.55806994 test_acc:  0.7890625\n",
            "iter:  746 train_cost:  0.539785 train_acc:  0.8203125 test_cost:  0.56925684 test_acc:  0.796875\n",
            "iter:  747 train_cost:  0.5142069 train_acc:  0.8515625 test_cost:  0.51534444 test_acc:  0.8359375\n",
            "iter:  748 train_cost:  0.5675772 train_acc:  0.8125 test_cost:  0.5191183 test_acc:  0.8671875\n",
            "iter:  749 train_cost:  0.41157383 train_acc:  0.8828125 test_cost:  0.4753715 test_acc:  0.859375\n",
            "iter:  750 train_cost:  0.4662931 train_acc:  0.8828125 test_cost:  0.49510655 test_acc:  0.8671875\n",
            "iter:  751 train_cost:  0.43876517 train_acc:  0.8671875 test_cost:  0.48030847 test_acc:  0.8203125\n",
            "iter:  752 train_cost:  0.5197362 train_acc:  0.84375 test_cost:  0.55374867 test_acc:  0.828125\n",
            "iter:  753 train_cost:  0.5111786 train_acc:  0.8359375 test_cost:  0.64911556 test_acc:  0.8203125\n",
            "iter:  754 train_cost:  0.54009116 train_acc:  0.828125 test_cost:  0.49147663 test_acc:  0.8828125\n",
            "iter:  755 train_cost:  0.42280504 train_acc:  0.859375 test_cost:  0.4621948 test_acc:  0.859375\n",
            "iter:  756 train_cost:  0.53659564 train_acc:  0.8125 test_cost:  0.5571666 test_acc:  0.8125\n",
            "iter:  757 train_cost:  0.49878263 train_acc:  0.859375 test_cost:  0.64095616 test_acc:  0.8515625\n",
            "iter:  758 train_cost:  0.5328304 train_acc:  0.8125 test_cost:  0.3531124 test_acc:  0.890625\n",
            "iter:  759 train_cost:  0.42685124 train_acc:  0.8984375 test_cost:  0.48456442 test_acc:  0.8203125\n",
            "iter:  760 train_cost:  0.6418233 train_acc:  0.8046875 test_cost:  0.5252077 test_acc:  0.8046875\n",
            "iter:  761 train_cost:  0.44530463 train_acc:  0.8515625 test_cost:  0.54267526 test_acc:  0.796875\n",
            "iter:  762 train_cost:  0.7260158 train_acc:  0.7421875 test_cost:  0.5409376 test_acc:  0.8515625\n",
            "iter:  763 train_cost:  0.59052575 train_acc:  0.7890625 test_cost:  0.38418663 test_acc:  0.890625\n",
            "iter:  764 train_cost:  0.6729558 train_acc:  0.8203125 test_cost:  0.5969499 test_acc:  0.8515625\n",
            "iter:  765 train_cost:  0.73290396 train_acc:  0.75 test_cost:  0.5583807 test_acc:  0.859375\n",
            "iter:  766 train_cost:  0.556395 train_acc:  0.8515625 test_cost:  0.5447997 test_acc:  0.84375\n",
            "iter:  767 train_cost:  0.6772176 train_acc:  0.8046875 test_cost:  0.47158998 test_acc:  0.8515625\n",
            "iter:  768 train_cost:  0.54192793 train_acc:  0.828125 test_cost:  0.627616 test_acc:  0.8125\n",
            "iter:  769 train_cost:  0.5524776 train_acc:  0.8515625 test_cost:  0.53533876 test_acc:  0.859375\n",
            "iter:  770 train_cost:  0.4767778 train_acc:  0.8671875 test_cost:  0.52803755 test_acc:  0.8515625\n",
            "iter:  771 train_cost:  0.42760333 train_acc:  0.890625 test_cost:  0.58695924 test_acc:  0.8125\n",
            "iter:  772 train_cost:  0.62705225 train_acc:  0.796875 test_cost:  0.42213702 test_acc:  0.90625\n",
            "iter:  773 train_cost:  0.69684917 train_acc:  0.828125 test_cost:  0.50563145 test_acc:  0.859375\n",
            "iter:  774 train_cost:  0.8850842 train_acc:  0.7734375 test_cost:  0.8062674 test_acc:  0.7734375\n",
            "iter:  775 train_cost:  0.5659559 train_acc:  0.8046875 test_cost:  0.625569 test_acc:  0.8125\n",
            "iter:  776 train_cost:  0.62678313 train_acc:  0.78125 test_cost:  0.62138104 test_acc:  0.8125\n",
            "iter:  777 train_cost:  0.45527834 train_acc:  0.8046875 test_cost:  0.556998 test_acc:  0.84375\n",
            "iter:  778 train_cost:  0.61729634 train_acc:  0.8203125 test_cost:  0.5757278 test_acc:  0.796875\n",
            "iter:  779 train_cost:  0.3823472 train_acc:  0.859375 test_cost:  0.64374447 test_acc:  0.8203125\n",
            "iter:  780 train_cost:  0.5634355 train_acc:  0.8046875 test_cost:  0.5436846 test_acc:  0.8359375\n",
            "iter:  781 train_cost:  0.56774414 train_acc:  0.8359375 test_cost:  0.5021458 test_acc:  0.7890625\n",
            "iter:  782 train_cost:  0.5774999 train_acc:  0.8203125 test_cost:  0.5830024 test_acc:  0.84375\n",
            "iter:  783 train_cost:  0.58409023 train_acc:  0.8671875 test_cost:  0.57528996 test_acc:  0.828125\n",
            "iter:  784 train_cost:  0.7126943 train_acc:  0.8203125 test_cost:  0.4096653 test_acc:  0.8828125\n",
            "iter:  785 train_cost:  0.4390868 train_acc:  0.8515625 test_cost:  0.39293447 test_acc:  0.859375\n",
            "iter:  786 train_cost:  0.5532628 train_acc:  0.8515625 test_cost:  0.6658368 test_acc:  0.7890625\n",
            "iter:  787 train_cost:  0.47983915 train_acc:  0.8515625 test_cost:  0.62078106 test_acc:  0.8359375\n",
            "iter:  788 train_cost:  0.71694225 train_acc:  0.8046875 test_cost:  0.57643867 test_acc:  0.7890625\n",
            "iter:  789 train_cost:  0.4140613 train_acc:  0.8828125 test_cost:  0.55112344 test_acc:  0.8359375\n",
            "iter:  790 train_cost:  0.6411561 train_acc:  0.8046875 test_cost:  0.5283536 test_acc:  0.796875\n",
            "iter:  791 train_cost:  0.46838576 train_acc:  0.8359375 test_cost:  0.4239422 test_acc:  0.8671875\n",
            "iter:  792 train_cost:  0.5227003 train_acc:  0.8515625 test_cost:  0.4375087 test_acc:  0.8828125\n",
            "iter:  793 train_cost:  0.46986017 train_acc:  0.84375 test_cost:  0.49234056 test_acc:  0.8671875\n",
            "iter:  794 train_cost:  0.4231296 train_acc:  0.84375 test_cost:  0.69020563 test_acc:  0.796875\n",
            "iter:  795 train_cost:  0.5967146 train_acc:  0.8203125 test_cost:  0.53981316 test_acc:  0.8203125\n",
            "iter:  796 train_cost:  0.377773 train_acc:  0.8828125 test_cost:  0.5973643 test_acc:  0.78125\n",
            "iter:  797 train_cost:  0.37911972 train_acc:  0.890625 test_cost:  0.52804816 test_acc:  0.8203125\n",
            "iter:  798 train_cost:  0.3598222 train_acc:  0.8984375 test_cost:  0.6439996 test_acc:  0.8203125\n",
            "iter:  799 train_cost:  0.6450866 train_acc:  0.7890625 test_cost:  0.66684556 test_acc:  0.859375\n",
            "iter:  800 train_cost:  0.49573842 train_acc:  0.8671875 test_cost:  0.41789505 test_acc:  0.859375\n",
            "iter:  801 train_cost:  0.66483957 train_acc:  0.84375 test_cost:  0.5818539 test_acc:  0.84375\n",
            "iter:  802 train_cost:  0.5608751 train_acc:  0.828125 test_cost:  0.65595263 test_acc:  0.8125\n",
            "iter:  803 train_cost:  0.46177346 train_acc:  0.890625 test_cost:  0.48220697 test_acc:  0.8671875\n",
            "iter:  804 train_cost:  0.41866082 train_acc:  0.8515625 test_cost:  0.46277356 test_acc:  0.8515625\n",
            "iter:  805 train_cost:  0.60274327 train_acc:  0.7890625 test_cost:  0.7061798 test_acc:  0.7734375\n",
            "iter:  806 train_cost:  0.5094894 train_acc:  0.859375 test_cost:  0.47575706 test_acc:  0.8515625\n",
            "iter:  807 train_cost:  0.65240383 train_acc:  0.796875 test_cost:  0.6273738 test_acc:  0.84375\n",
            "iter:  808 train_cost:  0.6185585 train_acc:  0.796875 test_cost:  0.34551322 test_acc:  0.890625\n",
            "iter:  809 train_cost:  0.5350833 train_acc:  0.8359375 test_cost:  0.5198237 test_acc:  0.8203125\n",
            "iter:  810 train_cost:  0.3922335 train_acc:  0.8671875 test_cost:  0.5834891 test_acc:  0.8046875\n",
            "iter:  811 train_cost:  0.42334282 train_acc:  0.859375 test_cost:  0.47831428 test_acc:  0.875\n",
            "iter:  812 train_cost:  0.6633634 train_acc:  0.8203125 test_cost:  0.67181003 test_acc:  0.8359375\n",
            "iter:  813 train_cost:  0.5455162 train_acc:  0.8203125 test_cost:  0.60577446 test_acc:  0.8203125\n",
            "iter:  814 train_cost:  0.53622603 train_acc:  0.84375 test_cost:  0.48577645 test_acc:  0.8359375\n",
            "iter:  815 train_cost:  0.4325684 train_acc:  0.859375 test_cost:  0.57125056 test_acc:  0.8203125\n",
            "iter:  816 train_cost:  0.64466393 train_acc:  0.796875 test_cost:  0.66923535 test_acc:  0.7890625\n",
            "iter:  817 train_cost:  0.46097636 train_acc:  0.828125 test_cost:  0.48002517 test_acc:  0.859375\n",
            "iter:  818 train_cost:  0.5143448 train_acc:  0.8125 test_cost:  0.53509474 test_acc:  0.8046875\n",
            "iter:  819 train_cost:  0.6033264 train_acc:  0.8046875 test_cost:  0.38611868 test_acc:  0.8828125\n",
            "iter:  820 train_cost:  0.4920407 train_acc:  0.8359375 test_cost:  0.4833424 test_acc:  0.84375\n",
            "iter:  821 train_cost:  0.6416712 train_acc:  0.8125 test_cost:  0.5472574 test_acc:  0.875\n",
            "iter:  822 train_cost:  0.39717707 train_acc:  0.890625 test_cost:  0.46643895 test_acc:  0.8671875\n",
            "iter:  823 train_cost:  0.586303 train_acc:  0.828125 test_cost:  0.40263513 test_acc:  0.8671875\n",
            "iter:  824 train_cost:  0.47528225 train_acc:  0.8828125 test_cost:  0.61472285 test_acc:  0.7734375\n",
            "iter:  825 train_cost:  0.430766 train_acc:  0.875 test_cost:  0.28133392 test_acc:  0.9375\n",
            "iter:  826 train_cost:  0.54861414 train_acc:  0.8046875 test_cost:  0.57592005 test_acc:  0.8515625\n",
            "iter:  827 train_cost:  0.6407996 train_acc:  0.8125 test_cost:  0.5693186 test_acc:  0.8125\n",
            "iter:  828 train_cost:  0.5772399 train_acc:  0.8046875 test_cost:  0.68921554 test_acc:  0.78125\n",
            "iter:  829 train_cost:  0.5417461 train_acc:  0.8125 test_cost:  0.5119424 test_acc:  0.828125\n",
            "iter:  830 train_cost:  0.67030406 train_acc:  0.765625 test_cost:  0.6163947 test_acc:  0.7890625\n",
            "iter:  831 train_cost:  0.34407717 train_acc:  0.890625 test_cost:  0.44853786 test_acc:  0.859375\n",
            "iter:  832 train_cost:  0.5929855 train_acc:  0.796875 test_cost:  0.581708 test_acc:  0.84375\n",
            "iter:  833 train_cost:  0.5428715 train_acc:  0.8515625 test_cost:  0.395446 test_acc:  0.875\n",
            "iter:  834 train_cost:  0.48710406 train_acc:  0.84375 test_cost:  0.56468797 test_acc:  0.84375\n",
            "iter:  835 train_cost:  0.32096335 train_acc:  0.90625 test_cost:  0.589468 test_acc:  0.8359375\n",
            "iter:  836 train_cost:  0.51977223 train_acc:  0.84375 test_cost:  0.30255112 test_acc:  0.90625\n",
            "iter:  837 train_cost:  0.5936905 train_acc:  0.8359375 test_cost:  0.52035743 test_acc:  0.859375\n",
            "iter:  838 train_cost:  0.47872782 train_acc:  0.8984375 test_cost:  0.4123106 test_acc:  0.8515625\n",
            "iter:  839 train_cost:  0.48437145 train_acc:  0.828125 test_cost:  0.6937567 test_acc:  0.796875\n",
            "iter:  840 train_cost:  0.48132238 train_acc:  0.84375 test_cost:  0.54349846 test_acc:  0.828125\n",
            "iter:  841 train_cost:  0.6314218 train_acc:  0.796875 test_cost:  0.6757195 test_acc:  0.84375\n",
            "iter:  842 train_cost:  0.37260097 train_acc:  0.890625 test_cost:  0.4523821 test_acc:  0.859375\n",
            "iter:  843 train_cost:  0.69963264 train_acc:  0.7890625 test_cost:  0.4295302 test_acc:  0.84375\n",
            "iter:  844 train_cost:  0.5812336 train_acc:  0.859375 test_cost:  0.45624146 test_acc:  0.8046875\n",
            "iter:  845 train_cost:  0.3906637 train_acc:  0.890625 test_cost:  0.3900508 test_acc:  0.875\n",
            "iter:  846 train_cost:  0.6130898 train_acc:  0.8203125 test_cost:  0.5208729 test_acc:  0.8515625\n",
            "iter:  847 train_cost:  0.51194495 train_acc:  0.8828125 test_cost:  0.45047268 test_acc:  0.8515625\n",
            "iter:  848 train_cost:  0.51541054 train_acc:  0.8125 test_cost:  0.6005728 test_acc:  0.828125\n",
            "iter:  849 train_cost:  0.6034272 train_acc:  0.828125 test_cost:  0.47030503 test_acc:  0.859375\n",
            "iter:  850 train_cost:  0.40246087 train_acc:  0.875 test_cost:  0.6594653 test_acc:  0.8203125\n",
            "iter:  851 train_cost:  0.6797724 train_acc:  0.7734375 test_cost:  0.43135038 test_acc:  0.8671875\n",
            "iter:  852 train_cost:  0.50256526 train_acc:  0.8203125 test_cost:  0.586107 test_acc:  0.828125\n",
            "iter:  853 train_cost:  0.45573622 train_acc:  0.84375 test_cost:  0.454136 test_acc:  0.8515625\n",
            "iter:  854 train_cost:  0.4403457 train_acc:  0.8359375 test_cost:  0.36513865 test_acc:  0.875\n",
            "iter:  855 train_cost:  0.50819844 train_acc:  0.8515625 test_cost:  0.51382643 test_acc:  0.8515625\n",
            "iter:  856 train_cost:  0.429231 train_acc:  0.890625 test_cost:  0.39467946 test_acc:  0.8671875\n",
            "iter:  857 train_cost:  0.41463804 train_acc:  0.859375 test_cost:  0.46584687 test_acc:  0.875\n",
            "iter:  858 train_cost:  0.7813669 train_acc:  0.7265625 test_cost:  0.47023335 test_acc:  0.8359375\n",
            "iter:  859 train_cost:  0.50950116 train_acc:  0.84375 test_cost:  0.63693583 test_acc:  0.765625\n",
            "iter:  860 train_cost:  0.48469758 train_acc:  0.8359375 test_cost:  0.5891953 test_acc:  0.8125\n",
            "iter:  861 train_cost:  0.35744268 train_acc:  0.890625 test_cost:  0.54300964 test_acc:  0.84375\n",
            "iter:  862 train_cost:  0.37712538 train_acc:  0.8828125 test_cost:  0.4868038 test_acc:  0.859375\n",
            "iter:  863 train_cost:  0.65192246 train_acc:  0.765625 test_cost:  0.5913484 test_acc:  0.8046875\n",
            "iter:  864 train_cost:  0.41089362 train_acc:  0.8984375 test_cost:  0.5538534 test_acc:  0.875\n",
            "iter:  865 train_cost:  0.41806835 train_acc:  0.8828125 test_cost:  0.6796038 test_acc:  0.8125\n",
            "iter:  866 train_cost:  0.47887152 train_acc:  0.8515625 test_cost:  0.54168266 test_acc:  0.8046875\n",
            "iter:  867 train_cost:  0.3746765 train_acc:  0.875 test_cost:  0.39085963 test_acc:  0.859375\n",
            "iter:  868 train_cost:  0.604265 train_acc:  0.8203125 test_cost:  0.5283989 test_acc:  0.8671875\n",
            "iter:  869 train_cost:  0.43621403 train_acc:  0.8515625 test_cost:  0.5158305 test_acc:  0.859375\n",
            "iter:  870 train_cost:  0.45640188 train_acc:  0.859375 test_cost:  0.4269598 test_acc:  0.8984375\n",
            "iter:  871 train_cost:  0.33878595 train_acc:  0.9140625 test_cost:  0.45045465 test_acc:  0.8671875\n",
            "iter:  872 train_cost:  0.39474693 train_acc:  0.890625 test_cost:  0.38868257 test_acc:  0.8671875\n",
            "iter:  873 train_cost:  0.44482604 train_acc:  0.875 test_cost:  0.45426732 test_acc:  0.8515625\n",
            "iter:  874 train_cost:  0.5839501 train_acc:  0.8359375 test_cost:  0.6123299 test_acc:  0.859375\n",
            "iter:  875 train_cost:  0.4571707 train_acc:  0.8671875 test_cost:  0.34220576 test_acc:  0.9140625\n",
            "iter:  876 train_cost:  0.36760888 train_acc:  0.8828125 test_cost:  0.4193916 test_acc:  0.84375\n",
            "iter:  877 train_cost:  0.4131549 train_acc:  0.90625 test_cost:  0.47762436 test_acc:  0.8515625\n",
            "iter:  878 train_cost:  0.42555198 train_acc:  0.859375 test_cost:  0.5275004 test_acc:  0.859375\n",
            "iter:  879 train_cost:  0.5366859 train_acc:  0.828125 test_cost:  0.41859493 test_acc:  0.8828125\n",
            "iter:  880 train_cost:  0.5414238 train_acc:  0.859375 test_cost:  0.4907198 test_acc:  0.84375\n",
            "iter:  881 train_cost:  0.6063468 train_acc:  0.8046875 test_cost:  0.6641439 test_acc:  0.796875\n",
            "iter:  882 train_cost:  0.51607114 train_acc:  0.8359375 test_cost:  0.57719254 test_acc:  0.8203125\n",
            "iter:  883 train_cost:  0.5479922 train_acc:  0.8515625 test_cost:  0.38034594 test_acc:  0.890625\n",
            "iter:  884 train_cost:  0.4201969 train_acc:  0.859375 test_cost:  0.54820716 test_acc:  0.8359375\n",
            "iter:  885 train_cost:  0.5814387 train_acc:  0.8046875 test_cost:  0.46877587 test_acc:  0.84375\n",
            "iter:  886 train_cost:  0.56964815 train_acc:  0.8203125 test_cost:  0.4889753 test_acc:  0.8203125\n",
            "iter:  887 train_cost:  0.5444093 train_acc:  0.828125 test_cost:  0.5196802 test_acc:  0.8515625\n",
            "iter:  888 train_cost:  0.4494694 train_acc:  0.8515625 test_cost:  0.66089636 test_acc:  0.8203125\n",
            "iter:  889 train_cost:  0.68301237 train_acc:  0.8203125 test_cost:  0.68001497 test_acc:  0.7734375\n",
            "iter:  890 train_cost:  0.59904903 train_acc:  0.8203125 test_cost:  0.51386935 test_acc:  0.828125\n",
            "iter:  891 train_cost:  0.36067072 train_acc:  0.890625 test_cost:  0.41514248 test_acc:  0.8671875\n",
            "iter:  892 train_cost:  0.49008194 train_acc:  0.8671875 test_cost:  0.23966138 test_acc:  0.9296875\n",
            "iter:  893 train_cost:  0.34265143 train_acc:  0.8984375 test_cost:  0.5329007 test_acc:  0.8515625\n",
            "iter:  894 train_cost:  0.46586847 train_acc:  0.84375 test_cost:  0.4666537 test_acc:  0.84375\n",
            "iter:  895 train_cost:  0.3043984 train_acc:  0.921875 test_cost:  0.45229763 test_acc:  0.8515625\n",
            "iter:  896 train_cost:  0.6311835 train_acc:  0.8359375 test_cost:  0.4446084 test_acc:  0.84375\n",
            "iter:  897 train_cost:  0.33903304 train_acc:  0.8671875 test_cost:  0.48049015 test_acc:  0.859375\n",
            "iter:  898 train_cost:  0.5630979 train_acc:  0.8203125 test_cost:  0.4649151 test_acc:  0.84375\n",
            "iter:  899 train_cost:  0.37415606 train_acc:  0.8515625 test_cost:  0.4413079 test_acc:  0.890625\n",
            "iter:  900 train_cost:  0.354312 train_acc:  0.8828125 test_cost:  0.44160447 test_acc:  0.875\n",
            "iter:  901 train_cost:  0.3748586 train_acc:  0.890625 test_cost:  0.52597934 test_acc:  0.875\n",
            "iter:  902 train_cost:  0.4101435 train_acc:  0.8671875 test_cost:  0.47701716 test_acc:  0.84375\n",
            "iter:  903 train_cost:  0.6320678 train_acc:  0.8046875 test_cost:  0.55923194 test_acc:  0.84375\n",
            "iter:  904 train_cost:  0.28297168 train_acc:  0.921875 test_cost:  0.5874814 test_acc:  0.7890625\n",
            "iter:  905 train_cost:  0.45291004 train_acc:  0.8828125 test_cost:  0.61452466 test_acc:  0.8125\n",
            "iter:  906 train_cost:  0.50898474 train_acc:  0.84375 test_cost:  0.49766028 test_acc:  0.859375\n",
            "iter:  907 train_cost:  0.4981894 train_acc:  0.8515625 test_cost:  0.478155 test_acc:  0.84375\n",
            "iter:  908 train_cost:  0.52795 train_acc:  0.8671875 test_cost:  0.45354837 test_acc:  0.828125\n",
            "iter:  909 train_cost:  0.41676468 train_acc:  0.875 test_cost:  0.6324403 test_acc:  0.8125\n",
            "iter:  910 train_cost:  0.5189202 train_acc:  0.84375 test_cost:  0.53402686 test_acc:  0.84375\n",
            "iter:  911 train_cost:  0.45653462 train_acc:  0.8671875 test_cost:  0.50438094 test_acc:  0.8046875\n",
            "iter:  912 train_cost:  0.3794278 train_acc:  0.8671875 test_cost:  0.46913496 test_acc:  0.828125\n",
            "iter:  913 train_cost:  0.33135927 train_acc:  0.90625 test_cost:  0.43624777 test_acc:  0.7890625\n",
            "iter:  914 train_cost:  0.5043936 train_acc:  0.8515625 test_cost:  0.5337859 test_acc:  0.84375\n",
            "iter:  915 train_cost:  0.4448859 train_acc:  0.890625 test_cost:  0.6060934 test_acc:  0.8046875\n",
            "iter:  916 train_cost:  0.5053631 train_acc:  0.859375 test_cost:  0.6237598 test_acc:  0.828125\n",
            "iter:  917 train_cost:  0.3992582 train_acc:  0.8671875 test_cost:  0.565871 test_acc:  0.8203125\n",
            "iter:  918 train_cost:  0.47724578 train_acc:  0.8125 test_cost:  0.46833354 test_acc:  0.8671875\n",
            "iter:  919 train_cost:  0.43793428 train_acc:  0.875 test_cost:  0.5473305 test_acc:  0.859375\n",
            "iter:  920 train_cost:  0.4679406 train_acc:  0.8671875 test_cost:  0.35602313 test_acc:  0.90625\n",
            "iter:  921 train_cost:  0.5053977 train_acc:  0.8359375 test_cost:  0.5344487 test_acc:  0.84375\n",
            "iter:  922 train_cost:  0.5336891 train_acc:  0.8515625 test_cost:  0.4861974 test_acc:  0.859375\n",
            "iter:  923 train_cost:  0.37869692 train_acc:  0.875 test_cost:  0.4754417 test_acc:  0.875\n",
            "iter:  924 train_cost:  0.2806001 train_acc:  0.921875 test_cost:  0.39591926 test_acc:  0.875\n",
            "iter:  925 train_cost:  0.38072082 train_acc:  0.8828125 test_cost:  0.52646595 test_acc:  0.875\n",
            "iter:  926 train_cost:  0.4921435 train_acc:  0.84375 test_cost:  0.42225853 test_acc:  0.8359375\n",
            "iter:  927 train_cost:  0.51747596 train_acc:  0.8203125 test_cost:  0.4716879 test_acc:  0.875\n",
            "iter:  928 train_cost:  0.40962952 train_acc:  0.8515625 test_cost:  0.35062122 test_acc:  0.8984375\n",
            "iter:  929 train_cost:  0.64339995 train_acc:  0.828125 test_cost:  0.5559457 test_acc:  0.8671875\n",
            "iter:  930 train_cost:  0.41913354 train_acc:  0.8671875 test_cost:  0.39827985 test_acc:  0.8515625\n",
            "iter:  931 train_cost:  0.6140093 train_acc:  0.8203125 test_cost:  0.5703449 test_acc:  0.796875\n",
            "iter:  932 train_cost:  0.5352118 train_acc:  0.8671875 test_cost:  0.58035815 test_acc:  0.8359375\n",
            "iter:  933 train_cost:  0.49769908 train_acc:  0.8125 test_cost:  0.55844057 test_acc:  0.8359375\n",
            "iter:  934 train_cost:  0.45129567 train_acc:  0.890625 test_cost:  0.5504074 test_acc:  0.828125\n",
            "iter:  935 train_cost:  0.41370064 train_acc:  0.8671875 test_cost:  0.43798435 test_acc:  0.8828125\n",
            "iter:  936 train_cost:  0.3919118 train_acc:  0.859375 test_cost:  0.34409377 test_acc:  0.875\n",
            "iter:  937 train_cost:  0.42118335 train_acc:  0.8671875 test_cost:  0.42501956 test_acc:  0.8515625\n",
            "iter:  938 train_cost:  0.40752852 train_acc:  0.875 test_cost:  0.7191456 test_acc:  0.796875\n",
            "iter:  939 train_cost:  0.498844 train_acc:  0.84375 test_cost:  0.44661838 test_acc:  0.859375\n",
            "iter:  940 train_cost:  0.5299422 train_acc:  0.7890625 test_cost:  0.5653467 test_acc:  0.859375\n",
            "iter:  941 train_cost:  0.4826524 train_acc:  0.8671875 test_cost:  0.44736072 test_acc:  0.8671875\n",
            "iter:  942 train_cost:  0.47831994 train_acc:  0.859375 test_cost:  0.5809854 test_acc:  0.8515625\n",
            "iter:  943 train_cost:  0.38087803 train_acc:  0.8828125 test_cost:  0.5493587 test_acc:  0.84375\n",
            "iter:  944 train_cost:  0.4967783 train_acc:  0.8671875 test_cost:  0.43377802 test_acc:  0.8359375\n",
            "iter:  945 train_cost:  0.4318192 train_acc:  0.890625 test_cost:  0.5186434 test_acc:  0.8359375\n",
            "iter:  946 train_cost:  0.45325425 train_acc:  0.8359375 test_cost:  0.6387819 test_acc:  0.796875\n",
            "iter:  947 train_cost:  0.6738281 train_acc:  0.8203125 test_cost:  0.5618294 test_acc:  0.8359375\n",
            "iter:  948 train_cost:  0.4499876 train_acc:  0.8828125 test_cost:  0.43526152 test_acc:  0.890625\n",
            "iter:  949 train_cost:  0.40400413 train_acc:  0.859375 test_cost:  0.4618496 test_acc:  0.8515625\n",
            "iter:  950 train_cost:  0.61015403 train_acc:  0.7734375 test_cost:  0.5679733 test_acc:  0.828125\n",
            "iter:  951 train_cost:  0.35718942 train_acc:  0.890625 test_cost:  0.45712844 test_acc:  0.84375\n",
            "iter:  952 train_cost:  0.37794018 train_acc:  0.8828125 test_cost:  0.51869166 test_acc:  0.8046875\n",
            "iter:  953 train_cost:  0.37429306 train_acc:  0.8671875 test_cost:  0.5048909 test_acc:  0.875\n",
            "iter:  954 train_cost:  0.5142972 train_acc:  0.859375 test_cost:  0.3734789 test_acc:  0.8671875\n",
            "iter:  955 train_cost:  0.3434323 train_acc:  0.859375 test_cost:  0.5566969 test_acc:  0.8671875\n",
            "iter:  956 train_cost:  0.35905272 train_acc:  0.9140625 test_cost:  0.4159452 test_acc:  0.890625\n",
            "iter:  957 train_cost:  0.39153463 train_acc:  0.90625 test_cost:  0.6393065 test_acc:  0.7890625\n",
            "iter:  958 train_cost:  0.5293751 train_acc:  0.8125 test_cost:  0.3383326 test_acc:  0.8671875\n",
            "iter:  959 train_cost:  0.45517206 train_acc:  0.8828125 test_cost:  0.47833169 test_acc:  0.8671875\n",
            "iter:  960 train_cost:  0.49903804 train_acc:  0.8359375 test_cost:  0.592134 test_acc:  0.8125\n",
            "iter:  961 train_cost:  0.5007568 train_acc:  0.8359375 test_cost:  0.50103754 test_acc:  0.8515625\n",
            "iter:  962 train_cost:  0.6194508 train_acc:  0.8125 test_cost:  0.5512009 test_acc:  0.8125\n",
            "iter:  963 train_cost:  0.31433162 train_acc:  0.8984375 test_cost:  0.4225807 test_acc:  0.8671875\n",
            "iter:  964 train_cost:  0.4455052 train_acc:  0.859375 test_cost:  0.41189775 test_acc:  0.8828125\n",
            "iter:  965 train_cost:  0.48344132 train_acc:  0.8984375 test_cost:  0.3742192 test_acc:  0.8671875\n",
            "iter:  966 train_cost:  0.54023886 train_acc:  0.84375 test_cost:  0.26540673 test_acc:  0.9140625\n",
            "iter:  967 train_cost:  0.6216496 train_acc:  0.8515625 test_cost:  0.6845303 test_acc:  0.796875\n",
            "iter:  968 train_cost:  0.34776092 train_acc:  0.890625 test_cost:  0.4330652 test_acc:  0.890625\n",
            "iter:  969 train_cost:  0.54208916 train_acc:  0.859375 test_cost:  0.47364366 test_acc:  0.84375\n",
            "iter:  970 train_cost:  0.28688738 train_acc:  0.9140625 test_cost:  0.52701247 test_acc:  0.8515625\n",
            "iter:  971 train_cost:  0.520158 train_acc:  0.859375 test_cost:  0.39061502 test_acc:  0.8828125\n",
            "iter:  972 train_cost:  0.45319492 train_acc:  0.859375 test_cost:  0.5400159 test_acc:  0.8203125\n",
            "iter:  973 train_cost:  0.46409068 train_acc:  0.796875 test_cost:  0.35086787 test_acc:  0.875\n",
            "iter:  974 train_cost:  0.37090337 train_acc:  0.875 test_cost:  0.4007727 test_acc:  0.8203125\n",
            "iter:  975 train_cost:  0.5630233 train_acc:  0.8046875 test_cost:  0.5094882 test_acc:  0.8359375\n",
            "iter:  976 train_cost:  0.4419906 train_acc:  0.890625 test_cost:  0.49271393 test_acc:  0.8203125\n",
            "iter:  977 train_cost:  0.564302 train_acc:  0.8203125 test_cost:  0.5219374 test_acc:  0.8359375\n",
            "iter:  978 train_cost:  0.4271442 train_acc:  0.84375 test_cost:  0.5570934 test_acc:  0.8515625\n",
            "iter:  979 train_cost:  0.50551116 train_acc:  0.859375 test_cost:  0.465054 test_acc:  0.8984375\n",
            "iter:  980 train_cost:  0.37108344 train_acc:  0.8828125 test_cost:  0.5131999 test_acc:  0.84375\n",
            "iter:  981 train_cost:  0.54691994 train_acc:  0.859375 test_cost:  0.34088734 test_acc:  0.8984375\n",
            "iter:  982 train_cost:  0.42145884 train_acc:  0.8515625 test_cost:  0.34574002 test_acc:  0.8984375\n",
            "iter:  983 train_cost:  0.44009498 train_acc:  0.859375 test_cost:  0.47128642 test_acc:  0.828125\n",
            "iter:  984 train_cost:  0.34609097 train_acc:  0.8828125 test_cost:  0.4905197 test_acc:  0.8671875\n",
            "iter:  985 train_cost:  0.43171152 train_acc:  0.8515625 test_cost:  0.41991296 test_acc:  0.84375\n",
            "iter:  986 train_cost:  0.51161975 train_acc:  0.859375 test_cost:  0.4125644 test_acc:  0.8828125\n",
            "iter:  987 train_cost:  0.46974254 train_acc:  0.8359375 test_cost:  0.5616805 test_acc:  0.796875\n",
            "iter:  988 train_cost:  0.4786353 train_acc:  0.8359375 test_cost:  0.36095947 test_acc:  0.8984375\n",
            "iter:  989 train_cost:  0.5151853 train_acc:  0.8046875 test_cost:  0.48605725 test_acc:  0.8359375\n",
            "iter:  990 train_cost:  0.38963923 train_acc:  0.875 test_cost:  0.4625904 test_acc:  0.84375\n",
            "iter:  991 train_cost:  0.40425864 train_acc:  0.859375 test_cost:  0.34406698 test_acc:  0.875\n",
            "iter:  992 train_cost:  0.563857 train_acc:  0.875 test_cost:  0.4735574 test_acc:  0.859375\n",
            "iter:  993 train_cost:  0.49132144 train_acc:  0.859375 test_cost:  0.36335042 test_acc:  0.890625\n",
            "iter:  994 train_cost:  0.5204402 train_acc:  0.859375 test_cost:  0.56843334 test_acc:  0.828125\n",
            "iter:  995 train_cost:  0.4952531 train_acc:  0.8359375 test_cost:  0.5785105 test_acc:  0.8515625\n",
            "iter:  996 train_cost:  0.43117756 train_acc:  0.8671875 test_cost:  0.53969043 test_acc:  0.8359375\n",
            "iter:  997 train_cost:  0.56948555 train_acc:  0.8203125 test_cost:  0.5583036 test_acc:  0.8046875\n",
            "iter:  998 train_cost:  0.42589295 train_acc:  0.8828125 test_cost:  0.620445 test_acc:  0.8125\n",
            "iter:  999 train_cost:  0.49115783 train_acc:  0.8359375 test_cost:  0.573193 test_acc:  0.8359375\n",
            "predicted  [[-1.4919202   0.38283062 -1.5497861  -0.15626955]\n",
            " [-1.3259544   0.60907865 -1.5930572  -0.252061  ]\n",
            " [-1.247788    0.70527196 -1.489849   -0.3477499 ]\n",
            " [-1.4623036   0.43893695 -1.6066997  -0.09167194]\n",
            " [-1.5935884   0.25709915 -1.626489   -0.02989376]\n",
            " [-1.4328773   0.45810473 -1.6380787  -0.16775507]\n",
            " [-1.4195874   0.48865938 -1.5655887  -0.16022992]\n",
            " [-1.2597828   0.6980649  -1.4336175  -0.32392412]\n",
            " [-1.5418792   0.31674945 -1.5989667  -0.13016367]\n",
            " [-1.5261164   0.3332094  -1.6442894  -0.13378221]]\n",
            "real  [[0.44816967 0.95323041 0.92308431 0.45319102]\n",
            " [0.41139221 0.2277632  0.24681174 0.23609451]\n",
            " [0.2042083  0.57847823 0.03928661 0.94865285]\n",
            " [0.47307747 0.05994807 0.53579507 0.49042075]\n",
            " [0.88135933 0.12772282 0.75207799 0.33202756]\n",
            " [0.36213796 0.14729383 0.06494912 0.75216967]\n",
            " [0.410895   0.88877659 0.61005907 0.52787836]\n",
            " [0.5982433  0.19543923 0.13278063 0.53665965]\n",
            " [0.99420464 0.0267975  0.82890853 0.61832711]\n",
            " [0.07596289 0.55581537 0.00169039 0.07832236]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}