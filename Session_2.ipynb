{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadhajmosa/Machine-learning-labs/blob/Anna/Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSUExzC-ZBV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWZldyi-Zef",
        "colab_type": "text"
      },
      "source": [
        "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
        "## Session 1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75NLOuwKXSs",
        "colab_type": "text"
      },
      "source": [
        "#Session 2: 05.06 - 13:00 - 14:30 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUtGM-W_ehP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Intro:\n",
        "\n",
        "Tensorflow is a powerful framework for implementing and deploying large-scale deep learning models. Recently, it has been widely used in both reasearch and production. TF objective is to combine scale and flexibility.\n",
        "\n",
        "In the past session, we will learning the following:\n",
        "\n",
        "1. TF programming stack\n",
        "2. TF programming concepts including computatoin graphs, operations and sessions. \n",
        "3. Implementation of linear regression\n",
        "4. Implementation of feed-forward neural networks\n",
        "\n",
        "## TF stack:\n",
        "\n",
        "TensorFlow is a framework composed of two core building blocks — a library for defining computational graphs and a runtime for executing such graphs on a variety of different hardware\n",
        "\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/layers.png)\n",
        "\n",
        "\n",
        "Before goining into details about the stack, let us talk about computational graphs.\n",
        "\n",
        "### Computational Graphs\n",
        "\n",
        "A directed graph is a data structure consisting of nodes (vertices) and edges. It’s a set of vertices connected pairwise by directed edges.\n",
        "\n",
        "Graphs come in many shapes and sizes and are used to solve many real-life problems, such as representing networks including telephone networks, circuit networks, road networks, and even social networks. \n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*V6aYjD3AxDbEKYahkGqVQw.png)\n",
        "\n",
        "TensorFlow uses directed graphs internally to represent computations, and they call this data flow graphs (or computational graphs).\n",
        "\n",
        "The nodes in TF data flow graph mostly represents operations, variables and placeholders.\n",
        "\n",
        "Take for example the following operation:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "\n",
        "To create a computational graph out of this program, we create nodes for each of the operations in our program, along with the input variables a and b. In fact, a and b could be constants if they don’t change. If one node is used as the input to another operation we draw a directed arrow that goes from one node to another.\n",
        "\n",
        "The computational graph for this program might look like this:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*vPb9E0Yd1QUAD0oFmAgaOw.png)\n",
        "\n",
        "Operations create or manipulate data according to specific rules. In TensorFlow those rules are called Ops, short for operations. Variables on the other hand represent shared, persistent state that can be manipulated by running Ops on those variables.\n",
        "\n",
        "The questions now what are the advantages of representing operations as directed graphs: The main advantage of using directed graphs is the ability to do **parallelism** and what is called **dependency driving scheduling**. \n",
        "For example, consider again the follwoing code:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "At the most fundamental level, most computer programs are mainly composed of two things — primitive operations and an order in which these operations are executed, often sequentially, line by line. This means we would first multiply a and b and only when this expression was evaluated we would take their sum. Computational graphs on the otherhand, exclusively specify the dependencies across the operations.\n",
        "If we look at our computational graph we see that we could execute the multiplication and addition in parallel. That’s because these two operations do not depend on each other.\n",
        " So we can use the topology of the graph to drive the scheduling of operations and execute them in the most efficient manner, e.g. using multiple GPUs on a single machine or even distribute the execution across multiple machines.\n",
        " Another key advantage is portability. The graph is a language-independent representation of our code. So we can build the graph in Python, save the model (TensorFlow uses protocol buffers), and restore the model in a different language, say C++, if you want to go really fast.\n",
        " \n",
        " \n",
        "\n",
        "--------------------------------\n",
        "# References:\n",
        "\n",
        "https://medium.com/@d3lm/understand-tensorflow-by-mimicking-its-api-from-scratch-faa55787170d\n",
        "\n",
        "https://www.tensorflow.org/guide/extend/architecture\n",
        "\n",
        "https://www.tensorflow.org/guide/low_level_intro\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLbVW-Adoko2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2129
        },
        "outputId": "271073f4-d469-47ad-831c-3bac94429964"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "num_inputs = 3\n",
        "num_outputs = 4\n",
        "\n",
        "num_samples = 10\n",
        "\n",
        "# Training data\n",
        "x_gr = np.random.rand(num_samples, num_inputs)\n",
        "y_gr = np.random.rand(num_samples, num_outputs)\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "# weights\n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs, num_outputs]))\n",
        "\n",
        "# model\n",
        "y_p = tf.matmul(x, w_1)\n",
        "\n",
        "# cost\n",
        "cost = tf.reduce_mean(tf.pow(y - y_p, 2)) # mse fisrt take then minimize\n",
        "\n",
        "# optimization\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "\n",
        "# initialize the graph\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  \n",
        "  for i in range(100):\n",
        "    \n",
        "    sess.run(optimizer, feed_dict={x: x_gr, y: y_gr})\n",
        "    pr_cost = sess.run(cost, feed_dict={x: x_gr, y: y_gr})\n",
        "    print('iter', i, 'cost: ', pr_cost)\n",
        "  \n",
        "  y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "  print('predcited', y_p_p)\n",
        "  print('real ', y_gr)\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0 cost:  0.61198723\n",
            "iter 1 cost:  0.6100459\n",
            "iter 2 cost:  0.6081093\n",
            "iter 3 cost:  0.6061774\n",
            "iter 4 cost:  0.60425043\n",
            "iter 5 cost:  0.60232836\n",
            "iter 6 cost:  0.60041124\n",
            "iter 7 cost:  0.59849924\n",
            "iter 8 cost:  0.5965924\n",
            "iter 9 cost:  0.5946908\n",
            "iter 10 cost:  0.5927944\n",
            "iter 11 cost:  0.5909034\n",
            "iter 12 cost:  0.58901787\n",
            "iter 13 cost:  0.5871377\n",
            "iter 14 cost:  0.5852631\n",
            "iter 15 cost:  0.58339405\n",
            "iter 16 cost:  0.5815306\n",
            "iter 17 cost:  0.5796728\n",
            "iter 18 cost:  0.5778208\n",
            "iter 19 cost:  0.5759746\n",
            "iter 20 cost:  0.57413405\n",
            "iter 21 cost:  0.57229936\n",
            "iter 22 cost:  0.57047063\n",
            "iter 23 cost:  0.56864774\n",
            "iter 24 cost:  0.5668308\n",
            "iter 25 cost:  0.5650198\n",
            "iter 26 cost:  0.5632149\n",
            "iter 27 cost:  0.5614159\n",
            "iter 28 cost:  0.55962306\n",
            "iter 29 cost:  0.55783606\n",
            "iter 30 cost:  0.55605525\n",
            "iter 31 cost:  0.5542805\n",
            "iter 32 cost:  0.55251193\n",
            "iter 33 cost:  0.5507494\n",
            "iter 34 cost:  0.548993\n",
            "iter 35 cost:  0.5472427\n",
            "iter 36 cost:  0.54549855\n",
            "iter 37 cost:  0.54376054\n",
            "iter 38 cost:  0.5420287\n",
            "iter 39 cost:  0.54030293\n",
            "iter 40 cost:  0.5385834\n",
            "iter 41 cost:  0.53686994\n",
            "iter 42 cost:  0.53516257\n",
            "iter 43 cost:  0.53346145\n",
            "iter 44 cost:  0.5317663\n",
            "iter 45 cost:  0.5300775\n",
            "iter 46 cost:  0.52839464\n",
            "iter 47 cost:  0.526718\n",
            "iter 48 cost:  0.5250474\n",
            "iter 49 cost:  0.52338284\n",
            "iter 50 cost:  0.52172446\n",
            "iter 51 cost:  0.5200721\n",
            "iter 52 cost:  0.5184258\n",
            "iter 53 cost:  0.5167856\n",
            "iter 54 cost:  0.51515144\n",
            "iter 55 cost:  0.5135233\n",
            "iter 56 cost:  0.51190114\n",
            "iter 57 cost:  0.51028496\n",
            "iter 58 cost:  0.5086748\n",
            "iter 59 cost:  0.5070706\n",
            "iter 60 cost:  0.50547236\n",
            "iter 61 cost:  0.5038801\n",
            "iter 62 cost:  0.50229377\n",
            "iter 63 cost:  0.5007132\n",
            "iter 64 cost:  0.49913874\n",
            "iter 65 cost:  0.4975701\n",
            "iter 66 cost:  0.4960073\n",
            "iter 67 cost:  0.49445042\n",
            "iter 68 cost:  0.49289933\n",
            "iter 69 cost:  0.491354\n",
            "iter 70 cost:  0.48981446\n",
            "iter 71 cost:  0.48828077\n",
            "iter 72 cost:  0.4867529\n",
            "iter 73 cost:  0.48523074\n",
            "iter 74 cost:  0.48371428\n",
            "iter 75 cost:  0.48220366\n",
            "iter 76 cost:  0.4806986\n",
            "iter 77 cost:  0.47919932\n",
            "iter 78 cost:  0.47770566\n",
            "iter 79 cost:  0.47621775\n",
            "iter 80 cost:  0.47473535\n",
            "iter 81 cost:  0.47325858\n",
            "iter 82 cost:  0.47178745\n",
            "iter 83 cost:  0.4703219\n",
            "iter 84 cost:  0.4688619\n",
            "iter 85 cost:  0.46740746\n",
            "iter 86 cost:  0.46595854\n",
            "iter 87 cost:  0.46451515\n",
            "iter 88 cost:  0.46307725\n",
            "iter 89 cost:  0.46164483\n",
            "iter 90 cost:  0.4602179\n",
            "iter 91 cost:  0.4587964\n",
            "iter 92 cost:  0.4573803\n",
            "iter 93 cost:  0.45596963\n",
            "iter 94 cost:  0.4545644\n",
            "iter 95 cost:  0.4531645\n",
            "iter 96 cost:  0.4517699\n",
            "iter 97 cost:  0.45038065\n",
            "iter 98 cost:  0.44899672\n",
            "iter 99 cost:  0.4476182\n",
            "predcited [[ 1.0642519  -0.10797907  0.63572466  0.6151705 ]\n",
            " [ 0.95057315 -0.05558784  0.4162824   0.2345316 ]\n",
            " [ 1.0715606  -0.21512848  0.48644888  0.8601454 ]\n",
            " [ 1.1371416   0.03873086  0.66152763  0.05474167]\n",
            " [ 1.719374    0.12379417  1.0996888  -0.05926034]\n",
            " [ 1.1694103  -0.08052979  0.8283477   0.6687256 ]\n",
            " [ 1.6303971  -0.06164222  0.9624437   0.537149  ]\n",
            " [ 1.4713259   0.12522149  0.83886063 -0.23176065]\n",
            " [ 0.8430602   0.12343843  0.6315912  -0.16910896]\n",
            " [ 2.14538    -0.02084586  1.2198906   0.4293001 ]]\n",
            "real  [[0.57394809 0.29101067 0.69905395 0.86220391]\n",
            " [0.02324423 0.22720175 0.75477321 0.58486926]\n",
            " [0.23815138 0.29457941 0.67673838 0.56579858]\n",
            " [0.62120126 0.78150879 0.65749981 0.1883166 ]\n",
            " [0.17328817 0.38847752 0.88352496 0.23752996]\n",
            " [0.91517876 0.97690852 0.96999503 0.09917936]\n",
            " [0.95635655 0.26766364 0.50175673 0.70247451]\n",
            " [0.41062677 0.15770593 0.06247677 0.74438781]\n",
            " [0.57134897 0.28954091 0.35324078 0.80823561]\n",
            " [0.13459438 0.80272035 0.31297211 0.17406621]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXbymsudvVj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "e2663868-11d5-4f39-e7c2-10cc8ee9c557"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for i in range(10):\n",
        "    sess.run(optimizer, feed_dict={x: x_gr, y: y_gr})\n",
        "    pr_cost = sess.run(cost, feed_dict={x: x_gr, y: y_gr})\n",
        "    print('iter', i, 'cost: ', pr_cost)\n",
        "    \n",
        "y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "print('predcited', y_p_p)\n",
        "print('real ', y_gr)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0 cost:  0.4302662\n",
            "iter 1 cost:  0.42903796\n",
            "iter 2 cost:  0.42781314\n",
            "iter 3 cost:  0.42659205\n",
            "iter 4 cost:  0.4253745\n",
            "iter 5 cost:  0.42416057\n",
            "iter 6 cost:  0.42295036\n",
            "iter 7 cost:  0.4217438\n",
            "iter 8 cost:  0.4205409\n",
            "iter 9 cost:  0.4193418\n",
            "predcited [[ 0.55518985  0.76716846  1.2293353   0.26625723]\n",
            " [ 0.23008093  0.25880137  0.93389106  0.42814687]\n",
            " [ 0.6152188   1.0576633   1.1845642  -0.00955155]\n",
            " [ 0.23310451  0.04499477  1.1799806   0.7821259 ]\n",
            " [ 0.32409704 -0.09890425  1.8213812   1.3506966 ]\n",
            " [ 0.6766422   0.8533402   1.4354147   0.3622901 ]\n",
            " [ 0.60858256  0.6542869   1.793784    0.74282306]\n",
            " [ 0.11631601 -0.33205917  1.4542714   1.2578692 ]\n",
            " [ 0.1278496  -0.21396655  0.92602456  0.8252694 ]\n",
            " [ 0.61402434  0.49834505  2.2734153   1.1878214 ]]\n",
            "real  [[0.57394809 0.29101067 0.69905395 0.86220391]\n",
            " [0.02324423 0.22720175 0.75477321 0.58486926]\n",
            " [0.23815138 0.29457941 0.67673838 0.56579858]\n",
            " [0.62120126 0.78150879 0.65749981 0.1883166 ]\n",
            " [0.17328817 0.38847752 0.88352496 0.23752996]\n",
            " [0.91517876 0.97690852 0.96999503 0.09917936]\n",
            " [0.95635655 0.26766364 0.50175673 0.70247451]\n",
            " [0.41062677 0.15770593 0.06247677 0.74438781]\n",
            " [0.57134897 0.28954091 0.35324078 0.80823561]\n",
            " [0.13459438 0.80272035 0.31297211 0.17406621]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72MhC5Omv0iS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2129
        },
        "outputId": "ff6c8972-3d98-436b-e697-c53c97888b7c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "num_inputs = 3\n",
        "num_h1_n = 4\n",
        "num_h2_n = 10\n",
        "num_outputs = 4\n",
        "\n",
        "num_samples = 10\n",
        "\n",
        "# Training data\n",
        "x_gr = np.random.rand(num_samples, num_inputs)\n",
        "y_gr = np.random.rand(num_samples, num_outputs)\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "# weights\n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs, num_h1_n]))\n",
        "w_2 = tf.Variable(tf.random_normal([num_h1_n, num_h2_n]))\n",
        "w_3 = tf.Variable(tf.random_normal([num_h2_n, num_outputs]))\n",
        "\n",
        "# bias\n",
        "b_1 = tf.Variable(tf.random_normal([num_h1_n]))\n",
        "b_2 = tf.Variable(tf.random_normal([num_h2_n]))\n",
        "b_3 = tf.Variable(tf.random_normal([num_outputs]))\n",
        "\n",
        "# model\n",
        "h1 = tf.nn.sigmoid(tf.add(tf.matmul(x, w_1), b_1)) # model of hidden layer 1\n",
        "h2 = tf.nn.sigmoid(tf.add(tf.matmul(h1, w_2), b_2)) # model of hidden layer 2\n",
        "y_p = tf.add(tf.matmul(h2, w_3), b_3)  # model of the output layer\n",
        "\n",
        "# cost\n",
        "cost = tf.reduce_mean(tf.pow(y - y_p, 2)) # mse first take then minimize\n",
        "\n",
        "# optimization\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "\n",
        "# initialize the graph\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  \n",
        "  for i in range(100):\n",
        "    \n",
        "    sess.run(optimizer, feed_dict={x: x_gr, y: y_gr})\n",
        "    pr_cost = sess.run(cost, feed_dict={x: x_gr, y: y_gr})\n",
        "    print('iter', i, 'cost: ', pr_cost)\n",
        "  \n",
        "  y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "  print('predcited', y_p_p)\n",
        "  print('real ', y_gr)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0 cost:  0.1679424\n",
            "iter 1 cost:  0.16739722\n",
            "iter 2 cost:  0.16685338\n",
            "iter 3 cost:  0.16631092\n",
            "iter 4 cost:  0.16576989\n",
            "iter 5 cost:  0.16523035\n",
            "iter 6 cost:  0.16469231\n",
            "iter 7 cost:  0.16415586\n",
            "iter 8 cost:  0.16362095\n",
            "iter 9 cost:  0.16308767\n",
            "iter 10 cost:  0.16255602\n",
            "iter 11 cost:  0.16202603\n",
            "iter 12 cost:  0.16149776\n",
            "iter 13 cost:  0.1609712\n",
            "iter 14 cost:  0.16044644\n",
            "iter 15 cost:  0.15992345\n",
            "iter 16 cost:  0.1594023\n",
            "iter 17 cost:  0.15888305\n",
            "iter 18 cost:  0.1583657\n",
            "iter 19 cost:  0.1578503\n",
            "iter 20 cost:  0.15733685\n",
            "iter 21 cost:  0.1568254\n",
            "iter 22 cost:  0.15631597\n",
            "iter 23 cost:  0.1558086\n",
            "iter 24 cost:  0.1553033\n",
            "iter 25 cost:  0.15480006\n",
            "iter 26 cost:  0.15429893\n",
            "iter 27 cost:  0.15379997\n",
            "iter 28 cost:  0.15330312\n",
            "iter 29 cost:  0.15280844\n",
            "iter 30 cost:  0.15231594\n",
            "iter 31 cost:  0.15182564\n",
            "iter 32 cost:  0.15133753\n",
            "iter 33 cost:  0.15085164\n",
            "iter 34 cost:  0.15036799\n",
            "iter 35 cost:  0.14988653\n",
            "iter 36 cost:  0.14940731\n",
            "iter 37 cost:  0.14893034\n",
            "iter 38 cost:  0.14845559\n",
            "iter 39 cost:  0.14798304\n",
            "iter 40 cost:  0.14751276\n",
            "iter 41 cost:  0.14704467\n",
            "iter 42 cost:  0.1465788\n",
            "iter 43 cost:  0.14611514\n",
            "iter 44 cost:  0.14565367\n",
            "iter 45 cost:  0.14519437\n",
            "iter 46 cost:  0.14473721\n",
            "iter 47 cost:  0.14428225\n",
            "iter 48 cost:  0.14382938\n",
            "iter 49 cost:  0.14337865\n",
            "iter 50 cost:  0.14293\n",
            "iter 51 cost:  0.1424834\n",
            "iter 52 cost:  0.14203887\n",
            "iter 53 cost:  0.14159635\n",
            "iter 54 cost:  0.14115584\n",
            "iter 55 cost:  0.14071725\n",
            "iter 56 cost:  0.14028063\n",
            "iter 57 cost:  0.13984592\n",
            "iter 58 cost:  0.13941309\n",
            "iter 59 cost:  0.13898206\n",
            "iter 60 cost:  0.13855287\n",
            "iter 61 cost:  0.13812546\n",
            "iter 62 cost:  0.1376998\n",
            "iter 63 cost:  0.1372758\n",
            "iter 64 cost:  0.1368535\n",
            "iter 65 cost:  0.13643284\n",
            "iter 66 cost:  0.13601375\n",
            "iter 67 cost:  0.13559622\n",
            "iter 68 cost:  0.13518019\n",
            "iter 69 cost:  0.13476565\n",
            "iter 70 cost:  0.13435254\n",
            "iter 71 cost:  0.13394085\n",
            "iter 72 cost:  0.13353048\n",
            "iter 73 cost:  0.13312143\n",
            "iter 74 cost:  0.13271365\n",
            "iter 75 cost:  0.13230713\n",
            "iter 76 cost:  0.13190177\n",
            "iter 77 cost:  0.13149759\n",
            "iter 78 cost:  0.13109452\n",
            "iter 79 cost:  0.13069251\n",
            "iter 80 cost:  0.13029154\n",
            "iter 81 cost:  0.12989156\n",
            "iter 82 cost:  0.12949255\n",
            "iter 83 cost:  0.12909445\n",
            "iter 84 cost:  0.12869722\n",
            "iter 85 cost:  0.12830083\n",
            "iter 86 cost:  0.12790525\n",
            "iter 87 cost:  0.12751043\n",
            "iter 88 cost:  0.12711635\n",
            "iter 89 cost:  0.12672296\n",
            "iter 90 cost:  0.12633024\n",
            "iter 91 cost:  0.12593815\n",
            "iter 92 cost:  0.12554666\n",
            "iter 93 cost:  0.12515573\n",
            "iter 94 cost:  0.12476534\n",
            "iter 95 cost:  0.12437544\n",
            "iter 96 cost:  0.12398605\n",
            "iter 97 cost:  0.1235971\n",
            "iter 98 cost:  0.123208545\n",
            "iter 99 cost:  0.122820415\n",
            "predcited [[0.44350305 0.839412   0.49637812 0.47091088]\n",
            " [0.45391217 0.84518296 0.4852562  0.438794  ]\n",
            " [0.4578295  0.83979386 0.5336766  0.48385775]\n",
            " [0.44687054 0.83915615 0.54184246 0.515637  ]\n",
            " [0.42950988 0.8335855  0.46091038 0.46839523]\n",
            " [0.45501864 0.8462041  0.52322924 0.47729155]\n",
            " [0.43466353 0.8379029  0.5199768  0.5102945 ]\n",
            " [0.47085845 0.84148717 0.5451634  0.47265536]\n",
            " [0.46744984 0.8417501  0.54759085 0.48327166]\n",
            " [0.41982082 0.81402737 0.5442217  0.55814195]]\n",
            "real  [[0.75677496 0.86622504 0.24616572 0.08559706]\n",
            " [0.00458467 0.90546897 0.62091264 0.69562129]\n",
            " [0.38832203 0.09411037 0.53453878 0.9388733 ]\n",
            " [0.25782516 0.20914901 0.604711   0.25880953]\n",
            " [0.36600028 0.24471499 0.18936937 0.77867655]\n",
            " [0.42414063 0.98935966 0.41082234 0.72101364]\n",
            " [0.00915616 0.17289262 0.97779326 0.38942187]\n",
            " [0.65362865 0.3688986  0.71169712 0.69685883]\n",
            " [0.17225434 0.01809993 0.8897835  0.09220552]\n",
            " [0.60148096 0.62382816 0.62216857 0.19050468]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClSa8DK5yemP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e08c1a7e-a6a2-4aaf-f691-605ad274ba34"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets('/tmp/data', one_hot='True')\n",
        "\n",
        "mnist.train.images.shape\n",
        "\n",
        "image = mnist.train.images[0].reshape((28, 28))\n",
        "print(mnist.train.labels[0])\n",
        "imshow(image)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9604f154e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIrwA0ERfiAowg8ERfiBoAg/ENT/AyErW1pw/s8cAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xudizkmm1AVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18006
        },
        "outputId": "ff3d4ee0-2572-4d36-f403-0e06e9715712"
      },
      "source": [
        "X_train = mnist.train.images\n",
        "Y_train = mnist.train.labels\n",
        "\n",
        "X_test = mnist.test.images\n",
        "Y_test = mnist.test.labels\n",
        "\n",
        "X_val = mnist.validation.images\n",
        "Y_val = mnist.validation.labels\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "num_inputs = 784\n",
        "num_h1_n = 100\n",
        "num_h2_n = 100\n",
        "num_outputs = 10\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "# weights\n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs, num_h1_n]))\n",
        "w_2 = tf.Variable(tf.random_normal([num_h1_n, num_h2_n]))\n",
        "w_3 = tf.Variable(tf.random_normal([num_h2_n, num_outputs]))\n",
        "\n",
        "# bias\n",
        "b_1 = tf.Variable(tf.random_normal([num_h1_n]))\n",
        "b_2 = tf.Variable(tf.random_normal([num_h2_n]))\n",
        "b_3 = tf.Variable(tf.random_normal([num_outputs]))\n",
        "\n",
        "# model\n",
        "h1 = tf.nn.sigmoid(tf.add(tf.matmul(x, w_1), b_1)) # model of hidden layer 1\n",
        "h2 = tf.nn.sigmoid(tf.add(tf.matmul(h1, w_2), b_2)) # model of hidden layer 2\n",
        "y_p = tf.add(tf.matmul(h2, w_3), b_3)  # model of the output layer\n",
        "\n",
        "# cost\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_p, labels=y)) # cost entropy\n",
        "\n",
        "#evaluate model\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(y_p, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# optimization\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "\n",
        "# initialize the graph\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  \n",
        "  for i in range(1000):\n",
        "    \n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "    \n",
        "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
        "    \n",
        "    train_cost, train_acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
        "        \n",
        "    test_batch_x, test_batch_y = mnist.test.next_batch(batch_size)\n",
        "    \n",
        "    test_cost, test_acc = sess.run([cost, accuracy], feed_dict={x: test_batch_x, y: test_batch_y})\n",
        "    \n",
        "    print('iter', i, 'train_cost: ', train_cost, 'train_acc: ', train_acc, 'test_cost: ', test_cost, 'test_acc: ', test_acc)\n",
        "    \n",
        "  \n",
        "  y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "  print('predcited', y_p_p)\n",
        "  print('real ', y_gr)\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0 train_cost:  10.366382 train_acc:  0.1171875 test_cost:  11.345047 test_acc:  0.0859375\n",
            "iter 1 train_cost:  9.271646 train_acc:  0.1328125 test_cost:  10.661743 test_acc:  0.078125\n",
            "iter 2 train_cost:  10.320458 train_acc:  0.0859375 test_cost:  9.831114 test_acc:  0.0859375\n",
            "iter 3 train_cost:  9.112186 train_acc:  0.0859375 test_cost:  9.4951315 test_acc:  0.078125\n",
            "iter 4 train_cost:  9.19833 train_acc:  0.0703125 test_cost:  9.387874 test_acc:  0.0859375\n",
            "iter 5 train_cost:  8.836685 train_acc:  0.09375 test_cost:  8.130456 test_acc:  0.1328125\n",
            "iter 6 train_cost:  9.3664 train_acc:  0.0859375 test_cost:  7.7693987 test_acc:  0.0859375\n",
            "iter 7 train_cost:  7.959239 train_acc:  0.125 test_cost:  7.7766805 test_acc:  0.09375\n",
            "iter 8 train_cost:  8.197771 train_acc:  0.0625 test_cost:  9.04916 test_acc:  0.0859375\n",
            "iter 9 train_cost:  7.760606 train_acc:  0.078125 test_cost:  8.434456 test_acc:  0.046875\n",
            "iter 10 train_cost:  7.3344684 train_acc:  0.1015625 test_cost:  7.3722367 test_acc:  0.1015625\n",
            "iter 11 train_cost:  7.7889495 train_acc:  0.0703125 test_cost:  8.033247 test_acc:  0.0859375\n",
            "iter 12 train_cost:  7.7427635 train_acc:  0.0703125 test_cost:  7.0977907 test_acc:  0.1171875\n",
            "iter 13 train_cost:  6.744775 train_acc:  0.109375 test_cost:  8.01642 test_acc:  0.0625\n",
            "iter 14 train_cost:  7.590346 train_acc:  0.0859375 test_cost:  7.446018 test_acc:  0.0390625\n",
            "iter 15 train_cost:  6.382251 train_acc:  0.109375 test_cost:  6.8927517 test_acc:  0.078125\n",
            "iter 16 train_cost:  7.040872 train_acc:  0.078125 test_cost:  6.2837543 test_acc:  0.0859375\n",
            "iter 17 train_cost:  7.5393677 train_acc:  0.0859375 test_cost:  6.040679 test_acc:  0.125\n",
            "iter 18 train_cost:  6.1989555 train_acc:  0.1171875 test_cost:  6.447335 test_acc:  0.1171875\n",
            "iter 19 train_cost:  6.7401276 train_acc:  0.0859375 test_cost:  6.217208 test_acc:  0.125\n",
            "iter 20 train_cost:  6.9897614 train_acc:  0.0390625 test_cost:  6.5447674 test_acc:  0.09375\n",
            "iter 21 train_cost:  7.103416 train_acc:  0.1328125 test_cost:  5.897541 test_acc:  0.078125\n",
            "iter 22 train_cost:  6.00377 train_acc:  0.078125 test_cost:  6.0400367 test_acc:  0.0859375\n",
            "iter 23 train_cost:  6.017481 train_acc:  0.1328125 test_cost:  6.2471323 test_acc:  0.078125\n",
            "iter 24 train_cost:  5.748272 train_acc:  0.125 test_cost:  6.2585893 test_acc:  0.0859375\n",
            "iter 25 train_cost:  5.7837553 train_acc:  0.1640625 test_cost:  5.8754835 test_acc:  0.1015625\n",
            "iter 26 train_cost:  5.6959896 train_acc:  0.1015625 test_cost:  6.1432714 test_acc:  0.0859375\n",
            "iter 27 train_cost:  6.6565614 train_acc:  0.125 test_cost:  5.8116617 test_acc:  0.1171875\n",
            "iter 28 train_cost:  5.8280554 train_acc:  0.09375 test_cost:  6.1575956 test_acc:  0.109375\n",
            "iter 29 train_cost:  5.4196568 train_acc:  0.140625 test_cost:  5.332499 test_acc:  0.1171875\n",
            "iter 30 train_cost:  5.559023 train_acc:  0.140625 test_cost:  5.803443 test_acc:  0.140625\n",
            "iter 31 train_cost:  5.467813 train_acc:  0.15625 test_cost:  4.686163 test_acc:  0.1640625\n",
            "iter 32 train_cost:  5.2796597 train_acc:  0.09375 test_cost:  5.249812 test_acc:  0.078125\n",
            "iter 33 train_cost:  4.9250584 train_acc:  0.1171875 test_cost:  5.364637 test_acc:  0.0703125\n",
            "iter 34 train_cost:  5.201296 train_acc:  0.1875 test_cost:  4.5486727 test_acc:  0.15625\n",
            "iter 35 train_cost:  4.9481826 train_acc:  0.1171875 test_cost:  4.5967264 test_acc:  0.1640625\n",
            "iter 36 train_cost:  4.842082 train_acc:  0.109375 test_cost:  5.242859 test_acc:  0.15625\n",
            "iter 37 train_cost:  4.726021 train_acc:  0.125 test_cost:  4.9355087 test_acc:  0.140625\n",
            "iter 38 train_cost:  4.329254 train_acc:  0.21875 test_cost:  4.4600677 test_acc:  0.1640625\n",
            "iter 39 train_cost:  4.514312 train_acc:  0.1875 test_cost:  4.8682127 test_acc:  0.125\n",
            "iter 40 train_cost:  5.334498 train_acc:  0.1484375 test_cost:  4.6870213 test_acc:  0.171875\n",
            "iter 41 train_cost:  4.7712398 train_acc:  0.1640625 test_cost:  4.7850924 test_acc:  0.1328125\n",
            "iter 42 train_cost:  4.6604977 train_acc:  0.109375 test_cost:  4.469882 test_acc:  0.1875\n",
            "iter 43 train_cost:  4.2752857 train_acc:  0.1953125 test_cost:  5.0547442 test_acc:  0.1484375\n",
            "iter 44 train_cost:  4.586471 train_acc:  0.1015625 test_cost:  4.0705185 test_acc:  0.2109375\n",
            "iter 45 train_cost:  4.860864 train_acc:  0.15625 test_cost:  4.0880356 test_acc:  0.1328125\n",
            "iter 46 train_cost:  3.8124905 train_acc:  0.1875 test_cost:  3.9553707 test_acc:  0.25\n",
            "iter 47 train_cost:  4.1790943 train_acc:  0.171875 test_cost:  3.9874287 test_acc:  0.2265625\n",
            "iter 48 train_cost:  3.9771597 train_acc:  0.203125 test_cost:  4.3520327 test_acc:  0.1953125\n",
            "iter 49 train_cost:  3.7853165 train_acc:  0.140625 test_cost:  4.2446194 test_acc:  0.171875\n",
            "iter 50 train_cost:  3.5489092 train_acc:  0.1796875 test_cost:  4.023071 test_acc:  0.140625\n",
            "iter 51 train_cost:  3.6707628 train_acc:  0.171875 test_cost:  4.0462503 test_acc:  0.1796875\n",
            "iter 52 train_cost:  3.9808743 train_acc:  0.1796875 test_cost:  3.773015 test_acc:  0.234375\n",
            "iter 53 train_cost:  3.832714 train_acc:  0.2578125 test_cost:  3.9718618 test_acc:  0.2421875\n",
            "iter 54 train_cost:  3.3742218 train_acc:  0.2265625 test_cost:  4.3162804 test_acc:  0.15625\n",
            "iter 55 train_cost:  3.1997895 train_acc:  0.21875 test_cost:  3.4337559 test_acc:  0.2265625\n",
            "iter 56 train_cost:  3.6811643 train_acc:  0.2421875 test_cost:  3.5079267 test_acc:  0.2109375\n",
            "iter 57 train_cost:  3.5456686 train_acc:  0.25 test_cost:  3.5643146 test_acc:  0.1953125\n",
            "iter 58 train_cost:  3.681623 train_acc:  0.1796875 test_cost:  3.3333027 test_acc:  0.3125\n",
            "iter 59 train_cost:  3.3085306 train_acc:  0.2890625 test_cost:  3.4592314 test_acc:  0.2578125\n",
            "iter 60 train_cost:  3.2226176 train_acc:  0.3046875 test_cost:  3.1109319 test_acc:  0.2421875\n",
            "iter 61 train_cost:  3.246458 train_acc:  0.3046875 test_cost:  3.434293 test_acc:  0.28125\n",
            "iter 62 train_cost:  3.5806072 train_acc:  0.2109375 test_cost:  3.2700028 test_acc:  0.296875\n",
            "iter 63 train_cost:  2.852881 train_acc:  0.2421875 test_cost:  3.3555293 test_acc:  0.2109375\n",
            "iter 64 train_cost:  3.359284 train_acc:  0.2109375 test_cost:  3.7576158 test_acc:  0.1953125\n",
            "iter 65 train_cost:  3.0612733 train_acc:  0.2421875 test_cost:  3.1178055 test_acc:  0.265625\n",
            "iter 66 train_cost:  3.1537242 train_acc:  0.21875 test_cost:  3.2037845 test_acc:  0.2265625\n",
            "iter 67 train_cost:  2.8282785 train_acc:  0.34375 test_cost:  2.9710631 test_acc:  0.2421875\n",
            "iter 68 train_cost:  3.2505584 train_acc:  0.265625 test_cost:  2.6232157 test_acc:  0.34375\n",
            "iter 69 train_cost:  3.2439513 train_acc:  0.2578125 test_cost:  3.048833 test_acc:  0.2734375\n",
            "iter 70 train_cost:  2.8399334 train_acc:  0.3046875 test_cost:  3.2280333 test_acc:  0.2421875\n",
            "iter 71 train_cost:  2.8957367 train_acc:  0.2734375 test_cost:  3.3567047 test_acc:  0.265625\n",
            "iter 72 train_cost:  3.0412529 train_acc:  0.296875 test_cost:  2.5838702 test_acc:  0.3125\n",
            "iter 73 train_cost:  2.9264777 train_acc:  0.2890625 test_cost:  2.7830212 test_acc:  0.2578125\n",
            "iter 74 train_cost:  2.5477762 train_acc:  0.328125 test_cost:  2.8596258 test_acc:  0.28125\n",
            "iter 75 train_cost:  2.9779024 train_acc:  0.2421875 test_cost:  2.593971 test_acc:  0.3515625\n",
            "iter 76 train_cost:  3.0040221 train_acc:  0.1953125 test_cost:  3.0343122 test_acc:  0.296875\n",
            "iter 77 train_cost:  2.5507562 train_acc:  0.3203125 test_cost:  2.4116778 test_acc:  0.359375\n",
            "iter 78 train_cost:  2.97058 train_acc:  0.25 test_cost:  2.5084596 test_acc:  0.2890625\n",
            "iter 79 train_cost:  2.801683 train_acc:  0.28125 test_cost:  2.3936422 test_acc:  0.3203125\n",
            "iter 80 train_cost:  2.7142527 train_acc:  0.2578125 test_cost:  2.9183307 test_acc:  0.2421875\n",
            "iter 81 train_cost:  2.8530254 train_acc:  0.328125 test_cost:  2.8259108 test_acc:  0.265625\n",
            "iter 82 train_cost:  2.6670384 train_acc:  0.2890625 test_cost:  2.7237363 test_acc:  0.265625\n",
            "iter 83 train_cost:  2.6332839 train_acc:  0.3125 test_cost:  2.510958 test_acc:  0.3125\n",
            "iter 84 train_cost:  2.3630733 train_acc:  0.34375 test_cost:  2.780212 test_acc:  0.3203125\n",
            "iter 85 train_cost:  3.1039143 train_acc:  0.21875 test_cost:  2.5908194 test_acc:  0.3125\n",
            "iter 86 train_cost:  2.5363407 train_acc:  0.3203125 test_cost:  2.4328723 test_acc:  0.328125\n",
            "iter 87 train_cost:  2.283879 train_acc:  0.3125 test_cost:  2.609732 test_acc:  0.2421875\n",
            "iter 88 train_cost:  2.4565623 train_acc:  0.3046875 test_cost:  2.5756865 test_acc:  0.3359375\n",
            "iter 89 train_cost:  2.497859 train_acc:  0.3515625 test_cost:  2.3613799 test_acc:  0.3203125\n",
            "iter 90 train_cost:  2.411749 train_acc:  0.2734375 test_cost:  2.2619493 test_acc:  0.40625\n",
            "iter 91 train_cost:  2.3421793 train_acc:  0.3671875 test_cost:  2.6355317 test_acc:  0.3125\n",
            "iter 92 train_cost:  2.2673826 train_acc:  0.3515625 test_cost:  2.5460012 test_acc:  0.3515625\n",
            "iter 93 train_cost:  2.6339796 train_acc:  0.3203125 test_cost:  2.2359624 test_acc:  0.34375\n",
            "iter 94 train_cost:  2.1888776 train_acc:  0.40625 test_cost:  2.4723377 test_acc:  0.2890625\n",
            "iter 95 train_cost:  2.2984056 train_acc:  0.375 test_cost:  2.267391 test_acc:  0.359375\n",
            "iter 96 train_cost:  2.263381 train_acc:  0.3203125 test_cost:  2.4863691 test_acc:  0.3125\n",
            "iter 97 train_cost:  2.171721 train_acc:  0.4140625 test_cost:  2.38339 test_acc:  0.3515625\n",
            "iter 98 train_cost:  2.224888 train_acc:  0.359375 test_cost:  2.411583 test_acc:  0.3515625\n",
            "iter 99 train_cost:  2.0781991 train_acc:  0.3828125 test_cost:  2.4001899 test_acc:  0.34375\n",
            "iter 100 train_cost:  2.2571409 train_acc:  0.3515625 test_cost:  2.3391676 test_acc:  0.328125\n",
            "iter 101 train_cost:  2.0320632 train_acc:  0.4296875 test_cost:  2.294144 test_acc:  0.3359375\n",
            "iter 102 train_cost:  2.3080688 train_acc:  0.3125 test_cost:  2.2308335 test_acc:  0.3828125\n",
            "iter 103 train_cost:  2.6189065 train_acc:  0.328125 test_cost:  2.555418 test_acc:  0.3046875\n",
            "iter 104 train_cost:  2.4631388 train_acc:  0.328125 test_cost:  2.1250274 test_acc:  0.34375\n",
            "iter 105 train_cost:  2.0455976 train_acc:  0.3828125 test_cost:  2.3525624 test_acc:  0.3984375\n",
            "iter 106 train_cost:  2.1295822 train_acc:  0.3671875 test_cost:  2.2008343 test_acc:  0.359375\n",
            "iter 107 train_cost:  2.388375 train_acc:  0.3828125 test_cost:  2.2991714 test_acc:  0.3203125\n",
            "iter 108 train_cost:  2.0265162 train_acc:  0.3671875 test_cost:  2.0916636 test_acc:  0.4140625\n",
            "iter 109 train_cost:  2.349394 train_acc:  0.3203125 test_cost:  1.9785758 test_acc:  0.359375\n",
            "iter 110 train_cost:  2.0678365 train_acc:  0.3671875 test_cost:  2.114966 test_acc:  0.3828125\n",
            "iter 111 train_cost:  2.0247436 train_acc:  0.3828125 test_cost:  2.127934 test_acc:  0.421875\n",
            "iter 112 train_cost:  2.265582 train_acc:  0.3828125 test_cost:  2.3313255 test_acc:  0.390625\n",
            "iter 113 train_cost:  2.0318105 train_acc:  0.3828125 test_cost:  2.4402936 test_acc:  0.34375\n",
            "iter 114 train_cost:  2.1148767 train_acc:  0.390625 test_cost:  2.0229352 test_acc:  0.4140625\n",
            "iter 115 train_cost:  2.2120285 train_acc:  0.375 test_cost:  1.8834264 test_acc:  0.4140625\n",
            "iter 116 train_cost:  1.8366327 train_acc:  0.421875 test_cost:  2.2376425 test_acc:  0.390625\n",
            "iter 117 train_cost:  2.1378753 train_acc:  0.3984375 test_cost:  2.1575623 test_acc:  0.390625\n",
            "iter 118 train_cost:  2.1093543 train_acc:  0.3984375 test_cost:  1.6438165 test_acc:  0.4453125\n",
            "iter 119 train_cost:  2.0967555 train_acc:  0.3984375 test_cost:  2.0640917 test_acc:  0.3671875\n",
            "iter 120 train_cost:  2.0477774 train_acc:  0.375 test_cost:  1.7553763 test_acc:  0.453125\n",
            "iter 121 train_cost:  2.0315537 train_acc:  0.4140625 test_cost:  2.1793733 test_acc:  0.34375\n",
            "iter 122 train_cost:  1.8647178 train_acc:  0.3984375 test_cost:  2.3083093 test_acc:  0.3515625\n",
            "iter 123 train_cost:  2.1038983 train_acc:  0.3671875 test_cost:  2.1182346 test_acc:  0.375\n",
            "iter 124 train_cost:  1.9942756 train_acc:  0.4453125 test_cost:  1.940537 test_acc:  0.4140625\n",
            "iter 125 train_cost:  1.8883215 train_acc:  0.4296875 test_cost:  1.6803209 test_acc:  0.4765625\n",
            "iter 126 train_cost:  2.1416993 train_acc:  0.40625 test_cost:  2.0867057 test_acc:  0.4375\n",
            "iter 127 train_cost:  1.7490305 train_acc:  0.453125 test_cost:  1.8588724 test_acc:  0.46875\n",
            "iter 128 train_cost:  2.0333858 train_acc:  0.4140625 test_cost:  2.2749758 test_acc:  0.40625\n",
            "iter 129 train_cost:  1.8641756 train_acc:  0.3984375 test_cost:  2.0185628 test_acc:  0.453125\n",
            "iter 130 train_cost:  1.7442005 train_acc:  0.453125 test_cost:  1.9053559 test_acc:  0.46875\n",
            "iter 131 train_cost:  2.119101 train_acc:  0.4140625 test_cost:  1.7162569 test_acc:  0.484375\n",
            "iter 132 train_cost:  2.0496569 train_acc:  0.3828125 test_cost:  1.8806348 test_acc:  0.4375\n",
            "iter 133 train_cost:  1.926631 train_acc:  0.5234375 test_cost:  2.09338 test_acc:  0.3984375\n",
            "iter 134 train_cost:  1.537481 train_acc:  0.546875 test_cost:  1.6812935 test_acc:  0.453125\n",
            "iter 135 train_cost:  2.1820517 train_acc:  0.3984375 test_cost:  1.6527131 test_acc:  0.4765625\n",
            "iter 136 train_cost:  1.9721886 train_acc:  0.3984375 test_cost:  1.8169713 test_acc:  0.4375\n",
            "iter 137 train_cost:  1.8964534 train_acc:  0.484375 test_cost:  2.0602484 test_acc:  0.4296875\n",
            "iter 138 train_cost:  1.8255112 train_acc:  0.546875 test_cost:  1.7892642 test_acc:  0.484375\n",
            "iter 139 train_cost:  1.8425407 train_acc:  0.421875 test_cost:  1.9783325 test_acc:  0.4375\n",
            "iter 140 train_cost:  1.6726702 train_acc:  0.5 test_cost:  1.8326137 test_acc:  0.46875\n",
            "iter 141 train_cost:  2.000877 train_acc:  0.421875 test_cost:  1.6675062 test_acc:  0.5234375\n",
            "iter 142 train_cost:  1.9362029 train_acc:  0.4609375 test_cost:  1.8080913 test_acc:  0.40625\n",
            "iter 143 train_cost:  1.7886155 train_acc:  0.4765625 test_cost:  1.8491635 test_acc:  0.3828125\n",
            "iter 144 train_cost:  1.6012435 train_acc:  0.546875 test_cost:  1.7300131 test_acc:  0.46875\n",
            "iter 145 train_cost:  1.924645 train_acc:  0.4453125 test_cost:  1.8996936 test_acc:  0.453125\n",
            "iter 146 train_cost:  1.7925304 train_acc:  0.4765625 test_cost:  1.7211137 test_acc:  0.484375\n",
            "iter 147 train_cost:  1.8947241 train_acc:  0.3984375 test_cost:  1.9125311 test_acc:  0.484375\n",
            "iter 148 train_cost:  1.8212924 train_acc:  0.4921875 test_cost:  1.800039 test_acc:  0.4765625\n",
            "iter 149 train_cost:  1.564935 train_acc:  0.546875 test_cost:  1.8713552 test_acc:  0.3984375\n",
            "iter 150 train_cost:  1.3347781 train_acc:  0.53125 test_cost:  1.4211677 test_acc:  0.53125\n",
            "iter 151 train_cost:  1.9563606 train_acc:  0.40625 test_cost:  1.7882605 test_acc:  0.453125\n",
            "iter 152 train_cost:  1.5523677 train_acc:  0.4453125 test_cost:  2.0742662 test_acc:  0.46875\n",
            "iter 153 train_cost:  1.787718 train_acc:  0.4609375 test_cost:  1.6906347 test_acc:  0.484375\n",
            "iter 154 train_cost:  1.6561882 train_acc:  0.484375 test_cost:  1.4756286 test_acc:  0.515625\n",
            "iter 155 train_cost:  1.6872766 train_acc:  0.59375 test_cost:  1.7554529 test_acc:  0.46875\n",
            "iter 156 train_cost:  1.626219 train_acc:  0.484375 test_cost:  1.6298864 test_acc:  0.4921875\n",
            "iter 157 train_cost:  1.7253759 train_acc:  0.421875 test_cost:  1.8645568 test_acc:  0.4609375\n",
            "iter 158 train_cost:  1.4886136 train_acc:  0.5078125 test_cost:  1.9415047 test_acc:  0.4375\n",
            "iter 159 train_cost:  1.615568 train_acc:  0.5390625 test_cost:  1.7479159 test_acc:  0.5234375\n",
            "iter 160 train_cost:  1.7302322 train_acc:  0.484375 test_cost:  1.7911692 test_acc:  0.4296875\n",
            "iter 161 train_cost:  1.8357253 train_acc:  0.453125 test_cost:  1.5337569 test_acc:  0.5078125\n",
            "iter 162 train_cost:  1.7429695 train_acc:  0.5 test_cost:  1.5707023 test_acc:  0.515625\n",
            "iter 163 train_cost:  1.4541687 train_acc:  0.5546875 test_cost:  1.6667913 test_acc:  0.4921875\n",
            "iter 164 train_cost:  1.6886183 train_acc:  0.5078125 test_cost:  1.7080408 test_acc:  0.484375\n",
            "iter 165 train_cost:  1.3779297 train_acc:  0.59375 test_cost:  1.7587366 test_acc:  0.5078125\n",
            "iter 166 train_cost:  1.5955646 train_acc:  0.515625 test_cost:  1.4247358 test_acc:  0.578125\n",
            "iter 167 train_cost:  1.3669271 train_acc:  0.546875 test_cost:  2.0065677 test_acc:  0.453125\n",
            "iter 168 train_cost:  1.5180781 train_acc:  0.546875 test_cost:  1.5994011 test_acc:  0.5078125\n",
            "iter 169 train_cost:  1.3707885 train_acc:  0.6015625 test_cost:  1.4272168 test_acc:  0.5390625\n",
            "iter 170 train_cost:  1.3792958 train_acc:  0.53125 test_cost:  1.4330609 test_acc:  0.5625\n",
            "iter 171 train_cost:  1.4000193 train_acc:  0.5390625 test_cost:  1.4282488 test_acc:  0.5625\n",
            "iter 172 train_cost:  1.5180509 train_acc:  0.5390625 test_cost:  1.5147884 test_acc:  0.5546875\n",
            "iter 173 train_cost:  1.5529065 train_acc:  0.5 test_cost:  1.3354936 test_acc:  0.5703125\n",
            "iter 174 train_cost:  1.8670546 train_acc:  0.5078125 test_cost:  1.6250806 test_acc:  0.5\n",
            "iter 175 train_cost:  1.6352987 train_acc:  0.515625 test_cost:  1.6868899 test_acc:  0.4765625\n",
            "iter 176 train_cost:  1.5746076 train_acc:  0.5234375 test_cost:  1.5859735 test_acc:  0.5390625\n",
            "iter 177 train_cost:  1.3467686 train_acc:  0.5390625 test_cost:  1.6120973 test_acc:  0.5234375\n",
            "iter 178 train_cost:  1.6097126 train_acc:  0.578125 test_cost:  1.4373513 test_acc:  0.5390625\n",
            "iter 179 train_cost:  1.6195643 train_acc:  0.515625 test_cost:  1.5248559 test_acc:  0.53125\n",
            "iter 180 train_cost:  1.4199953 train_acc:  0.59375 test_cost:  1.616467 test_acc:  0.5390625\n",
            "iter 181 train_cost:  1.7301888 train_acc:  0.5 test_cost:  1.4610456 test_acc:  0.5546875\n",
            "iter 182 train_cost:  1.8333558 train_acc:  0.5078125 test_cost:  1.6006075 test_acc:  0.4453125\n",
            "iter 183 train_cost:  1.5784724 train_acc:  0.546875 test_cost:  1.5458758 test_acc:  0.546875\n",
            "iter 184 train_cost:  1.6803651 train_acc:  0.5234375 test_cost:  1.5154979 test_acc:  0.53125\n",
            "iter 185 train_cost:  1.6328056 train_acc:  0.5078125 test_cost:  1.5759256 test_acc:  0.5078125\n",
            "iter 186 train_cost:  1.5815077 train_acc:  0.5625 test_cost:  1.2544912 test_acc:  0.6484375\n",
            "iter 187 train_cost:  1.4786925 train_acc:  0.5546875 test_cost:  1.5103742 test_acc:  0.5078125\n",
            "iter 188 train_cost:  1.452237 train_acc:  0.5234375 test_cost:  1.7667084 test_acc:  0.453125\n",
            "iter 189 train_cost:  1.690691 train_acc:  0.515625 test_cost:  1.4548097 test_acc:  0.5625\n",
            "iter 190 train_cost:  1.5138955 train_acc:  0.5390625 test_cost:  1.2856389 test_acc:  0.6015625\n",
            "iter 191 train_cost:  1.2345579 train_acc:  0.625 test_cost:  1.7181187 test_acc:  0.46875\n",
            "iter 192 train_cost:  1.5539865 train_acc:  0.5625 test_cost:  1.3942603 test_acc:  0.546875\n",
            "iter 193 train_cost:  1.5381397 train_acc:  0.53125 test_cost:  1.6315037 test_acc:  0.5234375\n",
            "iter 194 train_cost:  1.4182808 train_acc:  0.5546875 test_cost:  1.5422605 test_acc:  0.5078125\n",
            "iter 195 train_cost:  1.6647949 train_acc:  0.46875 test_cost:  1.5274955 test_acc:  0.484375\n",
            "iter 196 train_cost:  1.6339648 train_acc:  0.5078125 test_cost:  1.4451743 test_acc:  0.515625\n",
            "iter 197 train_cost:  1.5116936 train_acc:  0.5546875 test_cost:  1.3293095 test_acc:  0.5703125\n",
            "iter 198 train_cost:  1.1667029 train_acc:  0.6171875 test_cost:  1.410634 test_acc:  0.5390625\n",
            "iter 199 train_cost:  1.3418691 train_acc:  0.5234375 test_cost:  1.4077307 test_acc:  0.5859375\n",
            "iter 200 train_cost:  1.7125492 train_acc:  0.46875 test_cost:  1.3321495 test_acc:  0.53125\n",
            "iter 201 train_cost:  1.1782911 train_acc:  0.609375 test_cost:  1.4079058 test_acc:  0.5390625\n",
            "iter 202 train_cost:  1.5516243 train_acc:  0.53125 test_cost:  1.2990787 test_acc:  0.6015625\n",
            "iter 203 train_cost:  1.3110516 train_acc:  0.5703125 test_cost:  1.27391 test_acc:  0.59375\n",
            "iter 204 train_cost:  1.224812 train_acc:  0.671875 test_cost:  1.5014496 test_acc:  0.515625\n",
            "iter 205 train_cost:  1.4460716 train_acc:  0.546875 test_cost:  1.2524066 test_acc:  0.59375\n",
            "iter 206 train_cost:  1.314848 train_acc:  0.6171875 test_cost:  1.498662 test_acc:  0.53125\n",
            "iter 207 train_cost:  1.2150663 train_acc:  0.6171875 test_cost:  1.3628747 test_acc:  0.546875\n",
            "iter 208 train_cost:  1.4859743 train_acc:  0.5234375 test_cost:  1.4313321 test_acc:  0.46875\n",
            "iter 209 train_cost:  1.4989709 train_acc:  0.59375 test_cost:  1.3174334 test_acc:  0.5859375\n",
            "iter 210 train_cost:  1.5506535 train_acc:  0.515625 test_cost:  1.3614973 test_acc:  0.59375\n",
            "iter 211 train_cost:  1.3643987 train_acc:  0.546875 test_cost:  1.424655 test_acc:  0.609375\n",
            "iter 212 train_cost:  1.3903766 train_acc:  0.59375 test_cost:  1.477904 test_acc:  0.5625\n",
            "iter 213 train_cost:  1.4224125 train_acc:  0.5859375 test_cost:  1.3676989 test_acc:  0.578125\n",
            "iter 214 train_cost:  1.3247327 train_acc:  0.6328125 test_cost:  1.3021415 test_acc:  0.6015625\n",
            "iter 215 train_cost:  1.4091475 train_acc:  0.5546875 test_cost:  1.5056672 test_acc:  0.59375\n",
            "iter 216 train_cost:  1.4530528 train_acc:  0.5 test_cost:  1.4254107 test_acc:  0.5546875\n",
            "iter 217 train_cost:  1.5212045 train_acc:  0.546875 test_cost:  1.3836724 test_acc:  0.5703125\n",
            "iter 218 train_cost:  1.232194 train_acc:  0.59375 test_cost:  1.4403096 test_acc:  0.5859375\n",
            "iter 219 train_cost:  0.94262546 train_acc:  0.7109375 test_cost:  1.4395912 test_acc:  0.609375\n",
            "iter 220 train_cost:  1.1765356 train_acc:  0.59375 test_cost:  1.1045519 test_acc:  0.6171875\n",
            "iter 221 train_cost:  1.2640642 train_acc:  0.625 test_cost:  1.4320233 test_acc:  0.609375\n",
            "iter 222 train_cost:  1.3185992 train_acc:  0.5546875 test_cost:  1.2209651 test_acc:  0.5859375\n",
            "iter 223 train_cost:  1.1521957 train_acc:  0.6484375 test_cost:  1.1433227 test_acc:  0.5859375\n",
            "iter 224 train_cost:  1.1644583 train_acc:  0.625 test_cost:  1.2950956 test_acc:  0.609375\n",
            "iter 225 train_cost:  1.2315867 train_acc:  0.6015625 test_cost:  1.5016327 test_acc:  0.53125\n",
            "iter 226 train_cost:  1.2548783 train_acc:  0.5859375 test_cost:  1.52887 test_acc:  0.546875\n",
            "iter 227 train_cost:  1.2305119 train_acc:  0.6328125 test_cost:  1.1705437 test_acc:  0.6015625\n",
            "iter 228 train_cost:  1.4541407 train_acc:  0.59375 test_cost:  1.1742126 test_acc:  0.640625\n",
            "iter 229 train_cost:  1.4948206 train_acc:  0.6015625 test_cost:  1.2663485 test_acc:  0.6015625\n",
            "iter 230 train_cost:  1.3141909 train_acc:  0.6640625 test_cost:  1.1970413 test_acc:  0.6015625\n",
            "iter 231 train_cost:  1.3572819 train_acc:  0.5625 test_cost:  1.2359691 test_acc:  0.5859375\n",
            "iter 232 train_cost:  0.8824886 train_acc:  0.6640625 test_cost:  1.1464069 test_acc:  0.7109375\n",
            "iter 233 train_cost:  1.2347472 train_acc:  0.609375 test_cost:  1.1412535 test_acc:  0.625\n",
            "iter 234 train_cost:  1.4708325 train_acc:  0.546875 test_cost:  1.3822217 test_acc:  0.5859375\n",
            "iter 235 train_cost:  1.1626592 train_acc:  0.6015625 test_cost:  1.5422932 test_acc:  0.5625\n",
            "iter 236 train_cost:  1.0833454 train_acc:  0.6484375 test_cost:  1.1601009 test_acc:  0.6015625\n",
            "iter 237 train_cost:  1.2811474 train_acc:  0.625 test_cost:  1.122793 test_acc:  0.640625\n",
            "iter 238 train_cost:  1.3044381 train_acc:  0.59375 test_cost:  0.98529154 test_acc:  0.6953125\n",
            "iter 239 train_cost:  1.3836335 train_acc:  0.5546875 test_cost:  1.3389623 test_acc:  0.5390625\n",
            "iter 240 train_cost:  1.0488727 train_acc:  0.640625 test_cost:  1.5636812 test_acc:  0.5546875\n",
            "iter 241 train_cost:  1.3528247 train_acc:  0.625 test_cost:  1.303447 test_acc:  0.5859375\n",
            "iter 242 train_cost:  1.2340719 train_acc:  0.6328125 test_cost:  1.0145471 test_acc:  0.6640625\n",
            "iter 243 train_cost:  1.2961985 train_acc:  0.5703125 test_cost:  1.1384844 test_acc:  0.59375\n",
            "iter 244 train_cost:  1.372361 train_acc:  0.578125 test_cost:  1.1566908 test_acc:  0.65625\n",
            "iter 245 train_cost:  1.1506724 train_acc:  0.640625 test_cost:  1.1598083 test_acc:  0.609375\n",
            "iter 246 train_cost:  1.171795 train_acc:  0.5546875 test_cost:  1.1838734 test_acc:  0.671875\n",
            "iter 247 train_cost:  1.2315944 train_acc:  0.59375 test_cost:  1.4651777 test_acc:  0.578125\n",
            "iter 248 train_cost:  1.2806691 train_acc:  0.59375 test_cost:  1.2528971 test_acc:  0.609375\n",
            "iter 249 train_cost:  1.1737633 train_acc:  0.625 test_cost:  1.1449981 test_acc:  0.609375\n",
            "iter 250 train_cost:  1.20349 train_acc:  0.6328125 test_cost:  1.1256585 test_acc:  0.6015625\n",
            "iter 251 train_cost:  1.0999676 train_acc:  0.6640625 test_cost:  1.0131718 test_acc:  0.6640625\n",
            "iter 252 train_cost:  1.3665279 train_acc:  0.578125 test_cost:  1.1959283 test_acc:  0.609375\n",
            "iter 253 train_cost:  1.1375045 train_acc:  0.65625 test_cost:  1.0271872 test_acc:  0.6953125\n",
            "iter 254 train_cost:  1.2905422 train_acc:  0.609375 test_cost:  1.1554093 test_acc:  0.640625\n",
            "iter 255 train_cost:  1.0812337 train_acc:  0.6171875 test_cost:  1.0836388 test_acc:  0.703125\n",
            "iter 256 train_cost:  1.3075547 train_acc:  0.5859375 test_cost:  1.2938727 test_acc:  0.6171875\n",
            "iter 257 train_cost:  1.3663409 train_acc:  0.5703125 test_cost:  1.5043924 test_acc:  0.578125\n",
            "iter 258 train_cost:  1.2485355 train_acc:  0.5859375 test_cost:  0.97341275 test_acc:  0.671875\n",
            "iter 259 train_cost:  1.0536902 train_acc:  0.6640625 test_cost:  1.2382736 test_acc:  0.5625\n",
            "iter 260 train_cost:  1.1079855 train_acc:  0.6875 test_cost:  1.4887332 test_acc:  0.5859375\n",
            "iter 261 train_cost:  1.0189158 train_acc:  0.6796875 test_cost:  1.3216536 test_acc:  0.59375\n",
            "iter 262 train_cost:  1.4987878 train_acc:  0.5546875 test_cost:  1.2401844 test_acc:  0.640625\n",
            "iter 263 train_cost:  1.4594779 train_acc:  0.546875 test_cost:  1.2519846 test_acc:  0.640625\n",
            "iter 264 train_cost:  1.3616687 train_acc:  0.6015625 test_cost:  1.1076639 test_acc:  0.65625\n",
            "iter 265 train_cost:  0.9806967 train_acc:  0.71875 test_cost:  1.1990839 test_acc:  0.6328125\n",
            "iter 266 train_cost:  1.1156545 train_acc:  0.6484375 test_cost:  1.2655082 test_acc:  0.6171875\n",
            "iter 267 train_cost:  1.0304766 train_acc:  0.65625 test_cost:  1.1726547 test_acc:  0.625\n",
            "iter 268 train_cost:  1.220008 train_acc:  0.6640625 test_cost:  0.96570444 test_acc:  0.6875\n",
            "iter 269 train_cost:  1.0788155 train_acc:  0.640625 test_cost:  1.2368453 test_acc:  0.6171875\n",
            "iter 270 train_cost:  1.3653924 train_acc:  0.5859375 test_cost:  0.98779833 test_acc:  0.703125\n",
            "iter 271 train_cost:  1.4296715 train_acc:  0.6015625 test_cost:  1.078263 test_acc:  0.7109375\n",
            "iter 272 train_cost:  1.3190475 train_acc:  0.5859375 test_cost:  1.0841085 test_acc:  0.6875\n",
            "iter 273 train_cost:  0.95547223 train_acc:  0.7109375 test_cost:  1.003372 test_acc:  0.6796875\n",
            "iter 274 train_cost:  1.3967088 train_acc:  0.5703125 test_cost:  1.1733813 test_acc:  0.6015625\n",
            "iter 275 train_cost:  1.3379726 train_acc:  0.6015625 test_cost:  0.9531222 test_acc:  0.6796875\n",
            "iter 276 train_cost:  1.0555143 train_acc:  0.6953125 test_cost:  1.0668805 test_acc:  0.65625\n",
            "iter 277 train_cost:  1.0047169 train_acc:  0.7109375 test_cost:  1.0800476 test_acc:  0.6484375\n",
            "iter 278 train_cost:  0.8007633 train_acc:  0.6875 test_cost:  1.116959 test_acc:  0.6484375\n",
            "iter 279 train_cost:  1.1536856 train_acc:  0.6015625 test_cost:  1.3406186 test_acc:  0.640625\n",
            "iter 280 train_cost:  1.1426305 train_acc:  0.6171875 test_cost:  0.85074884 test_acc:  0.6796875\n",
            "iter 281 train_cost:  1.1993748 train_acc:  0.6328125 test_cost:  1.2439467 test_acc:  0.5703125\n",
            "iter 282 train_cost:  1.2996982 train_acc:  0.546875 test_cost:  1.0206475 test_acc:  0.671875\n",
            "iter 283 train_cost:  0.9459479 train_acc:  0.71875 test_cost:  1.3937981 test_acc:  0.546875\n",
            "iter 284 train_cost:  1.4614275 train_acc:  0.5546875 test_cost:  1.0622213 test_acc:  0.65625\n",
            "iter 285 train_cost:  1.0424104 train_acc:  0.640625 test_cost:  0.9648691 test_acc:  0.6875\n",
            "iter 286 train_cost:  0.9264207 train_acc:  0.7265625 test_cost:  1.1794322 test_acc:  0.6328125\n",
            "iter 287 train_cost:  1.193326 train_acc:  0.59375 test_cost:  1.2117469 test_acc:  0.6484375\n",
            "iter 288 train_cost:  0.95776045 train_acc:  0.6640625 test_cost:  0.926466 test_acc:  0.6953125\n",
            "iter 289 train_cost:  1.1410341 train_acc:  0.640625 test_cost:  1.2027079 test_acc:  0.5703125\n",
            "iter 290 train_cost:  1.0801796 train_acc:  0.6484375 test_cost:  1.0346224 test_acc:  0.625\n",
            "iter 291 train_cost:  1.1192385 train_acc:  0.640625 test_cost:  1.1260059 test_acc:  0.6484375\n",
            "iter 292 train_cost:  1.1728162 train_acc:  0.640625 test_cost:  1.0681323 test_acc:  0.671875\n",
            "iter 293 train_cost:  0.8291538 train_acc:  0.71875 test_cost:  1.2038864 test_acc:  0.6328125\n",
            "iter 294 train_cost:  1.035874 train_acc:  0.6953125 test_cost:  1.043412 test_acc:  0.6875\n",
            "iter 295 train_cost:  0.9391639 train_acc:  0.6875 test_cost:  1.6518977 test_acc:  0.4921875\n",
            "iter 296 train_cost:  1.1861322 train_acc:  0.59375 test_cost:  1.0115354 test_acc:  0.7109375\n",
            "iter 297 train_cost:  1.028894 train_acc:  0.6875 test_cost:  0.93782556 test_acc:  0.6796875\n",
            "iter 298 train_cost:  0.9679894 train_acc:  0.7421875 test_cost:  1.337197 test_acc:  0.609375\n",
            "iter 299 train_cost:  1.233644 train_acc:  0.625 test_cost:  0.8863753 test_acc:  0.703125\n",
            "iter 300 train_cost:  1.2316601 train_acc:  0.609375 test_cost:  0.9862877 test_acc:  0.6796875\n",
            "iter 301 train_cost:  0.9782261 train_acc:  0.6953125 test_cost:  0.9649948 test_acc:  0.65625\n",
            "iter 302 train_cost:  1.0432751 train_acc:  0.6171875 test_cost:  0.9643047 test_acc:  0.734375\n",
            "iter 303 train_cost:  0.9462785 train_acc:  0.7421875 test_cost:  1.1518843 test_acc:  0.625\n",
            "iter 304 train_cost:  0.9244409 train_acc:  0.6953125 test_cost:  1.0869138 test_acc:  0.6875\n",
            "iter 305 train_cost:  1.1031034 train_acc:  0.6484375 test_cost:  0.8458467 test_acc:  0.703125\n",
            "iter 306 train_cost:  1.0641042 train_acc:  0.671875 test_cost:  1.0712001 test_acc:  0.7109375\n",
            "iter 307 train_cost:  0.97815776 train_acc:  0.7265625 test_cost:  0.84006107 test_acc:  0.7421875\n",
            "iter 308 train_cost:  0.99043405 train_acc:  0.6875 test_cost:  1.2356198 test_acc:  0.625\n",
            "iter 309 train_cost:  1.0488476 train_acc:  0.7109375 test_cost:  1.0934997 test_acc:  0.6875\n",
            "iter 310 train_cost:  0.92618465 train_acc:  0.6953125 test_cost:  0.96649325 test_acc:  0.6640625\n",
            "iter 311 train_cost:  1.0920722 train_acc:  0.6640625 test_cost:  0.9249593 test_acc:  0.71875\n",
            "iter 312 train_cost:  1.2064044 train_acc:  0.625 test_cost:  1.0469438 test_acc:  0.65625\n",
            "iter 313 train_cost:  0.7700116 train_acc:  0.75 test_cost:  1.1724424 test_acc:  0.6328125\n",
            "iter 314 train_cost:  1.1885844 train_acc:  0.609375 test_cost:  0.9602535 test_acc:  0.6875\n",
            "iter 315 train_cost:  0.83398443 train_acc:  0.71875 test_cost:  1.3036518 test_acc:  0.6171875\n",
            "iter 316 train_cost:  0.935548 train_acc:  0.671875 test_cost:  0.9569925 test_acc:  0.65625\n",
            "iter 317 train_cost:  1.1671871 train_acc:  0.59375 test_cost:  1.1410537 test_acc:  0.6328125\n",
            "iter 318 train_cost:  1.09338 train_acc:  0.6328125 test_cost:  0.9076257 test_acc:  0.75\n",
            "iter 319 train_cost:  0.8596121 train_acc:  0.7421875 test_cost:  0.898177 test_acc:  0.7109375\n",
            "iter 320 train_cost:  1.1524794 train_acc:  0.6875 test_cost:  0.97900915 test_acc:  0.6640625\n",
            "iter 321 train_cost:  0.95641106 train_acc:  0.6484375 test_cost:  1.133343 test_acc:  0.6875\n",
            "iter 322 train_cost:  0.97956634 train_acc:  0.703125 test_cost:  0.94858253 test_acc:  0.671875\n",
            "iter 323 train_cost:  0.82231605 train_acc:  0.734375 test_cost:  0.87231874 test_acc:  0.703125\n",
            "iter 324 train_cost:  1.0016268 train_acc:  0.734375 test_cost:  0.98950416 test_acc:  0.703125\n",
            "iter 325 train_cost:  1.0907078 train_acc:  0.6640625 test_cost:  1.2148641 test_acc:  0.6484375\n",
            "iter 326 train_cost:  0.76147866 train_acc:  0.78125 test_cost:  0.98694146 test_acc:  0.703125\n",
            "iter 327 train_cost:  0.91792107 train_acc:  0.671875 test_cost:  0.9649012 test_acc:  0.6796875\n",
            "iter 328 train_cost:  1.2759073 train_acc:  0.65625 test_cost:  0.9948199 test_acc:  0.6875\n",
            "iter 329 train_cost:  1.1590657 train_acc:  0.6875 test_cost:  0.8677635 test_acc:  0.7265625\n",
            "iter 330 train_cost:  1.25015 train_acc:  0.6328125 test_cost:  0.8297529 test_acc:  0.6953125\n",
            "iter 331 train_cost:  1.1226399 train_acc:  0.6796875 test_cost:  0.9417444 test_acc:  0.65625\n",
            "iter 332 train_cost:  0.88640255 train_acc:  0.6875 test_cost:  0.81052125 test_acc:  0.71875\n",
            "iter 333 train_cost:  0.9963487 train_acc:  0.6875 test_cost:  1.002628 test_acc:  0.6875\n",
            "iter 334 train_cost:  0.89831793 train_acc:  0.7421875 test_cost:  0.9269786 test_acc:  0.7109375\n",
            "iter 335 train_cost:  0.8575535 train_acc:  0.7265625 test_cost:  1.0799704 test_acc:  0.6484375\n",
            "iter 336 train_cost:  0.81019384 train_acc:  0.7109375 test_cost:  1.0512305 test_acc:  0.6875\n",
            "iter 337 train_cost:  0.9479525 train_acc:  0.7265625 test_cost:  0.8886162 test_acc:  0.71875\n",
            "iter 338 train_cost:  0.9234212 train_acc:  0.7265625 test_cost:  0.94482636 test_acc:  0.6640625\n",
            "iter 339 train_cost:  0.9724109 train_acc:  0.6875 test_cost:  0.8515356 test_acc:  0.7265625\n",
            "iter 340 train_cost:  0.7114054 train_acc:  0.75 test_cost:  1.0631206 test_acc:  0.6484375\n",
            "iter 341 train_cost:  1.0567155 train_acc:  0.6640625 test_cost:  0.92041504 test_acc:  0.6953125\n",
            "iter 342 train_cost:  0.9118543 train_acc:  0.75 test_cost:  1.2708011 test_acc:  0.59375\n",
            "iter 343 train_cost:  0.9955711 train_acc:  0.671875 test_cost:  0.95040053 test_acc:  0.6875\n",
            "iter 344 train_cost:  1.1266246 train_acc:  0.640625 test_cost:  1.0385504 test_acc:  0.671875\n",
            "iter 345 train_cost:  0.9981848 train_acc:  0.6640625 test_cost:  0.9687708 test_acc:  0.6875\n",
            "iter 346 train_cost:  1.0697517 train_acc:  0.765625 test_cost:  0.8933433 test_acc:  0.6875\n",
            "iter 347 train_cost:  1.0929 train_acc:  0.6171875 test_cost:  0.8849671 test_acc:  0.7109375\n",
            "iter 348 train_cost:  1.1552604 train_acc:  0.6328125 test_cost:  1.1615965 test_acc:  0.6484375\n",
            "iter 349 train_cost:  0.9144827 train_acc:  0.703125 test_cost:  1.2103548 test_acc:  0.65625\n",
            "iter 350 train_cost:  1.0078747 train_acc:  0.6875 test_cost:  0.9115767 test_acc:  0.71875\n",
            "iter 351 train_cost:  0.9816917 train_acc:  0.6875 test_cost:  1.0353217 test_acc:  0.6796875\n",
            "iter 352 train_cost:  1.0201318 train_acc:  0.6875 test_cost:  1.1438594 test_acc:  0.640625\n",
            "iter 353 train_cost:  0.8475008 train_acc:  0.703125 test_cost:  0.9292975 test_acc:  0.7109375\n",
            "iter 354 train_cost:  0.988376 train_acc:  0.6953125 test_cost:  1.0129712 test_acc:  0.6875\n",
            "iter 355 train_cost:  0.9482857 train_acc:  0.703125 test_cost:  0.8365933 test_acc:  0.6953125\n",
            "iter 356 train_cost:  0.8010513 train_acc:  0.75 test_cost:  0.9413962 test_acc:  0.6953125\n",
            "iter 357 train_cost:  0.7923131 train_acc:  0.7734375 test_cost:  1.1825086 test_acc:  0.65625\n",
            "iter 358 train_cost:  0.88522923 train_acc:  0.734375 test_cost:  1.1089157 test_acc:  0.640625\n",
            "iter 359 train_cost:  1.2110593 train_acc:  0.65625 test_cost:  0.93004483 test_acc:  0.7109375\n",
            "iter 360 train_cost:  0.8737769 train_acc:  0.703125 test_cost:  1.0104934 test_acc:  0.71875\n",
            "iter 361 train_cost:  0.9504633 train_acc:  0.6875 test_cost:  0.8235245 test_acc:  0.7265625\n",
            "iter 362 train_cost:  0.7834704 train_acc:  0.7265625 test_cost:  1.1022029 test_acc:  0.6015625\n",
            "iter 363 train_cost:  0.92251754 train_acc:  0.6796875 test_cost:  0.7227572 test_acc:  0.7578125\n",
            "iter 364 train_cost:  0.93731874 train_acc:  0.6796875 test_cost:  0.86189395 test_acc:  0.7109375\n",
            "iter 365 train_cost:  0.8192835 train_acc:  0.7265625 test_cost:  0.9609736 test_acc:  0.7109375\n",
            "iter 366 train_cost:  0.97362757 train_acc:  0.671875 test_cost:  0.77837825 test_acc:  0.7421875\n",
            "iter 367 train_cost:  1.0915799 train_acc:  0.6484375 test_cost:  0.6939399 test_acc:  0.7265625\n",
            "iter 368 train_cost:  1.0145457 train_acc:  0.6953125 test_cost:  0.8526732 test_acc:  0.6875\n",
            "iter 369 train_cost:  0.82494736 train_acc:  0.71875 test_cost:  0.88280034 test_acc:  0.75\n",
            "iter 370 train_cost:  0.7253861 train_acc:  0.765625 test_cost:  0.9093289 test_acc:  0.6875\n",
            "iter 371 train_cost:  1.1677908 train_acc:  0.6796875 test_cost:  0.7852217 test_acc:  0.7890625\n",
            "iter 372 train_cost:  1.0875363 train_acc:  0.6953125 test_cost:  0.99511296 test_acc:  0.6796875\n",
            "iter 373 train_cost:  0.89996886 train_acc:  0.6953125 test_cost:  0.74454194 test_acc:  0.75\n",
            "iter 374 train_cost:  0.8137057 train_acc:  0.78125 test_cost:  0.89004195 test_acc:  0.6953125\n",
            "iter 375 train_cost:  1.263187 train_acc:  0.6640625 test_cost:  0.8386484 test_acc:  0.75\n",
            "iter 376 train_cost:  0.84661317 train_acc:  0.7109375 test_cost:  0.85588455 test_acc:  0.7265625\n",
            "iter 377 train_cost:  0.89196527 train_acc:  0.71875 test_cost:  0.93237615 test_acc:  0.703125\n",
            "iter 378 train_cost:  0.72798914 train_acc:  0.75 test_cost:  0.9576118 test_acc:  0.6796875\n",
            "iter 379 train_cost:  0.7499212 train_acc:  0.75 test_cost:  1.2669904 test_acc:  0.625\n",
            "iter 380 train_cost:  0.85209215 train_acc:  0.703125 test_cost:  0.7466806 test_acc:  0.8203125\n",
            "iter 381 train_cost:  1.2087138 train_acc:  0.65625 test_cost:  0.6435889 test_acc:  0.7890625\n",
            "iter 382 train_cost:  0.9769478 train_acc:  0.6796875 test_cost:  0.7887346 test_acc:  0.7109375\n",
            "iter 383 train_cost:  1.0138683 train_acc:  0.6796875 test_cost:  0.82351017 test_acc:  0.7578125\n",
            "iter 384 train_cost:  1.0140948 train_acc:  0.7109375 test_cost:  0.75210726 test_acc:  0.7421875\n",
            "iter 385 train_cost:  1.0577354 train_acc:  0.6484375 test_cost:  1.0928849 test_acc:  0.6640625\n",
            "iter 386 train_cost:  0.6642114 train_acc:  0.796875 test_cost:  0.8795541 test_acc:  0.7109375\n",
            "iter 387 train_cost:  0.6805127 train_acc:  0.7421875 test_cost:  0.98759764 test_acc:  0.703125\n",
            "iter 388 train_cost:  0.854692 train_acc:  0.7109375 test_cost:  0.85286367 test_acc:  0.703125\n",
            "iter 389 train_cost:  0.76920897 train_acc:  0.734375 test_cost:  0.9522189 test_acc:  0.6875\n",
            "iter 390 train_cost:  0.8960724 train_acc:  0.71875 test_cost:  0.78390837 test_acc:  0.7578125\n",
            "iter 391 train_cost:  0.8695968 train_acc:  0.734375 test_cost:  0.90965945 test_acc:  0.65625\n",
            "iter 392 train_cost:  0.8774328 train_acc:  0.7578125 test_cost:  0.8544277 test_acc:  0.703125\n",
            "iter 393 train_cost:  1.0361943 train_acc:  0.7265625 test_cost:  0.8335614 test_acc:  0.765625\n",
            "iter 394 train_cost:  0.9751862 train_acc:  0.6328125 test_cost:  0.7711231 test_acc:  0.7578125\n",
            "iter 395 train_cost:  0.898202 train_acc:  0.671875 test_cost:  0.9043146 test_acc:  0.71875\n",
            "iter 396 train_cost:  0.68648267 train_acc:  0.796875 test_cost:  1.0415179 test_acc:  0.7265625\n",
            "iter 397 train_cost:  0.91278076 train_acc:  0.7421875 test_cost:  0.83031106 test_acc:  0.7421875\n",
            "iter 398 train_cost:  0.9110106 train_acc:  0.7109375 test_cost:  0.86690533 test_acc:  0.6796875\n",
            "iter 399 train_cost:  0.87176526 train_acc:  0.6953125 test_cost:  0.98693705 test_acc:  0.71875\n",
            "iter 400 train_cost:  0.7520392 train_acc:  0.7421875 test_cost:  0.97158664 test_acc:  0.6640625\n",
            "iter 401 train_cost:  0.9205002 train_acc:  0.6328125 test_cost:  0.8069576 test_acc:  0.75\n",
            "iter 402 train_cost:  0.90008634 train_acc:  0.6953125 test_cost:  0.99525636 test_acc:  0.71875\n",
            "iter 403 train_cost:  0.8148889 train_acc:  0.6953125 test_cost:  0.6486467 test_acc:  0.734375\n",
            "iter 404 train_cost:  0.9470061 train_acc:  0.7265625 test_cost:  0.9166531 test_acc:  0.7109375\n",
            "iter 405 train_cost:  0.9733572 train_acc:  0.703125 test_cost:  1.0016288 test_acc:  0.71875\n",
            "iter 406 train_cost:  0.67768645 train_acc:  0.78125 test_cost:  0.7527812 test_acc:  0.7734375\n",
            "iter 407 train_cost:  0.86756015 train_acc:  0.6953125 test_cost:  0.90380526 test_acc:  0.7109375\n",
            "iter 408 train_cost:  0.8199772 train_acc:  0.734375 test_cost:  0.8826241 test_acc:  0.703125\n",
            "iter 409 train_cost:  0.97216076 train_acc:  0.7109375 test_cost:  0.7599837 test_acc:  0.734375\n",
            "iter 410 train_cost:  0.9127933 train_acc:  0.6875 test_cost:  0.9517803 test_acc:  0.6953125\n",
            "iter 411 train_cost:  0.8116181 train_acc:  0.71875 test_cost:  0.98242867 test_acc:  0.671875\n",
            "iter 412 train_cost:  0.62243426 train_acc:  0.8046875 test_cost:  0.6234275 test_acc:  0.8125\n",
            "iter 413 train_cost:  0.8675066 train_acc:  0.78125 test_cost:  0.9395033 test_acc:  0.6875\n",
            "iter 414 train_cost:  0.8969468 train_acc:  0.71875 test_cost:  0.77174026 test_acc:  0.7578125\n",
            "iter 415 train_cost:  0.9549812 train_acc:  0.71875 test_cost:  0.82131195 test_acc:  0.7265625\n",
            "iter 416 train_cost:  0.9339086 train_acc:  0.671875 test_cost:  0.78462964 test_acc:  0.703125\n",
            "iter 417 train_cost:  0.98350066 train_acc:  0.6875 test_cost:  0.8308349 test_acc:  0.7109375\n",
            "iter 418 train_cost:  0.840406 train_acc:  0.734375 test_cost:  0.7396741 test_acc:  0.7421875\n",
            "iter 419 train_cost:  0.74806273 train_acc:  0.8125 test_cost:  0.76967895 test_acc:  0.75\n",
            "iter 420 train_cost:  1.0524249 train_acc:  0.7109375 test_cost:  0.7342222 test_acc:  0.75\n",
            "iter 421 train_cost:  1.009191 train_acc:  0.703125 test_cost:  0.8861687 test_acc:  0.7109375\n",
            "iter 422 train_cost:  0.81714904 train_acc:  0.6953125 test_cost:  0.7732109 test_acc:  0.75\n",
            "iter 423 train_cost:  0.93459356 train_acc:  0.71875 test_cost:  0.8851242 test_acc:  0.6875\n",
            "iter 424 train_cost:  0.8633857 train_acc:  0.7265625 test_cost:  0.76295936 test_acc:  0.7890625\n",
            "iter 425 train_cost:  0.96061707 train_acc:  0.671875 test_cost:  1.0404296 test_acc:  0.671875\n",
            "iter 426 train_cost:  0.7993697 train_acc:  0.765625 test_cost:  1.0421411 test_acc:  0.671875\n",
            "iter 427 train_cost:  0.7597331 train_acc:  0.734375 test_cost:  0.94289494 test_acc:  0.6640625\n",
            "iter 428 train_cost:  0.9094098 train_acc:  0.734375 test_cost:  0.7080911 test_acc:  0.7578125\n",
            "iter 429 train_cost:  0.7415564 train_acc:  0.7421875 test_cost:  0.70514 test_acc:  0.7890625\n",
            "iter 430 train_cost:  0.7593766 train_acc:  0.7734375 test_cost:  1.0033547 test_acc:  0.671875\n",
            "iter 431 train_cost:  0.6818422 train_acc:  0.78125 test_cost:  0.8567396 test_acc:  0.7578125\n",
            "iter 432 train_cost:  0.87296456 train_acc:  0.7890625 test_cost:  1.0037999 test_acc:  0.6875\n",
            "iter 433 train_cost:  0.8307718 train_acc:  0.703125 test_cost:  0.77279437 test_acc:  0.7578125\n",
            "iter 434 train_cost:  0.9206872 train_acc:  0.71875 test_cost:  0.99341345 test_acc:  0.6796875\n",
            "iter 435 train_cost:  0.7902067 train_acc:  0.7421875 test_cost:  0.92429143 test_acc:  0.7265625\n",
            "iter 436 train_cost:  1.1128042 train_acc:  0.671875 test_cost:  0.84555936 test_acc:  0.765625\n",
            "iter 437 train_cost:  1.0396348 train_acc:  0.6953125 test_cost:  0.8912063 test_acc:  0.7421875\n",
            "iter 438 train_cost:  0.8446928 train_acc:  0.7421875 test_cost:  0.85225296 test_acc:  0.75\n",
            "iter 439 train_cost:  0.9153251 train_acc:  0.71875 test_cost:  0.696828 test_acc:  0.78125\n",
            "iter 440 train_cost:  0.96168536 train_acc:  0.7265625 test_cost:  0.74740654 test_acc:  0.7734375\n",
            "iter 441 train_cost:  0.9729162 train_acc:  0.703125 test_cost:  0.83464926 test_acc:  0.75\n",
            "iter 442 train_cost:  0.6412419 train_acc:  0.7734375 test_cost:  0.8966222 test_acc:  0.75\n",
            "iter 443 train_cost:  0.81384766 train_acc:  0.7421875 test_cost:  0.64605576 test_acc:  0.828125\n",
            "iter 444 train_cost:  0.9941261 train_acc:  0.703125 test_cost:  0.7450383 test_acc:  0.7734375\n",
            "iter 445 train_cost:  0.7469313 train_acc:  0.78125 test_cost:  0.89470446 test_acc:  0.71875\n",
            "iter 446 train_cost:  0.77191705 train_acc:  0.7265625 test_cost:  0.8432288 test_acc:  0.7265625\n",
            "iter 447 train_cost:  0.87427694 train_acc:  0.703125 test_cost:  1.0224857 test_acc:  0.6640625\n",
            "iter 448 train_cost:  0.9116445 train_acc:  0.71875 test_cost:  0.6403601 test_acc:  0.8046875\n",
            "iter 449 train_cost:  0.71033007 train_acc:  0.78125 test_cost:  0.84457135 test_acc:  0.7578125\n",
            "iter 450 train_cost:  0.8905653 train_acc:  0.7265625 test_cost:  0.6710669 test_acc:  0.7578125\n",
            "iter 451 train_cost:  0.84397024 train_acc:  0.75 test_cost:  0.7887294 test_acc:  0.7265625\n",
            "iter 452 train_cost:  1.0047047 train_acc:  0.7109375 test_cost:  0.71745056 test_acc:  0.765625\n",
            "iter 453 train_cost:  0.943219 train_acc:  0.703125 test_cost:  0.75869346 test_acc:  0.796875\n",
            "iter 454 train_cost:  0.9561454 train_acc:  0.6796875 test_cost:  0.86389554 test_acc:  0.7421875\n",
            "iter 455 train_cost:  1.0226673 train_acc:  0.7421875 test_cost:  0.6231709 test_acc:  0.7734375\n",
            "iter 456 train_cost:  0.97511744 train_acc:  0.6875 test_cost:  1.0101221 test_acc:  0.609375\n",
            "iter 457 train_cost:  0.9285007 train_acc:  0.71875 test_cost:  0.7594411 test_acc:  0.78125\n",
            "iter 458 train_cost:  0.7884318 train_acc:  0.8203125 test_cost:  0.96433806 test_acc:  0.7421875\n",
            "iter 459 train_cost:  0.86291176 train_acc:  0.7578125 test_cost:  0.7719949 test_acc:  0.71875\n",
            "iter 460 train_cost:  0.69105 train_acc:  0.796875 test_cost:  0.8344586 test_acc:  0.734375\n",
            "iter 461 train_cost:  0.78070474 train_acc:  0.7421875 test_cost:  0.8227787 test_acc:  0.6875\n",
            "iter 462 train_cost:  0.7666738 train_acc:  0.6953125 test_cost:  0.7709832 test_acc:  0.765625\n",
            "iter 463 train_cost:  0.66547704 train_acc:  0.7421875 test_cost:  0.726906 test_acc:  0.7734375\n",
            "iter 464 train_cost:  0.7484696 train_acc:  0.75 test_cost:  0.7345575 test_acc:  0.7734375\n",
            "iter 465 train_cost:  0.8760795 train_acc:  0.7421875 test_cost:  0.93070775 test_acc:  0.7265625\n",
            "iter 466 train_cost:  0.6869086 train_acc:  0.75 test_cost:  0.5760215 test_acc:  0.8203125\n",
            "iter 467 train_cost:  0.60217625 train_acc:  0.8046875 test_cost:  0.7516491 test_acc:  0.7890625\n",
            "iter 468 train_cost:  1.0871747 train_acc:  0.7421875 test_cost:  0.89027226 test_acc:  0.7109375\n",
            "iter 469 train_cost:  0.8866463 train_acc:  0.7265625 test_cost:  0.8607307 test_acc:  0.7265625\n",
            "iter 470 train_cost:  0.75512314 train_acc:  0.75 test_cost:  0.87871826 test_acc:  0.71875\n",
            "iter 471 train_cost:  0.83062166 train_acc:  0.7734375 test_cost:  0.6117306 test_acc:  0.78125\n",
            "iter 472 train_cost:  0.89247733 train_acc:  0.703125 test_cost:  0.7711899 test_acc:  0.78125\n",
            "iter 473 train_cost:  0.9777627 train_acc:  0.6953125 test_cost:  0.8280631 test_acc:  0.7421875\n",
            "iter 474 train_cost:  0.82715863 train_acc:  0.75 test_cost:  0.82505 test_acc:  0.7578125\n",
            "iter 475 train_cost:  0.94051427 train_acc:  0.71875 test_cost:  0.82068455 test_acc:  0.75\n",
            "iter 476 train_cost:  0.6947812 train_acc:  0.8046875 test_cost:  0.72912866 test_acc:  0.75\n",
            "iter 477 train_cost:  0.8914081 train_acc:  0.7421875 test_cost:  0.54456866 test_acc:  0.8125\n",
            "iter 478 train_cost:  0.8295675 train_acc:  0.7734375 test_cost:  0.78031945 test_acc:  0.71875\n",
            "iter 479 train_cost:  0.82928073 train_acc:  0.7265625 test_cost:  0.7637477 test_acc:  0.765625\n",
            "iter 480 train_cost:  0.7183334 train_acc:  0.765625 test_cost:  0.4955718 test_acc:  0.84375\n",
            "iter 481 train_cost:  0.79911596 train_acc:  0.7578125 test_cost:  0.5605682 test_acc:  0.78125\n",
            "iter 482 train_cost:  0.66974103 train_acc:  0.75 test_cost:  0.5972951 test_acc:  0.78125\n",
            "iter 483 train_cost:  0.7535388 train_acc:  0.7421875 test_cost:  0.7595166 test_acc:  0.75\n",
            "iter 484 train_cost:  0.6666109 train_acc:  0.7734375 test_cost:  0.69373447 test_acc:  0.7421875\n",
            "iter 485 train_cost:  0.81650656 train_acc:  0.7421875 test_cost:  1.0186685 test_acc:  0.703125\n",
            "iter 486 train_cost:  0.9548398 train_acc:  0.75 test_cost:  0.8987293 test_acc:  0.6875\n",
            "iter 487 train_cost:  0.9351729 train_acc:  0.765625 test_cost:  0.5382509 test_acc:  0.7890625\n",
            "iter 488 train_cost:  0.89325726 train_acc:  0.7578125 test_cost:  0.735132 test_acc:  0.765625\n",
            "iter 489 train_cost:  0.6903445 train_acc:  0.78125 test_cost:  0.93093157 test_acc:  0.734375\n",
            "iter 490 train_cost:  0.8456567 train_acc:  0.765625 test_cost:  0.7973039 test_acc:  0.7890625\n",
            "iter 491 train_cost:  0.7984339 train_acc:  0.7265625 test_cost:  0.60988283 test_acc:  0.7734375\n",
            "iter 492 train_cost:  0.6641067 train_acc:  0.7734375 test_cost:  0.7136972 test_acc:  0.7734375\n",
            "iter 493 train_cost:  0.79769933 train_acc:  0.7109375 test_cost:  0.604508 test_acc:  0.8125\n",
            "iter 494 train_cost:  0.72545207 train_acc:  0.796875 test_cost:  0.65359885 test_acc:  0.78125\n",
            "iter 495 train_cost:  0.6675702 train_acc:  0.8125 test_cost:  0.758196 test_acc:  0.75\n",
            "iter 496 train_cost:  0.92620915 train_acc:  0.6875 test_cost:  0.7495649 test_acc:  0.7578125\n",
            "iter 497 train_cost:  0.6320983 train_acc:  0.8515625 test_cost:  0.8955918 test_acc:  0.734375\n",
            "iter 498 train_cost:  0.821408 train_acc:  0.7734375 test_cost:  0.6922525 test_acc:  0.7734375\n",
            "iter 499 train_cost:  0.69599664 train_acc:  0.78125 test_cost:  0.66758704 test_acc:  0.7890625\n",
            "iter 500 train_cost:  0.7249302 train_acc:  0.8046875 test_cost:  0.84789145 test_acc:  0.7265625\n",
            "iter 501 train_cost:  0.8665148 train_acc:  0.6875 test_cost:  0.7747943 test_acc:  0.75\n",
            "iter 502 train_cost:  0.71699643 train_acc:  0.734375 test_cost:  0.7294152 test_acc:  0.7734375\n",
            "iter 503 train_cost:  0.6069776 train_acc:  0.7578125 test_cost:  0.5937459 test_acc:  0.8203125\n",
            "iter 504 train_cost:  0.70295054 train_acc:  0.796875 test_cost:  0.67897123 test_acc:  0.8046875\n",
            "iter 505 train_cost:  0.90716124 train_acc:  0.734375 test_cost:  0.80071956 test_acc:  0.7109375\n",
            "iter 506 train_cost:  0.7943468 train_acc:  0.7421875 test_cost:  0.8967141 test_acc:  0.703125\n",
            "iter 507 train_cost:  0.7628555 train_acc:  0.7265625 test_cost:  0.6104806 test_acc:  0.796875\n",
            "iter 508 train_cost:  0.8800639 train_acc:  0.7421875 test_cost:  0.76239157 test_acc:  0.703125\n",
            "iter 509 train_cost:  0.83771026 train_acc:  0.7109375 test_cost:  0.74494505 test_acc:  0.7578125\n",
            "iter 510 train_cost:  0.75781876 train_acc:  0.8125 test_cost:  0.8153521 test_acc:  0.734375\n",
            "iter 511 train_cost:  0.56098664 train_acc:  0.8203125 test_cost:  0.78611743 test_acc:  0.75\n",
            "iter 512 train_cost:  0.7653736 train_acc:  0.765625 test_cost:  0.5371402 test_acc:  0.8046875\n",
            "iter 513 train_cost:  0.72198904 train_acc:  0.7578125 test_cost:  0.8092618 test_acc:  0.734375\n",
            "iter 514 train_cost:  0.72259635 train_acc:  0.75 test_cost:  0.44837952 test_acc:  0.8203125\n",
            "iter 515 train_cost:  0.6208008 train_acc:  0.8125 test_cost:  0.81008685 test_acc:  0.75\n",
            "iter 516 train_cost:  0.92340493 train_acc:  0.6640625 test_cost:  0.8768523 test_acc:  0.7578125\n",
            "iter 517 train_cost:  0.68802834 train_acc:  0.78125 test_cost:  0.51392126 test_acc:  0.828125\n",
            "iter 518 train_cost:  0.5799681 train_acc:  0.7890625 test_cost:  0.5918342 test_acc:  0.8203125\n",
            "iter 519 train_cost:  0.77325475 train_acc:  0.71875 test_cost:  0.83818007 test_acc:  0.734375\n",
            "iter 520 train_cost:  0.8495282 train_acc:  0.7109375 test_cost:  0.81885314 test_acc:  0.734375\n",
            "iter 521 train_cost:  0.66162455 train_acc:  0.7890625 test_cost:  0.5645146 test_acc:  0.8203125\n",
            "iter 522 train_cost:  0.7279389 train_acc:  0.7890625 test_cost:  0.765484 test_acc:  0.7578125\n",
            "iter 523 train_cost:  0.799289 train_acc:  0.703125 test_cost:  0.7957109 test_acc:  0.7265625\n",
            "iter 524 train_cost:  0.70504534 train_acc:  0.78125 test_cost:  0.5128986 test_acc:  0.828125\n",
            "iter 525 train_cost:  0.5894537 train_acc:  0.796875 test_cost:  0.8422561 test_acc:  0.796875\n",
            "iter 526 train_cost:  0.6700665 train_acc:  0.765625 test_cost:  0.5624688 test_acc:  0.859375\n",
            "iter 527 train_cost:  0.7579788 train_acc:  0.7890625 test_cost:  0.6761626 test_acc:  0.75\n",
            "iter 528 train_cost:  0.6678966 train_acc:  0.7890625 test_cost:  0.63733923 test_acc:  0.78125\n",
            "iter 529 train_cost:  0.8366452 train_acc:  0.7578125 test_cost:  0.7858475 test_acc:  0.7734375\n",
            "iter 530 train_cost:  0.528638 train_acc:  0.84375 test_cost:  0.6355597 test_acc:  0.7890625\n",
            "iter 531 train_cost:  0.75810754 train_acc:  0.7265625 test_cost:  0.7825984 test_acc:  0.7109375\n",
            "iter 532 train_cost:  0.8097686 train_acc:  0.7578125 test_cost:  0.67827433 test_acc:  0.75\n",
            "iter 533 train_cost:  0.814332 train_acc:  0.75 test_cost:  0.7185438 test_acc:  0.7890625\n",
            "iter 534 train_cost:  0.8986547 train_acc:  0.6875 test_cost:  0.8695872 test_acc:  0.765625\n",
            "iter 535 train_cost:  0.6993729 train_acc:  0.7734375 test_cost:  0.83105856 test_acc:  0.734375\n",
            "iter 536 train_cost:  0.6331099 train_acc:  0.796875 test_cost:  1.0279661 test_acc:  0.7265625\n",
            "iter 537 train_cost:  0.8324813 train_acc:  0.703125 test_cost:  0.7068858 test_acc:  0.78125\n",
            "iter 538 train_cost:  0.564975 train_acc:  0.8125 test_cost:  0.6938937 test_acc:  0.7890625\n",
            "iter 539 train_cost:  0.59763336 train_acc:  0.8125 test_cost:  0.5461544 test_acc:  0.7890625\n",
            "iter 540 train_cost:  0.78242135 train_acc:  0.7265625 test_cost:  0.6494524 test_acc:  0.7890625\n",
            "iter 541 train_cost:  0.8454697 train_acc:  0.7265625 test_cost:  0.5965903 test_acc:  0.78125\n",
            "iter 542 train_cost:  0.72837263 train_acc:  0.7421875 test_cost:  0.7058191 test_acc:  0.796875\n",
            "iter 543 train_cost:  0.8250688 train_acc:  0.765625 test_cost:  0.6739411 test_acc:  0.7578125\n",
            "iter 544 train_cost:  0.6857704 train_acc:  0.7734375 test_cost:  0.62485975 test_acc:  0.8046875\n",
            "iter 545 train_cost:  0.512422 train_acc:  0.828125 test_cost:  0.7914257 test_acc:  0.7265625\n",
            "iter 546 train_cost:  0.7218318 train_acc:  0.7734375 test_cost:  0.82192624 test_acc:  0.78125\n",
            "iter 547 train_cost:  0.767228 train_acc:  0.78125 test_cost:  0.5088627 test_acc:  0.859375\n",
            "iter 548 train_cost:  0.5906615 train_acc:  0.765625 test_cost:  0.90912724 test_acc:  0.7421875\n",
            "iter 549 train_cost:  0.8538835 train_acc:  0.765625 test_cost:  0.6349052 test_acc:  0.8203125\n",
            "iter 550 train_cost:  0.6929318 train_acc:  0.78125 test_cost:  0.97316587 test_acc:  0.6953125\n",
            "iter 551 train_cost:  0.51926017 train_acc:  0.828125 test_cost:  0.6487414 test_acc:  0.859375\n",
            "iter 552 train_cost:  0.67841065 train_acc:  0.765625 test_cost:  0.64571166 test_acc:  0.796875\n",
            "iter 553 train_cost:  0.72655505 train_acc:  0.78125 test_cost:  0.6803141 test_acc:  0.7578125\n",
            "iter 554 train_cost:  0.5820712 train_acc:  0.8046875 test_cost:  0.69992614 test_acc:  0.75\n",
            "iter 555 train_cost:  0.7202099 train_acc:  0.78125 test_cost:  0.79814124 test_acc:  0.7734375\n",
            "iter 556 train_cost:  0.62433326 train_acc:  0.78125 test_cost:  0.5220213 test_acc:  0.8046875\n",
            "iter 557 train_cost:  0.5675942 train_acc:  0.8125 test_cost:  0.7083024 test_acc:  0.765625\n",
            "iter 558 train_cost:  0.8250185 train_acc:  0.7734375 test_cost:  0.8000784 test_acc:  0.7578125\n",
            "iter 559 train_cost:  0.6926098 train_acc:  0.7734375 test_cost:  0.7404711 test_acc:  0.7265625\n",
            "iter 560 train_cost:  0.7017726 train_acc:  0.8046875 test_cost:  0.62424034 test_acc:  0.7890625\n",
            "iter 561 train_cost:  0.68143964 train_acc:  0.7890625 test_cost:  0.6491789 test_acc:  0.8046875\n",
            "iter 562 train_cost:  0.8710325 train_acc:  0.78125 test_cost:  0.63430643 test_acc:  0.7890625\n",
            "iter 563 train_cost:  0.6850779 train_acc:  0.7890625 test_cost:  0.6961597 test_acc:  0.7890625\n",
            "iter 564 train_cost:  0.6803949 train_acc:  0.78125 test_cost:  0.5662662 test_acc:  0.7890625\n",
            "iter 565 train_cost:  0.84278464 train_acc:  0.7265625 test_cost:  0.6560607 test_acc:  0.796875\n",
            "iter 566 train_cost:  0.96664923 train_acc:  0.7109375 test_cost:  0.6706561 test_acc:  0.765625\n",
            "iter 567 train_cost:  0.6501884 train_acc:  0.78125 test_cost:  0.6503949 test_acc:  0.78125\n",
            "iter 568 train_cost:  0.631436 train_acc:  0.828125 test_cost:  0.5786269 test_acc:  0.78125\n",
            "iter 569 train_cost:  0.5860294 train_acc:  0.8515625 test_cost:  0.8653407 test_acc:  0.7421875\n",
            "iter 570 train_cost:  0.7997758 train_acc:  0.71875 test_cost:  0.6687699 test_acc:  0.8125\n",
            "iter 571 train_cost:  0.60527074 train_acc:  0.7890625 test_cost:  0.61510533 test_acc:  0.796875\n",
            "iter 572 train_cost:  0.49797645 train_acc:  0.8046875 test_cost:  0.6459733 test_acc:  0.8125\n",
            "iter 573 train_cost:  0.694191 train_acc:  0.78125 test_cost:  0.5950676 test_acc:  0.8125\n",
            "iter 574 train_cost:  0.68108463 train_acc:  0.7734375 test_cost:  0.6787643 test_acc:  0.7890625\n",
            "iter 575 train_cost:  0.7954381 train_acc:  0.765625 test_cost:  0.5991061 test_acc:  0.828125\n",
            "iter 576 train_cost:  0.51886684 train_acc:  0.8046875 test_cost:  0.6403406 test_acc:  0.8203125\n",
            "iter 577 train_cost:  0.8530657 train_acc:  0.78125 test_cost:  0.8710818 test_acc:  0.7109375\n",
            "iter 578 train_cost:  0.5827414 train_acc:  0.78125 test_cost:  0.65910625 test_acc:  0.7578125\n",
            "iter 579 train_cost:  0.6223035 train_acc:  0.828125 test_cost:  0.81289566 test_acc:  0.7578125\n",
            "iter 580 train_cost:  0.6859753 train_acc:  0.7578125 test_cost:  0.76323223 test_acc:  0.7421875\n",
            "iter 581 train_cost:  0.80925155 train_acc:  0.7109375 test_cost:  0.6535638 test_acc:  0.8046875\n",
            "iter 582 train_cost:  0.7151616 train_acc:  0.7578125 test_cost:  0.7058785 test_acc:  0.765625\n",
            "iter 583 train_cost:  0.66201043 train_acc:  0.8203125 test_cost:  0.6721544 test_acc:  0.78125\n",
            "iter 584 train_cost:  0.6755198 train_acc:  0.75 test_cost:  0.9264246 test_acc:  0.75\n",
            "iter 585 train_cost:  0.8517142 train_acc:  0.7421875 test_cost:  0.68055886 test_acc:  0.8125\n",
            "iter 586 train_cost:  0.64577454 train_acc:  0.7734375 test_cost:  0.7280365 test_acc:  0.765625\n",
            "iter 587 train_cost:  0.5511409 train_acc:  0.8125 test_cost:  0.5324479 test_acc:  0.8515625\n",
            "iter 588 train_cost:  0.83259094 train_acc:  0.7578125 test_cost:  0.6354624 test_acc:  0.796875\n",
            "iter 589 train_cost:  0.68812734 train_acc:  0.8359375 test_cost:  0.7172151 test_acc:  0.75\n",
            "iter 590 train_cost:  0.7082045 train_acc:  0.7890625 test_cost:  0.6005547 test_acc:  0.828125\n",
            "iter 591 train_cost:  0.565346 train_acc:  0.8125 test_cost:  0.8637791 test_acc:  0.7421875\n",
            "iter 592 train_cost:  0.6782836 train_acc:  0.7734375 test_cost:  0.8452239 test_acc:  0.765625\n",
            "iter 593 train_cost:  0.6274981 train_acc:  0.8046875 test_cost:  0.85164094 test_acc:  0.7578125\n",
            "iter 594 train_cost:  0.625224 train_acc:  0.7890625 test_cost:  0.57351243 test_acc:  0.8203125\n",
            "iter 595 train_cost:  0.6812227 train_acc:  0.8046875 test_cost:  0.590928 test_acc:  0.796875\n",
            "iter 596 train_cost:  0.7519124 train_acc:  0.796875 test_cost:  0.68105555 test_acc:  0.7734375\n",
            "iter 597 train_cost:  0.62749296 train_acc:  0.8125 test_cost:  0.6930734 test_acc:  0.796875\n",
            "iter 598 train_cost:  0.84319854 train_acc:  0.7421875 test_cost:  0.51996434 test_acc:  0.8359375\n",
            "iter 599 train_cost:  0.6412648 train_acc:  0.8046875 test_cost:  0.3973937 test_acc:  0.8828125\n",
            "iter 600 train_cost:  0.6273006 train_acc:  0.828125 test_cost:  0.7577264 test_acc:  0.765625\n",
            "iter 601 train_cost:  0.90285015 train_acc:  0.71875 test_cost:  0.61226875 test_acc:  0.8359375\n",
            "iter 602 train_cost:  0.57453454 train_acc:  0.84375 test_cost:  0.59549415 test_acc:  0.7734375\n",
            "iter 603 train_cost:  0.6324242 train_acc:  0.7890625 test_cost:  0.5882621 test_acc:  0.8203125\n",
            "iter 604 train_cost:  0.666361 train_acc:  0.8046875 test_cost:  0.67234945 test_acc:  0.8046875\n",
            "iter 605 train_cost:  0.78043723 train_acc:  0.7265625 test_cost:  0.779984 test_acc:  0.7578125\n",
            "iter 606 train_cost:  0.6998904 train_acc:  0.78125 test_cost:  0.84220517 test_acc:  0.734375\n",
            "iter 607 train_cost:  0.7851228 train_acc:  0.7578125 test_cost:  0.699361 test_acc:  0.7578125\n",
            "iter 608 train_cost:  0.5670427 train_acc:  0.8515625 test_cost:  0.7978173 test_acc:  0.7578125\n",
            "iter 609 train_cost:  0.6908126 train_acc:  0.7890625 test_cost:  0.56565315 test_acc:  0.84375\n",
            "iter 610 train_cost:  0.7507822 train_acc:  0.75 test_cost:  0.64002913 test_acc:  0.8125\n",
            "iter 611 train_cost:  0.8308284 train_acc:  0.7578125 test_cost:  0.63015634 test_acc:  0.8046875\n",
            "iter 612 train_cost:  0.5690943 train_acc:  0.796875 test_cost:  0.70379305 test_acc:  0.8125\n",
            "iter 613 train_cost:  0.51909024 train_acc:  0.8046875 test_cost:  0.74873495 test_acc:  0.765625\n",
            "iter 614 train_cost:  0.97024345 train_acc:  0.7109375 test_cost:  0.49583122 test_acc:  0.8359375\n",
            "iter 615 train_cost:  0.5187166 train_acc:  0.8671875 test_cost:  0.68812764 test_acc:  0.75\n",
            "iter 616 train_cost:  0.6435453 train_acc:  0.8046875 test_cost:  0.8786333 test_acc:  0.71875\n",
            "iter 617 train_cost:  0.7497724 train_acc:  0.765625 test_cost:  0.48380816 test_acc:  0.859375\n",
            "iter 618 train_cost:  0.6207614 train_acc:  0.8046875 test_cost:  0.54297876 test_acc:  0.8046875\n",
            "iter 619 train_cost:  0.67208797 train_acc:  0.796875 test_cost:  0.6364284 test_acc:  0.78125\n",
            "iter 620 train_cost:  0.8167677 train_acc:  0.765625 test_cost:  0.46392205 test_acc:  0.875\n",
            "iter 621 train_cost:  0.89327246 train_acc:  0.7265625 test_cost:  0.63798225 test_acc:  0.78125\n",
            "iter 622 train_cost:  0.61383814 train_acc:  0.8125 test_cost:  0.59362125 test_acc:  0.8125\n",
            "iter 623 train_cost:  0.6066927 train_acc:  0.84375 test_cost:  0.58972067 test_acc:  0.8046875\n",
            "iter 624 train_cost:  0.6662835 train_acc:  0.78125 test_cost:  0.7353279 test_acc:  0.7578125\n",
            "iter 625 train_cost:  0.71393275 train_acc:  0.78125 test_cost:  0.6774783 test_acc:  0.7734375\n",
            "iter 626 train_cost:  0.69593275 train_acc:  0.78125 test_cost:  0.7974856 test_acc:  0.765625\n",
            "iter 627 train_cost:  0.55623513 train_acc:  0.796875 test_cost:  0.4800071 test_acc:  0.859375\n",
            "iter 628 train_cost:  0.68460405 train_acc:  0.765625 test_cost:  0.7341325 test_acc:  0.75\n",
            "iter 629 train_cost:  0.61427367 train_acc:  0.7734375 test_cost:  0.6204 test_acc:  0.8515625\n",
            "iter 630 train_cost:  0.7726505 train_acc:  0.7578125 test_cost:  0.5800818 test_acc:  0.84375\n",
            "iter 631 train_cost:  0.57858366 train_acc:  0.796875 test_cost:  0.6292417 test_acc:  0.7734375\n",
            "iter 632 train_cost:  0.584713 train_acc:  0.765625 test_cost:  0.5545346 test_acc:  0.8125\n",
            "iter 633 train_cost:  0.5412842 train_acc:  0.84375 test_cost:  0.49091327 test_acc:  0.84375\n",
            "iter 634 train_cost:  0.53285736 train_acc:  0.84375 test_cost:  0.5368484 test_acc:  0.8203125\n",
            "iter 635 train_cost:  0.6279145 train_acc:  0.796875 test_cost:  0.45043242 test_acc:  0.859375\n",
            "iter 636 train_cost:  0.76054883 train_acc:  0.7578125 test_cost:  0.657306 test_acc:  0.796875\n",
            "iter 637 train_cost:  0.5277294 train_acc:  0.8125 test_cost:  0.67636 test_acc:  0.78125\n",
            "iter 638 train_cost:  0.81214696 train_acc:  0.765625 test_cost:  0.4947161 test_acc:  0.84375\n",
            "iter 639 train_cost:  0.6533663 train_acc:  0.7890625 test_cost:  0.6568845 test_acc:  0.8046875\n",
            "iter 640 train_cost:  0.6976749 train_acc:  0.7890625 test_cost:  0.7000871 test_acc:  0.7890625\n",
            "iter 641 train_cost:  0.71289444 train_acc:  0.71875 test_cost:  0.91910994 test_acc:  0.75\n",
            "iter 642 train_cost:  0.6026931 train_acc:  0.8359375 test_cost:  0.4284702 test_acc:  0.8828125\n",
            "iter 643 train_cost:  0.62544173 train_acc:  0.78125 test_cost:  0.74046135 test_acc:  0.765625\n",
            "iter 644 train_cost:  0.54880667 train_acc:  0.8125 test_cost:  0.6424212 test_acc:  0.8203125\n",
            "iter 645 train_cost:  0.45048094 train_acc:  0.8359375 test_cost:  0.68303424 test_acc:  0.796875\n",
            "iter 646 train_cost:  0.584795 train_acc:  0.8203125 test_cost:  0.49377114 test_acc:  0.828125\n",
            "iter 647 train_cost:  0.6879666 train_acc:  0.796875 test_cost:  0.516716 test_acc:  0.8359375\n",
            "iter 648 train_cost:  0.5007541 train_acc:  0.8359375 test_cost:  0.7056818 test_acc:  0.78125\n",
            "iter 649 train_cost:  0.6922562 train_acc:  0.78125 test_cost:  0.552053 test_acc:  0.8203125\n",
            "iter 650 train_cost:  0.75974923 train_acc:  0.8125 test_cost:  0.63336766 test_acc:  0.7734375\n",
            "iter 651 train_cost:  0.89237857 train_acc:  0.703125 test_cost:  0.6398836 test_acc:  0.8203125\n",
            "iter 652 train_cost:  0.510425 train_acc:  0.828125 test_cost:  0.6504605 test_acc:  0.7734375\n",
            "iter 653 train_cost:  0.55234283 train_acc:  0.796875 test_cost:  0.59798396 test_acc:  0.796875\n",
            "iter 654 train_cost:  0.6393944 train_acc:  0.7890625 test_cost:  0.8058815 test_acc:  0.7890625\n",
            "iter 655 train_cost:  0.5707621 train_acc:  0.8359375 test_cost:  0.75462633 test_acc:  0.7578125\n",
            "iter 656 train_cost:  0.6624697 train_acc:  0.765625 test_cost:  0.58570415 test_acc:  0.8515625\n",
            "iter 657 train_cost:  0.7610178 train_acc:  0.765625 test_cost:  0.5249711 test_acc:  0.796875\n",
            "iter 658 train_cost:  0.52426094 train_acc:  0.8203125 test_cost:  0.5200886 test_acc:  0.828125\n",
            "iter 659 train_cost:  0.530215 train_acc:  0.8359375 test_cost:  0.7462394 test_acc:  0.734375\n",
            "iter 660 train_cost:  0.5564191 train_acc:  0.8125 test_cost:  0.60045326 test_acc:  0.7890625\n",
            "iter 661 train_cost:  0.7367356 train_acc:  0.734375 test_cost:  0.73532903 test_acc:  0.765625\n",
            "iter 662 train_cost:  0.6099508 train_acc:  0.8203125 test_cost:  0.6175777 test_acc:  0.84375\n",
            "iter 663 train_cost:  0.60862863 train_acc:  0.765625 test_cost:  0.54891163 test_acc:  0.8359375\n",
            "iter 664 train_cost:  0.58184224 train_acc:  0.8515625 test_cost:  0.5478718 test_acc:  0.8046875\n",
            "iter 665 train_cost:  0.47290447 train_acc:  0.8671875 test_cost:  0.6449993 test_acc:  0.828125\n",
            "iter 666 train_cost:  0.5925348 train_acc:  0.796875 test_cost:  0.64107335 test_acc:  0.7734375\n",
            "iter 667 train_cost:  0.99338186 train_acc:  0.6640625 test_cost:  0.70080155 test_acc:  0.8046875\n",
            "iter 668 train_cost:  0.83652675 train_acc:  0.7109375 test_cost:  0.6066818 test_acc:  0.828125\n",
            "iter 669 train_cost:  0.4916367 train_acc:  0.859375 test_cost:  0.6516148 test_acc:  0.78125\n",
            "iter 670 train_cost:  0.6480046 train_acc:  0.828125 test_cost:  0.7224526 test_acc:  0.7578125\n",
            "iter 671 train_cost:  0.8914374 train_acc:  0.734375 test_cost:  0.6879443 test_acc:  0.8046875\n",
            "iter 672 train_cost:  0.65038514 train_acc:  0.8125 test_cost:  0.8679544 test_acc:  0.7421875\n",
            "iter 673 train_cost:  0.67183596 train_acc:  0.7890625 test_cost:  0.7319219 test_acc:  0.75\n",
            "iter 674 train_cost:  0.8284452 train_acc:  0.75 test_cost:  0.47989017 test_acc:  0.84375\n",
            "iter 675 train_cost:  0.8922873 train_acc:  0.7109375 test_cost:  0.64394677 test_acc:  0.796875\n",
            "iter 676 train_cost:  0.8077073 train_acc:  0.7734375 test_cost:  0.5023054 test_acc:  0.8359375\n",
            "iter 677 train_cost:  0.60586566 train_acc:  0.8515625 test_cost:  0.6383157 test_acc:  0.7890625\n",
            "iter 678 train_cost:  0.57084 train_acc:  0.8125 test_cost:  0.5618745 test_acc:  0.8671875\n",
            "iter 679 train_cost:  0.72394013 train_acc:  0.765625 test_cost:  0.590711 test_acc:  0.8359375\n",
            "iter 680 train_cost:  0.5430566 train_acc:  0.8515625 test_cost:  0.6703243 test_acc:  0.7578125\n",
            "iter 681 train_cost:  0.5900613 train_acc:  0.78125 test_cost:  0.50388515 test_acc:  0.8515625\n",
            "iter 682 train_cost:  0.6636666 train_acc:  0.7890625 test_cost:  0.6159028 test_acc:  0.828125\n",
            "iter 683 train_cost:  0.6060916 train_acc:  0.78125 test_cost:  0.4952532 test_acc:  0.859375\n",
            "iter 684 train_cost:  0.8278816 train_acc:  0.7734375 test_cost:  0.6124735 test_acc:  0.796875\n",
            "iter 685 train_cost:  0.5395042 train_acc:  0.7890625 test_cost:  0.29958516 test_acc:  0.8828125\n",
            "iter 686 train_cost:  0.7040092 train_acc:  0.75 test_cost:  0.6023304 test_acc:  0.7734375\n",
            "iter 687 train_cost:  0.707828 train_acc:  0.765625 test_cost:  0.69144416 test_acc:  0.7890625\n",
            "iter 688 train_cost:  0.6326232 train_acc:  0.8515625 test_cost:  0.820151 test_acc:  0.7890625\n",
            "iter 689 train_cost:  0.43935665 train_acc:  0.859375 test_cost:  0.55179346 test_acc:  0.8203125\n",
            "iter 690 train_cost:  0.6795928 train_acc:  0.796875 test_cost:  0.5262548 test_acc:  0.8046875\n",
            "iter 691 train_cost:  0.69386435 train_acc:  0.78125 test_cost:  0.51456416 test_acc:  0.8671875\n",
            "iter 692 train_cost:  0.90601957 train_acc:  0.6875 test_cost:  0.45407787 test_acc:  0.8515625\n",
            "iter 693 train_cost:  0.71826136 train_acc:  0.75 test_cost:  0.53715307 test_acc:  0.8203125\n",
            "iter 694 train_cost:  0.71567136 train_acc:  0.7734375 test_cost:  0.55435103 test_acc:  0.8515625\n",
            "iter 695 train_cost:  0.560418 train_acc:  0.8125 test_cost:  0.606067 test_acc:  0.75\n",
            "iter 696 train_cost:  0.43354735 train_acc:  0.8359375 test_cost:  0.38421476 test_acc:  0.875\n",
            "iter 697 train_cost:  0.5908288 train_acc:  0.78125 test_cost:  0.7177558 test_acc:  0.8046875\n",
            "iter 698 train_cost:  0.64390445 train_acc:  0.7734375 test_cost:  0.72947884 test_acc:  0.75\n",
            "iter 699 train_cost:  0.49199829 train_acc:  0.796875 test_cost:  0.52996624 test_acc:  0.8203125\n",
            "iter 700 train_cost:  0.44977668 train_acc:  0.828125 test_cost:  0.5466959 test_acc:  0.8125\n",
            "iter 701 train_cost:  0.58562994 train_acc:  0.8671875 test_cost:  0.3867322 test_acc:  0.8671875\n",
            "iter 702 train_cost:  0.403754 train_acc:  0.8671875 test_cost:  0.4918618 test_acc:  0.8203125\n",
            "iter 703 train_cost:  0.58597434 train_acc:  0.8046875 test_cost:  0.81117064 test_acc:  0.7578125\n",
            "iter 704 train_cost:  0.7655654 train_acc:  0.8125 test_cost:  0.57994616 test_acc:  0.8359375\n",
            "iter 705 train_cost:  0.54048234 train_acc:  0.84375 test_cost:  0.69986194 test_acc:  0.8046875\n",
            "iter 706 train_cost:  0.6796885 train_acc:  0.78125 test_cost:  0.63477945 test_acc:  0.828125\n",
            "iter 707 train_cost:  0.66629004 train_acc:  0.8359375 test_cost:  0.5820415 test_acc:  0.8046875\n",
            "iter 708 train_cost:  0.5906867 train_acc:  0.7890625 test_cost:  0.67281455 test_acc:  0.7890625\n",
            "iter 709 train_cost:  0.81658113 train_acc:  0.796875 test_cost:  0.59067726 test_acc:  0.828125\n",
            "iter 710 train_cost:  0.56759983 train_acc:  0.7890625 test_cost:  0.4542421 test_acc:  0.8828125\n",
            "iter 711 train_cost:  0.59015596 train_acc:  0.7890625 test_cost:  0.7029722 test_acc:  0.796875\n",
            "iter 712 train_cost:  0.5286194 train_acc:  0.8046875 test_cost:  0.5625355 test_acc:  0.84375\n",
            "iter 713 train_cost:  0.5288507 train_acc:  0.8359375 test_cost:  0.5008399 test_acc:  0.8515625\n",
            "iter 714 train_cost:  0.46487263 train_acc:  0.828125 test_cost:  0.6974485 test_acc:  0.7890625\n",
            "iter 715 train_cost:  0.5278532 train_acc:  0.84375 test_cost:  0.48437697 test_acc:  0.875\n",
            "iter 716 train_cost:  0.46650243 train_acc:  0.8203125 test_cost:  0.64834195 test_acc:  0.8125\n",
            "iter 717 train_cost:  0.68854856 train_acc:  0.765625 test_cost:  0.552642 test_acc:  0.8125\n",
            "iter 718 train_cost:  0.6604998 train_acc:  0.78125 test_cost:  0.4614179 test_acc:  0.84375\n",
            "iter 719 train_cost:  0.580287 train_acc:  0.8125 test_cost:  0.8101795 test_acc:  0.765625\n",
            "iter 720 train_cost:  0.69772446 train_acc:  0.78125 test_cost:  0.4358707 test_acc:  0.8671875\n",
            "iter 721 train_cost:  0.44582736 train_acc:  0.875 test_cost:  0.63525665 test_acc:  0.8203125\n",
            "iter 722 train_cost:  0.37486416 train_acc:  0.890625 test_cost:  0.43870604 test_acc:  0.84375\n",
            "iter 723 train_cost:  0.5675734 train_acc:  0.8125 test_cost:  0.6310736 test_acc:  0.8125\n",
            "iter 724 train_cost:  0.68409127 train_acc:  0.78125 test_cost:  0.54887223 test_acc:  0.8359375\n",
            "iter 725 train_cost:  0.5190036 train_acc:  0.8671875 test_cost:  0.6594351 test_acc:  0.78125\n",
            "iter 726 train_cost:  0.79621565 train_acc:  0.78125 test_cost:  0.5790387 test_acc:  0.828125\n",
            "iter 727 train_cost:  0.5687139 train_acc:  0.8203125 test_cost:  0.46582395 test_acc:  0.859375\n",
            "iter 728 train_cost:  0.582388 train_acc:  0.8125 test_cost:  0.5521431 test_acc:  0.828125\n",
            "iter 729 train_cost:  0.69677806 train_acc:  0.828125 test_cost:  0.7337861 test_acc:  0.765625\n",
            "iter 730 train_cost:  0.6213747 train_acc:  0.8359375 test_cost:  0.6302049 test_acc:  0.8203125\n",
            "iter 731 train_cost:  0.36118978 train_acc:  0.90625 test_cost:  0.60343397 test_acc:  0.78125\n",
            "iter 732 train_cost:  0.69526434 train_acc:  0.7890625 test_cost:  0.4926453 test_acc:  0.8671875\n",
            "iter 733 train_cost:  0.5396208 train_acc:  0.7890625 test_cost:  0.55752826 test_acc:  0.8203125\n",
            "iter 734 train_cost:  0.46372476 train_acc:  0.8359375 test_cost:  0.55794895 test_acc:  0.84375\n",
            "iter 735 train_cost:  0.5711705 train_acc:  0.8125 test_cost:  0.56364924 test_acc:  0.8046875\n",
            "iter 736 train_cost:  0.44675153 train_acc:  0.8125 test_cost:  0.53161305 test_acc:  0.8359375\n",
            "iter 737 train_cost:  0.6017021 train_acc:  0.8125 test_cost:  0.63643235 test_acc:  0.796875\n",
            "iter 738 train_cost:  0.7283592 train_acc:  0.75 test_cost:  0.5382807 test_acc:  0.8203125\n",
            "iter 739 train_cost:  0.40462267 train_acc:  0.8984375 test_cost:  0.6810657 test_acc:  0.8046875\n",
            "iter 740 train_cost:  0.5945337 train_acc:  0.796875 test_cost:  0.4054817 test_acc:  0.8515625\n",
            "iter 741 train_cost:  0.7062716 train_acc:  0.7890625 test_cost:  0.58636385 test_acc:  0.84375\n",
            "iter 742 train_cost:  0.5228946 train_acc:  0.875 test_cost:  0.7256464 test_acc:  0.828125\n",
            "iter 743 train_cost:  0.57495165 train_acc:  0.8203125 test_cost:  0.63133085 test_acc:  0.8125\n",
            "iter 744 train_cost:  0.54095405 train_acc:  0.828125 test_cost:  0.7880395 test_acc:  0.78125\n",
            "iter 745 train_cost:  0.52073604 train_acc:  0.8671875 test_cost:  0.53405994 test_acc:  0.8359375\n",
            "iter 746 train_cost:  0.6820713 train_acc:  0.7890625 test_cost:  0.49073493 test_acc:  0.8515625\n",
            "iter 747 train_cost:  0.68518573 train_acc:  0.78125 test_cost:  0.5671559 test_acc:  0.796875\n",
            "iter 748 train_cost:  0.6988882 train_acc:  0.796875 test_cost:  0.5555887 test_acc:  0.8046875\n",
            "iter 749 train_cost:  0.4627646 train_acc:  0.875 test_cost:  0.4188766 test_acc:  0.8515625\n",
            "iter 750 train_cost:  0.4508415 train_acc:  0.8203125 test_cost:  0.6228353 test_acc:  0.796875\n",
            "iter 751 train_cost:  0.6697855 train_acc:  0.78125 test_cost:  0.6203162 test_acc:  0.828125\n",
            "iter 752 train_cost:  0.42620003 train_acc:  0.890625 test_cost:  0.45630926 test_acc:  0.8671875\n",
            "iter 753 train_cost:  0.6030578 train_acc:  0.828125 test_cost:  0.55712414 test_acc:  0.7890625\n",
            "iter 754 train_cost:  0.48813576 train_acc:  0.8671875 test_cost:  0.3960281 test_acc:  0.875\n",
            "iter 755 train_cost:  0.42689168 train_acc:  0.8671875 test_cost:  0.64363307 test_acc:  0.828125\n",
            "iter 756 train_cost:  0.8464276 train_acc:  0.734375 test_cost:  0.7013981 test_acc:  0.8125\n",
            "iter 757 train_cost:  0.63852054 train_acc:  0.796875 test_cost:  0.50435597 test_acc:  0.8515625\n",
            "iter 758 train_cost:  0.66827404 train_acc:  0.8046875 test_cost:  0.5009872 test_acc:  0.8203125\n",
            "iter 759 train_cost:  0.561098 train_acc:  0.8125 test_cost:  0.41531703 test_acc:  0.8671875\n",
            "iter 760 train_cost:  0.6853866 train_acc:  0.7890625 test_cost:  0.4961415 test_acc:  0.8203125\n",
            "iter 761 train_cost:  0.4111574 train_acc:  0.8671875 test_cost:  0.39239025 test_acc:  0.859375\n",
            "iter 762 train_cost:  0.67952514 train_acc:  0.796875 test_cost:  0.5366188 test_acc:  0.8125\n",
            "iter 763 train_cost:  0.7061634 train_acc:  0.8046875 test_cost:  0.4895622 test_acc:  0.84375\n",
            "iter 764 train_cost:  0.4994382 train_acc:  0.8515625 test_cost:  0.679158 test_acc:  0.8046875\n",
            "iter 765 train_cost:  0.57410634 train_acc:  0.8515625 test_cost:  0.71656555 test_acc:  0.78125\n",
            "iter 766 train_cost:  0.76138675 train_acc:  0.8125 test_cost:  0.5095918 test_acc:  0.859375\n",
            "iter 767 train_cost:  0.773748 train_acc:  0.78125 test_cost:  0.54290557 test_acc:  0.84375\n",
            "iter 768 train_cost:  0.57279384 train_acc:  0.828125 test_cost:  0.66960347 test_acc:  0.796875\n",
            "iter 769 train_cost:  0.68448997 train_acc:  0.8046875 test_cost:  0.48374265 test_acc:  0.859375\n",
            "iter 770 train_cost:  0.5552385 train_acc:  0.8203125 test_cost:  0.6109709 test_acc:  0.7890625\n",
            "iter 771 train_cost:  0.4680813 train_acc:  0.828125 test_cost:  0.5120894 test_acc:  0.828125\n",
            "iter 772 train_cost:  0.6028242 train_acc:  0.828125 test_cost:  0.47959775 test_acc:  0.828125\n",
            "iter 773 train_cost:  0.42659163 train_acc:  0.859375 test_cost:  0.4691405 test_acc:  0.859375\n",
            "iter 774 train_cost:  0.53653127 train_acc:  0.8203125 test_cost:  0.7212393 test_acc:  0.7734375\n",
            "iter 775 train_cost:  0.36854255 train_acc:  0.875 test_cost:  0.6107317 test_acc:  0.796875\n",
            "iter 776 train_cost:  0.7749096 train_acc:  0.7734375 test_cost:  0.5232432 test_acc:  0.84375\n",
            "iter 777 train_cost:  0.6907895 train_acc:  0.8046875 test_cost:  0.58394 test_acc:  0.84375\n",
            "iter 778 train_cost:  0.46847558 train_acc:  0.828125 test_cost:  0.56896013 test_acc:  0.8125\n",
            "iter 779 train_cost:  0.47489837 train_acc:  0.859375 test_cost:  0.71994054 test_acc:  0.796875\n",
            "iter 780 train_cost:  0.75366867 train_acc:  0.78125 test_cost:  0.47322553 test_acc:  0.8359375\n",
            "iter 781 train_cost:  0.49169472 train_acc:  0.8359375 test_cost:  0.5737666 test_acc:  0.84375\n",
            "iter 782 train_cost:  0.4542201 train_acc:  0.8671875 test_cost:  0.5107228 test_acc:  0.8828125\n",
            "iter 783 train_cost:  0.51352566 train_acc:  0.8359375 test_cost:  0.67913383 test_acc:  0.7890625\n",
            "iter 784 train_cost:  0.51685953 train_acc:  0.859375 test_cost:  0.6455436 test_acc:  0.84375\n",
            "iter 785 train_cost:  0.716236 train_acc:  0.7890625 test_cost:  0.56907487 test_acc:  0.84375\n",
            "iter 786 train_cost:  0.36281288 train_acc:  0.8671875 test_cost:  0.57346785 test_acc:  0.84375\n",
            "iter 787 train_cost:  0.5551156 train_acc:  0.84375 test_cost:  0.48118693 test_acc:  0.859375\n",
            "iter 788 train_cost:  0.47226354 train_acc:  0.8359375 test_cost:  0.6983241 test_acc:  0.78125\n",
            "iter 789 train_cost:  0.50447804 train_acc:  0.859375 test_cost:  0.60377336 test_acc:  0.8359375\n",
            "iter 790 train_cost:  0.6807162 train_acc:  0.7890625 test_cost:  0.54435354 test_acc:  0.84375\n",
            "iter 791 train_cost:  0.6328994 train_acc:  0.796875 test_cost:  0.4408045 test_acc:  0.8359375\n",
            "iter 792 train_cost:  0.6182369 train_acc:  0.765625 test_cost:  0.5535269 test_acc:  0.8125\n",
            "iter 793 train_cost:  0.43058616 train_acc:  0.84375 test_cost:  0.54401666 test_acc:  0.8359375\n",
            "iter 794 train_cost:  0.5838572 train_acc:  0.828125 test_cost:  0.62225544 test_acc:  0.796875\n",
            "iter 795 train_cost:  0.4713626 train_acc:  0.859375 test_cost:  0.6136547 test_acc:  0.828125\n",
            "iter 796 train_cost:  0.55689186 train_acc:  0.8359375 test_cost:  0.42953104 test_acc:  0.859375\n",
            "iter 797 train_cost:  0.54104406 train_acc:  0.8046875 test_cost:  0.41487014 test_acc:  0.890625\n",
            "iter 798 train_cost:  0.71724355 train_acc:  0.7734375 test_cost:  0.62909627 test_acc:  0.7890625\n",
            "iter 799 train_cost:  0.7143113 train_acc:  0.75 test_cost:  0.6275994 test_acc:  0.7890625\n",
            "iter 800 train_cost:  0.542664 train_acc:  0.796875 test_cost:  0.6176709 test_acc:  0.828125\n",
            "iter 801 train_cost:  0.5428022 train_acc:  0.859375 test_cost:  0.4701649 test_acc:  0.8671875\n",
            "iter 802 train_cost:  0.65038526 train_acc:  0.8203125 test_cost:  0.6613295 test_acc:  0.796875\n",
            "iter 803 train_cost:  0.5015521 train_acc:  0.84375 test_cost:  0.48020315 test_acc:  0.8515625\n",
            "iter 804 train_cost:  0.5502752 train_acc:  0.828125 test_cost:  0.7218927 test_acc:  0.78125\n",
            "iter 805 train_cost:  0.45637447 train_acc:  0.8203125 test_cost:  0.39036158 test_acc:  0.8671875\n",
            "iter 806 train_cost:  0.5845676 train_acc:  0.8125 test_cost:  0.52932525 test_acc:  0.828125\n",
            "iter 807 train_cost:  0.7529545 train_acc:  0.796875 test_cost:  0.4734453 test_acc:  0.8671875\n",
            "iter 808 train_cost:  0.5832873 train_acc:  0.7890625 test_cost:  0.44307274 test_acc:  0.8515625\n",
            "iter 809 train_cost:  0.72834504 train_acc:  0.8046875 test_cost:  0.46786103 test_acc:  0.8515625\n",
            "iter 810 train_cost:  0.7642083 train_acc:  0.7890625 test_cost:  0.6523964 test_acc:  0.7890625\n",
            "iter 811 train_cost:  0.6583307 train_acc:  0.8046875 test_cost:  0.49280477 test_acc:  0.8515625\n",
            "iter 812 train_cost:  0.65715104 train_acc:  0.828125 test_cost:  0.50849503 test_acc:  0.8125\n",
            "iter 813 train_cost:  0.45466876 train_acc:  0.84375 test_cost:  0.7155088 test_acc:  0.796875\n",
            "iter 814 train_cost:  0.4095591 train_acc:  0.859375 test_cost:  0.7139955 test_acc:  0.7734375\n",
            "iter 815 train_cost:  0.49983862 train_acc:  0.84375 test_cost:  0.4899768 test_acc:  0.84375\n",
            "iter 816 train_cost:  0.4712178 train_acc:  0.8515625 test_cost:  0.5228124 test_acc:  0.828125\n",
            "iter 817 train_cost:  0.5926828 train_acc:  0.828125 test_cost:  0.36435348 test_acc:  0.859375\n",
            "iter 818 train_cost:  0.48536944 train_acc:  0.8203125 test_cost:  0.7008549 test_acc:  0.78125\n",
            "iter 819 train_cost:  0.56358886 train_acc:  0.84375 test_cost:  0.4072569 test_acc:  0.875\n",
            "iter 820 train_cost:  0.6546144 train_acc:  0.7890625 test_cost:  0.5762517 test_acc:  0.828125\n",
            "iter 821 train_cost:  0.3642586 train_acc:  0.84375 test_cost:  0.48431426 test_acc:  0.8828125\n",
            "iter 822 train_cost:  0.5081676 train_acc:  0.8125 test_cost:  0.321031 test_acc:  0.890625\n",
            "iter 823 train_cost:  0.4435507 train_acc:  0.84375 test_cost:  0.467625 test_acc:  0.8359375\n",
            "iter 824 train_cost:  0.33451885 train_acc:  0.8671875 test_cost:  0.55818903 test_acc:  0.8046875\n",
            "iter 825 train_cost:  0.41045377 train_acc:  0.84375 test_cost:  0.46591413 test_acc:  0.828125\n",
            "iter 826 train_cost:  0.57023 train_acc:  0.8359375 test_cost:  0.7740066 test_acc:  0.78125\n",
            "iter 827 train_cost:  0.52388257 train_acc:  0.8359375 test_cost:  0.6170851 test_acc:  0.8203125\n",
            "iter 828 train_cost:  0.6519346 train_acc:  0.796875 test_cost:  0.6617206 test_acc:  0.8046875\n",
            "iter 829 train_cost:  0.61288315 train_acc:  0.8359375 test_cost:  0.58417505 test_acc:  0.828125\n",
            "iter 830 train_cost:  0.45839906 train_acc:  0.8671875 test_cost:  0.56393754 test_acc:  0.828125\n",
            "iter 831 train_cost:  0.48202378 train_acc:  0.828125 test_cost:  0.70465064 test_acc:  0.7890625\n",
            "iter 832 train_cost:  0.45942432 train_acc:  0.859375 test_cost:  0.4354621 test_acc:  0.890625\n",
            "iter 833 train_cost:  0.50598395 train_acc:  0.8671875 test_cost:  0.6262712 test_acc:  0.828125\n",
            "iter 834 train_cost:  0.5402763 train_acc:  0.8125 test_cost:  0.40746444 test_acc:  0.875\n",
            "iter 835 train_cost:  0.47160706 train_acc:  0.8359375 test_cost:  0.5228038 test_acc:  0.8359375\n",
            "iter 836 train_cost:  0.61302555 train_acc:  0.796875 test_cost:  0.50533175 test_acc:  0.8515625\n",
            "iter 837 train_cost:  0.59657615 train_acc:  0.8125 test_cost:  0.53070617 test_acc:  0.8203125\n",
            "iter 838 train_cost:  0.49880975 train_acc:  0.8515625 test_cost:  0.44828394 test_acc:  0.8671875\n",
            "iter 839 train_cost:  0.5305639 train_acc:  0.8046875 test_cost:  0.4897563 test_acc:  0.8515625\n",
            "iter 840 train_cost:  0.50979394 train_acc:  0.8125 test_cost:  0.50483906 test_acc:  0.8125\n",
            "iter 841 train_cost:  0.53378415 train_acc:  0.8125 test_cost:  0.49111435 test_acc:  0.828125\n",
            "iter 842 train_cost:  0.5271452 train_acc:  0.8046875 test_cost:  0.62102646 test_acc:  0.8359375\n",
            "iter 843 train_cost:  0.54146135 train_acc:  0.859375 test_cost:  0.48628742 test_acc:  0.828125\n",
            "iter 844 train_cost:  0.46256587 train_acc:  0.8125 test_cost:  0.5562301 test_acc:  0.796875\n",
            "iter 845 train_cost:  0.5487472 train_acc:  0.8359375 test_cost:  0.5470516 test_acc:  0.8515625\n",
            "iter 846 train_cost:  0.50542265 train_acc:  0.8515625 test_cost:  0.5296756 test_acc:  0.8359375\n",
            "iter 847 train_cost:  0.5060058 train_acc:  0.8203125 test_cost:  0.539314 test_acc:  0.828125\n",
            "iter 848 train_cost:  0.757027 train_acc:  0.796875 test_cost:  0.5133966 test_acc:  0.84375\n",
            "iter 849 train_cost:  0.5163111 train_acc:  0.8359375 test_cost:  0.46797472 test_acc:  0.859375\n",
            "iter 850 train_cost:  0.6552909 train_acc:  0.828125 test_cost:  0.47313684 test_acc:  0.875\n",
            "iter 851 train_cost:  0.55119234 train_acc:  0.8515625 test_cost:  0.5890411 test_acc:  0.8125\n",
            "iter 852 train_cost:  0.47317323 train_acc:  0.8359375 test_cost:  0.58383584 test_acc:  0.84375\n",
            "iter 853 train_cost:  0.54129136 train_acc:  0.828125 test_cost:  0.54628277 test_acc:  0.8359375\n",
            "iter 854 train_cost:  0.54592425 train_acc:  0.84375 test_cost:  0.59020305 test_acc:  0.828125\n",
            "iter 855 train_cost:  0.4267696 train_acc:  0.859375 test_cost:  0.4542827 test_acc:  0.828125\n",
            "iter 856 train_cost:  0.41357952 train_acc:  0.8671875 test_cost:  0.37167406 test_acc:  0.8671875\n",
            "iter 857 train_cost:  0.42121404 train_acc:  0.859375 test_cost:  0.44210467 test_acc:  0.859375\n",
            "iter 858 train_cost:  0.44160548 train_acc:  0.8515625 test_cost:  0.54919 test_acc:  0.8203125\n",
            "iter 859 train_cost:  0.7146258 train_acc:  0.796875 test_cost:  0.59180295 test_acc:  0.796875\n",
            "iter 860 train_cost:  0.6906396 train_acc:  0.8125 test_cost:  0.5973736 test_acc:  0.828125\n",
            "iter 861 train_cost:  0.42314887 train_acc:  0.8828125 test_cost:  0.5538767 test_acc:  0.828125\n",
            "iter 862 train_cost:  0.42384088 train_acc:  0.8671875 test_cost:  0.38292778 test_acc:  0.875\n",
            "iter 863 train_cost:  0.4474578 train_acc:  0.859375 test_cost:  0.65584934 test_acc:  0.8203125\n",
            "iter 864 train_cost:  0.5056832 train_acc:  0.8515625 test_cost:  0.4233135 test_acc:  0.8515625\n",
            "iter 865 train_cost:  0.5555044 train_acc:  0.8203125 test_cost:  0.54151624 test_acc:  0.8203125\n",
            "iter 866 train_cost:  0.618153 train_acc:  0.8359375 test_cost:  0.5156752 test_acc:  0.828125\n",
            "iter 867 train_cost:  0.5254439 train_acc:  0.8359375 test_cost:  0.31343284 test_acc:  0.875\n",
            "iter 868 train_cost:  0.4859897 train_acc:  0.828125 test_cost:  0.8044945 test_acc:  0.78125\n",
            "iter 869 train_cost:  0.50600415 train_acc:  0.828125 test_cost:  0.45341313 test_acc:  0.8359375\n",
            "iter 870 train_cost:  0.6477216 train_acc:  0.828125 test_cost:  0.65003246 test_acc:  0.8203125\n",
            "iter 871 train_cost:  0.5376899 train_acc:  0.859375 test_cost:  0.5738293 test_acc:  0.8359375\n",
            "iter 872 train_cost:  0.44460574 train_acc:  0.8828125 test_cost:  0.6390449 test_acc:  0.8046875\n",
            "iter 873 train_cost:  0.4600135 train_acc:  0.859375 test_cost:  0.5035383 test_acc:  0.859375\n",
            "iter 874 train_cost:  0.6281309 train_acc:  0.7734375 test_cost:  0.7029707 test_acc:  0.8125\n",
            "iter 875 train_cost:  0.5593151 train_acc:  0.875 test_cost:  0.46379846 test_acc:  0.84375\n",
            "iter 876 train_cost:  0.5533881 train_acc:  0.8203125 test_cost:  0.48939216 test_acc:  0.828125\n",
            "iter 877 train_cost:  0.6654129 train_acc:  0.78125 test_cost:  0.47791618 test_acc:  0.8671875\n",
            "iter 878 train_cost:  0.63146365 train_acc:  0.7890625 test_cost:  0.6467104 test_acc:  0.765625\n",
            "iter 879 train_cost:  0.6275018 train_acc:  0.765625 test_cost:  0.35534966 test_acc:  0.8828125\n",
            "iter 880 train_cost:  0.5523994 train_acc:  0.828125 test_cost:  0.6403258 test_acc:  0.796875\n",
            "iter 881 train_cost:  0.4030078 train_acc:  0.8515625 test_cost:  0.574713 test_acc:  0.8359375\n",
            "iter 882 train_cost:  0.61727345 train_acc:  0.7890625 test_cost:  0.6209239 test_acc:  0.859375\n",
            "iter 883 train_cost:  0.4181777 train_acc:  0.859375 test_cost:  0.54046243 test_acc:  0.8515625\n",
            "iter 884 train_cost:  0.47499883 train_acc:  0.8671875 test_cost:  0.5343976 test_acc:  0.84375\n",
            "iter 885 train_cost:  0.5048283 train_acc:  0.8828125 test_cost:  0.62490433 test_acc:  0.7734375\n",
            "iter 886 train_cost:  0.5013016 train_acc:  0.8203125 test_cost:  0.40962124 test_acc:  0.8671875\n",
            "iter 887 train_cost:  0.57787085 train_acc:  0.8515625 test_cost:  0.5284216 test_acc:  0.8359375\n",
            "iter 888 train_cost:  0.4592561 train_acc:  0.84375 test_cost:  0.4527033 test_acc:  0.859375\n",
            "iter 889 train_cost:  0.41589773 train_acc:  0.8828125 test_cost:  0.538715 test_acc:  0.8203125\n",
            "iter 890 train_cost:  0.47374836 train_acc:  0.875 test_cost:  0.4813247 test_acc:  0.828125\n",
            "iter 891 train_cost:  0.5646485 train_acc:  0.8359375 test_cost:  0.61385846 test_acc:  0.8125\n",
            "iter 892 train_cost:  0.43168914 train_acc:  0.84375 test_cost:  0.5745952 test_acc:  0.8203125\n",
            "iter 893 train_cost:  0.52317166 train_acc:  0.8515625 test_cost:  0.61977303 test_acc:  0.84375\n",
            "iter 894 train_cost:  0.66910106 train_acc:  0.78125 test_cost:  0.41121668 test_acc:  0.90625\n",
            "iter 895 train_cost:  0.50924927 train_acc:  0.84375 test_cost:  0.4391737 test_acc:  0.8671875\n",
            "iter 896 train_cost:  0.521083 train_acc:  0.8359375 test_cost:  0.5343642 test_acc:  0.8515625\n",
            "iter 897 train_cost:  0.37174952 train_acc:  0.90625 test_cost:  0.4628894 test_acc:  0.828125\n",
            "iter 898 train_cost:  0.61218864 train_acc:  0.8515625 test_cost:  0.5663651 test_acc:  0.8046875\n",
            "iter 899 train_cost:  0.4391596 train_acc:  0.828125 test_cost:  0.54046136 test_acc:  0.8828125\n",
            "iter 900 train_cost:  0.66393244 train_acc:  0.8203125 test_cost:  0.5508845 test_acc:  0.8515625\n",
            "iter 901 train_cost:  0.59535044 train_acc:  0.8046875 test_cost:  0.53813547 test_acc:  0.8515625\n",
            "iter 902 train_cost:  0.558265 train_acc:  0.8359375 test_cost:  0.48182333 test_acc:  0.859375\n",
            "iter 903 train_cost:  0.64438456 train_acc:  0.78125 test_cost:  0.6143476 test_acc:  0.84375\n",
            "iter 904 train_cost:  0.41084227 train_acc:  0.8515625 test_cost:  0.4814309 test_acc:  0.8515625\n",
            "iter 905 train_cost:  0.64927363 train_acc:  0.796875 test_cost:  0.49809766 test_acc:  0.8359375\n",
            "iter 906 train_cost:  0.33510798 train_acc:  0.90625 test_cost:  0.45704553 test_acc:  0.859375\n",
            "iter 907 train_cost:  0.5239477 train_acc:  0.8359375 test_cost:  0.41101635 test_acc:  0.84375\n",
            "iter 908 train_cost:  0.59568685 train_acc:  0.8359375 test_cost:  0.51977974 test_acc:  0.84375\n",
            "iter 909 train_cost:  0.786355 train_acc:  0.765625 test_cost:  0.4914562 test_acc:  0.8359375\n",
            "iter 910 train_cost:  0.40130228 train_acc:  0.875 test_cost:  0.8229278 test_acc:  0.796875\n",
            "iter 911 train_cost:  0.6370873 train_acc:  0.796875 test_cost:  0.5026573 test_acc:  0.8046875\n",
            "iter 912 train_cost:  0.33987778 train_acc:  0.875 test_cost:  0.34207985 test_acc:  0.9140625\n",
            "iter 913 train_cost:  0.5328159 train_acc:  0.8359375 test_cost:  0.4863786 test_acc:  0.8515625\n",
            "iter 914 train_cost:  0.3758309 train_acc:  0.859375 test_cost:  0.54715437 test_acc:  0.859375\n",
            "iter 915 train_cost:  0.49346122 train_acc:  0.8515625 test_cost:  0.6142958 test_acc:  0.8125\n",
            "iter 916 train_cost:  0.6423772 train_acc:  0.796875 test_cost:  0.32705742 test_acc:  0.875\n",
            "iter 917 train_cost:  0.46801677 train_acc:  0.8671875 test_cost:  0.5408357 test_acc:  0.84375\n",
            "iter 918 train_cost:  0.5048558 train_acc:  0.8046875 test_cost:  0.4001938 test_acc:  0.8828125\n",
            "iter 919 train_cost:  0.5798202 train_acc:  0.8203125 test_cost:  0.42006174 test_acc:  0.875\n",
            "iter 920 train_cost:  0.67121637 train_acc:  0.78125 test_cost:  0.63216096 test_acc:  0.7890625\n",
            "iter 921 train_cost:  0.5882731 train_acc:  0.828125 test_cost:  0.55810034 test_acc:  0.8359375\n",
            "iter 922 train_cost:  0.398099 train_acc:  0.8671875 test_cost:  0.3901947 test_acc:  0.890625\n",
            "iter 923 train_cost:  0.52550983 train_acc:  0.8359375 test_cost:  0.5216504 test_acc:  0.8203125\n",
            "iter 924 train_cost:  0.49961385 train_acc:  0.8359375 test_cost:  0.42063954 test_acc:  0.859375\n",
            "iter 925 train_cost:  0.39780998 train_acc:  0.875 test_cost:  0.5170862 test_acc:  0.828125\n",
            "iter 926 train_cost:  0.45771247 train_acc:  0.859375 test_cost:  0.51866674 test_acc:  0.8359375\n",
            "iter 927 train_cost:  0.43410444 train_acc:  0.875 test_cost:  0.52020574 test_acc:  0.8515625\n",
            "iter 928 train_cost:  0.44732305 train_acc:  0.8671875 test_cost:  0.31562877 test_acc:  0.9140625\n",
            "iter 929 train_cost:  0.5084688 train_acc:  0.8046875 test_cost:  0.62894434 test_acc:  0.78125\n",
            "iter 930 train_cost:  0.5861255 train_acc:  0.84375 test_cost:  0.37989074 test_acc:  0.875\n",
            "iter 931 train_cost:  0.6546428 train_acc:  0.8203125 test_cost:  0.634963 test_acc:  0.8046875\n",
            "iter 932 train_cost:  0.4800456 train_acc:  0.875 test_cost:  0.5475546 test_acc:  0.84375\n",
            "iter 933 train_cost:  0.52978456 train_acc:  0.84375 test_cost:  0.48621297 test_acc:  0.90625\n",
            "iter 934 train_cost:  0.40936977 train_acc:  0.8515625 test_cost:  0.37001792 test_acc:  0.8984375\n",
            "iter 935 train_cost:  0.38863707 train_acc:  0.90625 test_cost:  0.46050346 test_acc:  0.84375\n",
            "iter 936 train_cost:  0.47231668 train_acc:  0.859375 test_cost:  0.44516277 test_acc:  0.8359375\n",
            "iter 937 train_cost:  0.41650695 train_acc:  0.8671875 test_cost:  0.43268073 test_acc:  0.875\n",
            "iter 938 train_cost:  0.44013745 train_acc:  0.875 test_cost:  0.59741944 test_acc:  0.796875\n",
            "iter 939 train_cost:  0.4842906 train_acc:  0.8203125 test_cost:  0.42092767 test_acc:  0.8671875\n",
            "iter 940 train_cost:  0.5311476 train_acc:  0.859375 test_cost:  0.5606431 test_acc:  0.8046875\n",
            "iter 941 train_cost:  0.5724062 train_acc:  0.84375 test_cost:  0.48073506 test_acc:  0.859375\n",
            "iter 942 train_cost:  0.52939326 train_acc:  0.828125 test_cost:  0.64157754 test_acc:  0.828125\n",
            "iter 943 train_cost:  0.40962598 train_acc:  0.875 test_cost:  0.5799974 test_acc:  0.796875\n",
            "iter 944 train_cost:  0.47921515 train_acc:  0.8125 test_cost:  0.44979078 test_acc:  0.8671875\n",
            "iter 945 train_cost:  0.5455493 train_acc:  0.859375 test_cost:  0.50502414 test_acc:  0.875\n",
            "iter 946 train_cost:  0.4110816 train_acc:  0.8671875 test_cost:  0.4170837 test_acc:  0.875\n",
            "iter 947 train_cost:  0.514844 train_acc:  0.84375 test_cost:  0.70225656 test_acc:  0.796875\n",
            "iter 948 train_cost:  0.4989584 train_acc:  0.8359375 test_cost:  0.6702024 test_acc:  0.828125\n",
            "iter 949 train_cost:  0.43756112 train_acc:  0.8671875 test_cost:  0.41608724 test_acc:  0.859375\n",
            "iter 950 train_cost:  0.5426697 train_acc:  0.859375 test_cost:  0.54216444 test_acc:  0.8203125\n",
            "iter 951 train_cost:  0.4819133 train_acc:  0.84375 test_cost:  0.3789839 test_acc:  0.8828125\n",
            "iter 952 train_cost:  0.37692684 train_acc:  0.890625 test_cost:  0.47814322 test_acc:  0.8515625\n",
            "iter 953 train_cost:  0.376341 train_acc:  0.890625 test_cost:  0.61415094 test_acc:  0.8203125\n",
            "iter 954 train_cost:  0.41281646 train_acc:  0.859375 test_cost:  0.60191596 test_acc:  0.8515625\n",
            "iter 955 train_cost:  0.3815563 train_acc:  0.8515625 test_cost:  0.50508326 test_acc:  0.8359375\n",
            "iter 956 train_cost:  0.56974995 train_acc:  0.8671875 test_cost:  0.42474496 test_acc:  0.859375\n",
            "iter 957 train_cost:  0.5070709 train_acc:  0.859375 test_cost:  0.42943516 test_acc:  0.8828125\n",
            "iter 958 train_cost:  0.4533709 train_acc:  0.8671875 test_cost:  0.7092934 test_acc:  0.8125\n",
            "iter 959 train_cost:  0.67206365 train_acc:  0.796875 test_cost:  0.3679524 test_acc:  0.859375\n",
            "iter 960 train_cost:  0.48005188 train_acc:  0.8515625 test_cost:  0.410231 test_acc:  0.859375\n",
            "iter 961 train_cost:  0.67524624 train_acc:  0.78125 test_cost:  0.3855791 test_acc:  0.84375\n",
            "iter 962 train_cost:  0.5347591 train_acc:  0.8359375 test_cost:  0.2884346 test_acc:  0.8984375\n",
            "iter 963 train_cost:  0.5668268 train_acc:  0.8515625 test_cost:  0.54501164 test_acc:  0.8359375\n",
            "iter 964 train_cost:  0.48547575 train_acc:  0.8046875 test_cost:  0.37542075 test_acc:  0.8671875\n",
            "iter 965 train_cost:  0.44791946 train_acc:  0.8671875 test_cost:  0.56936014 test_acc:  0.859375\n",
            "iter 966 train_cost:  0.41042 train_acc:  0.8671875 test_cost:  0.5846883 test_acc:  0.8203125\n",
            "iter 967 train_cost:  0.35792404 train_acc:  0.875 test_cost:  0.55955505 test_acc:  0.8515625\n",
            "iter 968 train_cost:  0.63945943 train_acc:  0.8046875 test_cost:  0.5332079 test_acc:  0.7890625\n",
            "iter 969 train_cost:  0.5258456 train_acc:  0.8671875 test_cost:  0.5392459 test_acc:  0.859375\n",
            "iter 970 train_cost:  0.47930312 train_acc:  0.859375 test_cost:  0.4205792 test_acc:  0.8515625\n",
            "iter 971 train_cost:  0.68708783 train_acc:  0.8203125 test_cost:  0.55584866 test_acc:  0.8359375\n",
            "iter 972 train_cost:  0.59044605 train_acc:  0.828125 test_cost:  0.5657774 test_acc:  0.84375\n",
            "iter 973 train_cost:  0.5274911 train_acc:  0.8515625 test_cost:  0.6526866 test_acc:  0.828125\n",
            "iter 974 train_cost:  0.3406796 train_acc:  0.90625 test_cost:  0.57650423 test_acc:  0.8203125\n",
            "iter 975 train_cost:  0.42552915 train_acc:  0.84375 test_cost:  0.4404875 test_acc:  0.875\n",
            "iter 976 train_cost:  0.39617407 train_acc:  0.8515625 test_cost:  0.41669223 test_acc:  0.8515625\n",
            "iter 977 train_cost:  0.5501339 train_acc:  0.8515625 test_cost:  0.39833188 test_acc:  0.8515625\n",
            "iter 978 train_cost:  0.39669055 train_acc:  0.875 test_cost:  0.57838666 test_acc:  0.8515625\n",
            "iter 979 train_cost:  0.5382811 train_acc:  0.8671875 test_cost:  0.41287774 test_acc:  0.859375\n",
            "iter 980 train_cost:  0.57594186 train_acc:  0.8046875 test_cost:  0.6635097 test_acc:  0.8046875\n",
            "iter 981 train_cost:  0.44707084 train_acc:  0.875 test_cost:  0.3367642 test_acc:  0.875\n",
            "iter 982 train_cost:  0.5745992 train_acc:  0.796875 test_cost:  0.5267 test_acc:  0.8828125\n",
            "iter 983 train_cost:  0.5477744 train_acc:  0.8515625 test_cost:  0.3575981 test_acc:  0.8984375\n",
            "iter 984 train_cost:  0.5712003 train_acc:  0.7890625 test_cost:  0.3901504 test_acc:  0.875\n",
            "iter 985 train_cost:  0.4916728 train_acc:  0.8671875 test_cost:  0.66744125 test_acc:  0.8359375\n",
            "iter 986 train_cost:  0.43906924 train_acc:  0.8671875 test_cost:  0.40871477 test_acc:  0.859375\n",
            "iter 987 train_cost:  0.42680502 train_acc:  0.859375 test_cost:  0.38951975 test_acc:  0.8984375\n",
            "iter 988 train_cost:  0.5536679 train_acc:  0.8125 test_cost:  0.3995453 test_acc:  0.890625\n",
            "iter 989 train_cost:  0.29629534 train_acc:  0.90625 test_cost:  0.5916593 test_acc:  0.84375\n",
            "iter 990 train_cost:  0.52820563 train_acc:  0.828125 test_cost:  0.58597624 test_acc:  0.8125\n",
            "iter 991 train_cost:  0.4836834 train_acc:  0.8515625 test_cost:  0.47452906 test_acc:  0.8515625\n",
            "iter 992 train_cost:  0.46285453 train_acc:  0.859375 test_cost:  0.5467344 test_acc:  0.8203125\n",
            "iter 993 train_cost:  0.50563127 train_acc:  0.8359375 test_cost:  0.28885663 test_acc:  0.90625\n",
            "iter 994 train_cost:  0.5818205 train_acc:  0.8359375 test_cost:  0.47825694 test_acc:  0.859375\n",
            "iter 995 train_cost:  0.5176718 train_acc:  0.8515625 test_cost:  0.55423236 test_acc:  0.8515625\n",
            "iter 996 train_cost:  0.51613426 train_acc:  0.8203125 test_cost:  0.47161216 test_acc:  0.84375\n",
            "iter 997 train_cost:  0.40229982 train_acc:  0.8671875 test_cost:  0.46950024 test_acc:  0.8671875\n",
            "iter 998 train_cost:  0.3348989 train_acc:  0.8671875 test_cost:  0.46874496 test_acc:  0.84375\n",
            "iter 999 train_cost:  0.4913023 train_acc:  0.8515625 test_cost:  0.42628047 test_acc:  0.8515625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-769d52915d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m   \u001b[0my_p_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_gr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_gr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predcited'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'real '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (10, 3) for Tensor 'Placeholder_40:0', which has shape '(?, 784)'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3V8ztAKDCg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "Before we jump into Tensorflow, we will implemented our first neural network model using Python Numpy package. NumPy is the fundamental package for scientific computing with Python, such as:\n",
        "\n",
        "1. Linear Algebra\n",
        "2. Statistics\n",
        "3. Calculus\n",
        "\n",
        "## A brief intro to Numpy operations:\n",
        "\n",
        "1. Creating a Vector:\n",
        "Here we use Numpy to create a 1-D Array which we then call a vector.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTf7M4r7Lgj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Library\n",
        "import numpy as np\n",
        "\n",
        "#Create a vector as a Row\n",
        "vector_row = np.array([1,2,3])\n",
        "\n",
        "#Create vector as a Column\n",
        "vector_column = np.array([[1],[2],[3]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYFjSo0OLqA3",
        "colab_type": "text"
      },
      "source": [
        "2. Creating a Matrix\n",
        "We Create a 2-D Array in Numpy and call it a Matrix. It contains 2 rows and 3 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJlDBq5rLmA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Library\n",
        "import numpy as np\n",
        "\n",
        "#Create a Matrix\n",
        "matrix = np.array([[1,2,3],[4,5,6]])\n",
        "print(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv99hZqULygH",
        "colab_type": "text"
      },
      "source": [
        "3. Selecting Elements\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLQlxFzkPrKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Library\n",
        "import numpy as np\n",
        "\n",
        "#Create a vector as a Row\n",
        "vector_row = np.array([ 1,2,3,4,5,6 ])\n",
        "\n",
        "#Create a Matrix\n",
        "matrix = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(matrix)\n",
        "\n",
        "#Select 3rd element of Vector\n",
        "print(vector_row[2])\n",
        "\n",
        "#Select 2nd row 2nd column\n",
        "print(matrix[1,1])\n",
        "#Select all elements of a vector\n",
        "print(vector_row[:])\n",
        "#Select everything up to and including the 3rd element\n",
        "print(vector_row[:3])\n",
        "#Select the everything after the 3rd element\n",
        "print(vector_row[3:])\n",
        "#Select the last element\n",
        "print(vector_row[-1])\n",
        "#Select the first 2 rows and all the columns of the matrix\n",
        "print(matrix[:2,:])\n",
        "#Select all rows and the 2nd column of the matrix\n",
        "print(matrix[:,1:2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO3vTGEKQhm7",
        "colab_type": "text"
      },
      "source": [
        "4. Describing a Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8bDjBhhQpg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "#Create a Matrix\n",
        "matrix = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "#View the Number of Rows and Columns\n",
        "print(matrix.shape)\n",
        "#View the number of elements (rows*columns)\n",
        "print(matrix.size)\n",
        "#View the number of Dimensions(2 in this case)\n",
        "print(matrix.ndim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKISvY8kQtA0",
        "colab_type": "text"
      },
      "source": [
        "5. Finding the max and min values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abPJd0JrQ4mM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Library\n",
        "import numpy as np\n",
        "\n",
        "#Create a Matrix\n",
        "matrix = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(matrix)\n",
        "#Return the max element\n",
        "print(np.max(matrix))\n",
        "#Return the min element\n",
        "print(np.min(matrix))\n",
        "#To find the max element in each column\n",
        "print(np.max(matrix,axis=0))\n",
        "#To find the max element in each row\n",
        "print(np.max(matrix,axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qm64s_eR0zQ",
        "colab_type": "text"
      },
      "source": [
        "6. Reshaping Arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwepq7h_SBBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Library\n",
        "import numpy as np\n",
        "\n",
        "#Create a Matrix\n",
        "matrix = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(matrix)\n",
        "#Reshape\n",
        "print(matrix.reshape(9,1))\n",
        "#Here -1 says as many columns as needed and 1 row\n",
        "print(matrix.reshape(1,-1))\n",
        "#If we provide only 1 value Reshape would return a 1-d array of that length\n",
        "print(matrix.reshape(9))\n",
        "#We can also use the Flatten method to convert a matrix to 1-d array\n",
        "print(matrix.flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJU3xABuVem_",
        "colab_type": "text"
      },
      "source": [
        "7. Calculating Dot Products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPKg382VVivy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Library\n",
        "import numpy as np\n",
        "\n",
        "#Create vector-1\n",
        "vector_1 = np.array([ 1,2,3 ])\n",
        "#Create vector-2\n",
        "vector_2 = np.array([ 4,5,6 ])\n",
        "#Calculate Dot Product\n",
        "print(np.dot(vector_1,vector_2))\n",
        "#Alternatively you can use @ to calculate dot products\n",
        "print(vector_1 @ vector_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB-jK7jEXY7F",
        "colab_type": "text"
      },
      "source": [
        "##Linear regression in Numpy:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Write the numpy code for the following model:\n",
        "\n",
        "$Y=WX+B$\n",
        "\n",
        "where $X$ is 3x10 matrix:  10 samples and 3 features\n",
        "\n",
        "$Y$ is 4x10 matrix: 10 samples and 4 outputs\n",
        "\n",
        "$W$ is the weights matrix with the shape 4x3: connecting 3 inputs to 4 outputs\n",
        "\n",
        "$b$ is a vector with a size 4 ( one bias per output)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EtM5LVtWCpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Library\n",
        "import numpy as np\n",
        "\n",
        "# Generate a random X (we do not have a real data)\n",
        "X = np.random.rand(3,10)\n",
        "display(X.shape)\n",
        "\n",
        "# Generate a random weights vector\n",
        "W = np.random.rand(4,3)\n",
        "\n",
        "# Generate a random bias \n",
        "b = np.random.rand(4,1)\n",
        "\n",
        "# Calculate Y\n",
        "Y= np.dot(W,X) + b\n",
        "display(Y.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMIoucH9hFfr",
        "colab_type": "text"
      },
      "source": [
        "## One neuron model in numpy:\n",
        "\n",
        "A single neuron has multiple inputs and one output, in addition to the linear regression model, we need to add non linearity through an activation function:\n",
        "\n",
        "$Y= f(WX+B)$\n",
        "\n",
        "where $X$ is n x m matrix:  m samples and n features/inputs\n",
        "\n",
        "$f(g)= \\frac{1}{1+\\exp(-g)}$  is a sigmoid acitavation function\n",
        "\n",
        "$Y$ is nh1 x m matrix: m samples and ny outputs\n",
        "\n",
        "$W$ is the weights matrix with the shape nh1 x n: connecting 3 inputs to 4 outputs\n",
        "\n",
        "$b$ is a vector with a size nh1 ( one bias per output)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qry1JDGEiLmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load Library\n",
        "import numpy as np \n",
        "\n",
        "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmoid)\n",
        "\n",
        "# Generate a random X (we do not have a real data)\n",
        "X = np.random.rand(3,10)\n",
        "\n",
        "\n",
        "# Generate a random weights vector\n",
        "W = np.random.rand(1,3)\n",
        "\n",
        "\n",
        "# Generate a random bias \n",
        "b = np.random.rand()\n",
        "\n",
        "# Calculate Y\n",
        "Y= f(np.dot(W,X) + b)\n",
        "display(Y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSnbti9ooIIs",
        "colab_type": "text"
      },
      "source": [
        "## One hidden layer model in numpy:\n",
        "\n",
        "The difference from the one neuron model is simple:  we need only to change the number of output \"ny\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAY3o6zBnpA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load Library\n",
        "import numpy as np \n",
        "\n",
        "#Suppose we have the following NN architecture\n",
        "\n",
        "m = 10 # Number of samples\n",
        "ni= 3 # Number of input neurons\n",
        "h = 1 # Number of hidden layers\n",
        "nh1 = 4 # Number of neurons in the hidden layer 1\n",
        "no =1 # Number of neurons in the output layer\n",
        "\n",
        "\n",
        "\n",
        "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmoid)\n",
        "\n",
        "# Generate a random X (we do not have a real data)\n",
        "X = np.random.rand(ni,m)\n",
        "\n",
        "\n",
        "# Generate a random weights vector for the first hidden layer\n",
        "W1 = np.random.rand(nh1,ni)\n",
        "\n",
        "\n",
        "# Generate a random bias for the first hidden layer \n",
        "b1 = np.random.rand(nh1,1)\n",
        "\n",
        "# Generate a random weights vector for the output layer\n",
        "W2 = np.random.rand(no,nh1)\n",
        "\n",
        "# Generate a random bias for the output layer \n",
        "b2 = np.random.rand(no,1)\n",
        "\n",
        "# Calculate output of the first hidden layer\n",
        "Yh1= f(np.dot(W1,X) + b1)\n",
        "\n",
        "# Calculate output of the output layer\n",
        "\n",
        "Y= f(np.dot(W2,Yh1) + b2)\n",
        "\n",
        "display(Yh1.shape)\n",
        "display(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11fqb_bQvIEi",
        "colab_type": "text"
      },
      "source": [
        "## Gradient descent in Numpy:\n",
        "Let us now start training a neural network\n",
        "We start by implementing a simple gradient descent for linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzBJxwb7FFZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaQyLoxk2FyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converged = False\n",
        "iter = 0\n",
        "m = 10 # Number of samples\n",
        "ni= 1 # Number of input neurons\n",
        "h = 1 # Number of hidden layers\n",
        "no =1 # Number of neurons in the output layer\n",
        "\n",
        "# Generate a random X (we do not have a real data)\n",
        "X = np.random.rand(m)\n",
        "display(X)\n",
        "\n",
        "# learning rate\n",
        "alpha =0.01\n",
        "\n",
        "# early stop criteria \n",
        "ep=0.001\n",
        "\n",
        "# maximum number of training iterations\n",
        "max_iter=100\n",
        "\n",
        "# Generate a random weights vector for the output layer\n",
        "W1 = np.random.rand()\n",
        "\n",
        "# Generate a random bias for the output layer \n",
        "b1 = np.random.rand()\n",
        "\n",
        "# Generate a random ground truth\n",
        "Y_gr = np.random.rand(m)\n",
        "\n",
        "\n",
        "J = sum([(b1 + W1*X[i] - Y_gr[i])**2 for i in range(m)])\n",
        "\n",
        "while not converged:\n",
        "        # for each training sample, compute the gradient (d/d_theta j(theta))\n",
        "        grad0 = 1.0/m * sum([(b1 + W1*X[i] - Y_gr[i]) for i in range(m)]) \n",
        "        grad1 = 1.0/m * sum([(b1 + W1*X[i] - Y_gr[i])*X[i] for i in range(m)])\n",
        "        \n",
        "        # update the theta_temp\n",
        "        temp0 = W1 - alpha * grad0\n",
        "        temp1 = b1 - alpha * grad1\n",
        "        # update theta\n",
        "        W1 = temp0\n",
        "        b1 = temp1\n",
        "        \n",
        "        # sum squared error\n",
        "        e = sum([(b1 + W1*X[i] - Y_gr[i])**2 for i in range(m)]) \n",
        "\n",
        "        if abs(J-e) <= ep:\n",
        "            print('Converged, iterations: ', iter, '!!!')\n",
        "            converged = True\n",
        "    \n",
        "        J = e   # update error \n",
        "        iter += 1  # update iter\n",
        "    \n",
        "        if iter == max_iter:\n",
        "            print('Max interactions exceeded!')\n",
        "            converged = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqCCVlmFIZl",
        "colab_type": "text"
      },
      "source": [
        "##Assignment 1\n",
        "### Backpropagation in Numpy:\n"
      ]
    }
  ]
}