{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadhajmosa/Machine-learning-labs/blob/AlessandroFornasier/Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSUExzC-ZBV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWZldyi-Zef",
        "colab_type": "text"
      },
      "source": [
        "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
        "## Session 1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75NLOuwKXSs",
        "colab_type": "text"
      },
      "source": [
        "#Session 2: 05.06 - 13:00 - 14:30 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUtGM-W_ehP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Intro:\n",
        "\n",
        "Tensorflow is a powerful framework for implementing and deploying large-scale deep learning models. Recently, it has been widely used in both reasearch and production. TF objective is to combine scale and flexibility.\n",
        "\n",
        "In the past session, we will learning the following:\n",
        "\n",
        "1. TF programming stack\n",
        "2. TF programming concepts including computatoin graphs, operations and sessions. \n",
        "3. Implementation of linear regression\n",
        "4. Implementation of feed-forward neural networks\n",
        "\n",
        "## TF stack:\n",
        "\n",
        "TensorFlow is a framework composed of two core building blocks — a library for defining computational graphs and a runtime for executing such graphs on a variety of different hardware\n",
        "\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/layers.png)\n",
        "\n",
        "\n",
        "Before goining into details about the stack, let us talk about computational graphs.\n",
        "\n",
        "### Computational Graphs\n",
        "\n",
        "A directed graph is a data structure consisting of nodes (vertices) and edges. It’s a set of vertices connected pairwise by directed edges.\n",
        "\n",
        "Graphs come in many shapes and sizes and are used to solve many real-life problems, such as representing networks including telephone networks, circuit networks, road networks, and even social networks. \n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*V6aYjD3AxDbEKYahkGqVQw.png)\n",
        "\n",
        "TensorFlow uses directed graphs internally to represent computations, and they call this data flow graphs (or computational graphs).\n",
        "\n",
        "The nodes in TF data flow graph mostly represents operations, variables and placeholders.\n",
        "\n",
        "Take for example the following operation:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "\n",
        "To create a computational graph out of this program, we create nodes for each of the operations in our program, along with the input variables a and b. In fact, a and b could be constants if they don’t change. If one node is used as the input to another operation we draw a directed arrow that goes from one node to another.\n",
        "\n",
        "The computational graph for this program might look like this:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*vPb9E0Yd1QUAD0oFmAgaOw.png)\n",
        "\n",
        "Operations create or manipulate data according to specific rules. In TensorFlow those rules are called Ops, short for operations. Variables on the other hand represent shared, persistent state that can be manipulated by running Ops on those variables.\n",
        "\n",
        "The questions now what are the advantages of representing operations as directed graphs: The main advantage of using directed graphs is the ability to do **parallelism** and what is called **dependency driving scheduling**. \n",
        "For example, consider again the follwoing code:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "At the most fundamental level, most computer programs are mainly composed of two things — primitive operations and an order in which these operations are executed, often sequentially, line by line. This means we would first multiply a and b and only when this expression was evaluated we would take their sum. Computational graphs on the otherhand, exclusively specify the dependencies across the operations.\n",
        "If we look at our computational graph we see that we could execute the multiplication and addition in parallel. That’s because these two operations do not depend on each other.\n",
        " So we can use the topology of the graph to drive the scheduling of operations and execute them in the most efficient manner, e.g. using multiple GPUs on a single machine or even distribute the execution across multiple machines.\n",
        " Another key advantage is portability. The graph is a language-independent representation of our code. So we can build the graph in Python, save the model (TensorFlow uses protocol buffers), and restore the model in a different language, say C++, if you want to go really fast.\n",
        " \n",
        " \n",
        "\n",
        "--------------------------------\n",
        "# References:\n",
        "\n",
        "https://medium.com/@d3lm/understand-tensorflow-by-mimicking-its-api-from-scratch-faa55787170d\n",
        "\n",
        "https://www.tensorflow.org/guide/extend/architecture\n",
        "\n",
        "https://www.tensorflow.org/guide/low_level_intro\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-GFJPVDnEwx",
        "colab_type": "text"
      },
      "source": [
        "# placeholder: tensors are feeded externaly for example inputs tensors + output tensors\n",
        "\n",
        "# variables : tensors represent the parameters of the network/graph ie. nn weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmSCbhtoJBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "num_inputs = 3\n",
        "num_outputs = 4\n",
        "num_samples= 10\n",
        "\n",
        "# Training data\n",
        "x_gr = np.random.rand(num_samples,num_inputs)\n",
        "y_gr = np.random.rand(num_samples,num_outputs)\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "# weights \n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs,num_outputs ]))\n",
        "\n",
        "# model (matmul is the dotproduct)\n",
        "y_p = tf.matmul(x, w_1)\n",
        "\n",
        "# cost\n",
        "cost = tf.reduce_mean(tf.pow(y-y_p,2))\n",
        "\n",
        "# optimisation \n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(10):\n",
        "        #first run the optimizer (one iteration of the gradient descent)\n",
        "        #the feed_dict is a dictionary of the data that has to be unsed instead\n",
        "        #of the placeholders\n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "    y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    print('predicted ', y_p_p)\n",
        "    print('real ', y_gr)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzDUVNSSwBH4",
        "colab_type": "code",
        "outputId": "219b34e5-9b4b-4764-dbca-33c17dd65028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "learningRate = 0.001\n",
        "trainingIterations = 2000\n",
        "batchSize = 128\n",
        "\n",
        "# Network Parameters\n",
        "nInputs = 3\n",
        "nOutputs = 4\n",
        "nHiddenLayerNeurons = np.array([4,10])\n",
        "nSamples= 10\n",
        "\n",
        "# Training data (GroundTruth)\n",
        "xGroundTruth = np.random.rand(nSamples,nInputs)\n",
        "yGroundTruth = np.random.rand(nSamples,nOutputs)\n",
        "\n",
        "# TensorFlow Graph input/output placeholders\n",
        "x = tf.placeholder(tf.float32, [None, nInputs])\n",
        "y = tf.placeholder(tf.float32, [None, nOutputs])\n",
        "\n",
        "# Weights \n",
        "W1 = tf.Variable(tf.random_normal([nInputs,nHiddenLayerNeurons[0]]))\n",
        "W2 = tf.Variable(tf.random_normal([nHiddenLayerNeurons[0],nHiddenLayerNeurons[1]]))\n",
        "W3 = tf.Variable(tf.random_normal([nHiddenLayerNeurons[1],nOutputs]))\n",
        "\n",
        "# Biases\n",
        "B1 = tf.Variable(tf.random_normal([nHiddenLayerNeurons[0]]))\n",
        "B2 = tf.Variable(tf.random_normal([nHiddenLayerNeurons[1]]))\n",
        "B3 = tf.Variable(tf.random_normal([nOutputs]))\n",
        "\n",
        "# Model\n",
        "H1 = tf.nn.sigmoid(tf.add(tf.matmul(x,W1),B1))\n",
        "H2 = tf.nn.sigmoid(tf.add(tf.matmul(H2,W2),B2))\n",
        "Y = tf.add(tf.matmul(H2,W3),B3)\n",
        "\n",
        "# Cost ... complete from here ...\n",
        "cost = tf.reduce_mean(tf.pow(y-y_p,2))\n",
        "\n",
        "# optimisation \n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(10):\n",
        "        #first run the optimizer (one iteration of the gradient descent)\n",
        "        #the feed_dict is a dictionary of the data that has to be unsed instead\n",
        "        #of the placeholders\n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "    y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    print('predicted ', y_p_p)\n",
        "    print('real ', y_gr)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAqwBs3WzHRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67284
        },
        "outputId": "7c580d5d-fb05-4895-e5e5-7d97542dc5d3"
      },
      "source": [
        "# Libraries import\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Import MNIST data input (28x28 image --> mnist.train.images.shape)\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "\n",
        "#import imshow\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "# Extract the traning, test and validation data and labels\n",
        "xTrain = mnist.train.images\n",
        "yTrain = mnist.train.labels\n",
        "xTest = mnist.test.images\n",
        "yTest = mnist.test.labels\n",
        "xValidation = mnist.validation.images\n",
        "yValidation = mnist.validation.labels\n",
        "\n",
        "# Parameters\n",
        "learningRate = 0.001\n",
        "trainingIterations = 2000\n",
        "batchSize = 128\n",
        "\n",
        "# Network Parameters\n",
        "nInputs =  mnist.train.images[0].size\n",
        "nOutputs = mnist.train.labels[0].size\n",
        "nHiddenLayerNeurons = np.array([100,100])\n",
        "nSamples= 10\n",
        "\n",
        "# Training data (GroundTruth)\n",
        "xGroundTruth = np.random.rand(nSamples,nInputs)\n",
        "yGroundTruth = np.random.rand(nSamples,nOutputs)\n",
        "\n",
        "# TensorFlow Graph input/output placeholders\n",
        "x = tf.placeholder(tf.float32, [None, nInputs])\n",
        "y = tf.placeholder(tf.float32, [None, nOutputs])\n",
        "\n",
        "# Weights \n",
        "W1 = tf.Variable(tf.random_normal([nInputs,nHiddenLayerNeurons[0]]))\n",
        "W2 = tf.Variable(tf.random_normal([nHiddenLayerNeurons[0],nHiddenLayerNeurons[1]]))\n",
        "W3 = tf.Variable(tf.random_normal([nHiddenLayerNeurons[1],nOutputs]))\n",
        "\n",
        "# Biases\n",
        "B1 = tf.Variable(tf.random_normal([nHiddenLayerNeurons[0]]))\n",
        "B2 = tf.Variable(tf.random_normal([nHiddenLayerNeurons[1]]))\n",
        "B3 = tf.Variable(tf.random_normal([nOutputs]))\n",
        "\n",
        "# Model\n",
        "H1 = tf.nn.sigmoid(tf.add(tf.matmul(x,W1),B1))\n",
        "H2 = tf.nn.sigmoid(tf.add(tf.matmul(H1,W2),B2))\n",
        "Y = tf.add(tf.matmul(H2,W3),B3)\n",
        "\n",
        "# Model Evaluation (tf.equal compare the 2 matricies and returns another matrix\n",
        "# with every values equal to true if the 2 value in the matricies are the same\n",
        "# false otherwise)\n",
        "nCorrectPrediction = tf.equal(tf.argmax(Y,1), tf.argmax(y,1))\n",
        "\n",
        "# Cost\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Y, labels=y))\n",
        "\n",
        "# Accurancy\n",
        "accurancy = tf.reduce_mean(tf.cast(nCorrectPrediction, tf.float32))\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(cost)\n",
        "\n",
        "# Initalizing the graph and the weights\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    # Session initialization\n",
        "    sess.run(init)\n",
        "    \n",
        "    for iteration in range(trainingIterations):\n",
        "      \n",
        "      # Take the samples from the dataset of the specified batchSize\n",
        "      xTrainBatch, yTrainBatch = mnist.train.next_batch(batchSize)\n",
        "      \n",
        "      # Take the samples from the dataset of the specified batchSize\n",
        "      xTestBatch, yTestBatch = mnist.test.next_batch(batchSize)\n",
        "      \n",
        "      # First run the optimizer (one iteration of the gradient descent)\n",
        "      # the feed_dict is a dictionary of the data that has to be unsed\n",
        "      # insteadof the placeholders\n",
        "      sess.run(optimizer, feed_dict={x: xTrainBatch, y: yTrainBatch}) \n",
        "\n",
        "      # Evaluate the cost and accurancy during the traning process\n",
        "      trainCost, trainAccurancy = sess.run([cost, accurancy], feed_dict={x: xTrainBatch, y: yTrainBatch})\n",
        "      \n",
        "      # Evaluate the cost and accurancy during the traning process\n",
        "      testCost, testAccurancy = sess.run([cost, accurancy], feed_dict={x: xTestBatch, y: yTestBatch})\n",
        "      \n",
        "      print('\\nIteration: ', iteration, 'trainCost: ', trainCost, 'trainAccurancy: ', trainAccurancy, 'testCost: ', testCost, 'testAccurancy: ', testAccurancy )\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            "Iteration:  0 trainCost:  14.767424 trainAccurancy:  0.0859375 testCost:  15.287432 testAccurancy:  0.0625\n",
            "\n",
            "Iteration:  1 trainCost:  13.770051 trainAccurancy:  0.125 testCost:  13.611641 testAccurancy:  0.1015625\n",
            "\n",
            "Iteration:  2 trainCost:  13.092819 trainAccurancy:  0.1015625 testCost:  13.796176 testAccurancy:  0.078125\n",
            "\n",
            "Iteration:  3 trainCost:  13.455248 trainAccurancy:  0.0703125 testCost:  13.493982 testAccurancy:  0.1015625\n",
            "\n",
            "Iteration:  4 trainCost:  12.022712 trainAccurancy:  0.1015625 testCost:  14.158468 testAccurancy:  0.078125\n",
            "\n",
            "Iteration:  5 trainCost:  12.252884 trainAccurancy:  0.109375 testCost:  12.264145 testAccurancy:  0.09375\n",
            "\n",
            "Iteration:  6 trainCost:  12.706514 trainAccurancy:  0.09375 testCost:  11.409385 testAccurancy:  0.1171875\n",
            "\n",
            "Iteration:  7 trainCost:  11.6320505 trainAccurancy:  0.125 testCost:  11.6451645 testAccurancy:  0.1640625\n",
            "\n",
            "Iteration:  8 trainCost:  10.690205 trainAccurancy:  0.109375 testCost:  11.058313 testAccurancy:  0.1171875\n",
            "\n",
            "Iteration:  9 trainCost:  11.744608 trainAccurancy:  0.109375 testCost:  11.925829 testAccurancy:  0.078125\n",
            "\n",
            "Iteration:  10 trainCost:  11.324575 trainAccurancy:  0.09375 testCost:  10.644362 testAccurancy:  0.09375\n",
            "\n",
            "Iteration:  11 trainCost:  9.429209 trainAccurancy:  0.1875 testCost:  11.334906 testAccurancy:  0.078125\n",
            "\n",
            "Iteration:  12 trainCost:  8.960729 trainAccurancy:  0.1484375 testCost:  10.828224 testAccurancy:  0.09375\n",
            "\n",
            "Iteration:  13 trainCost:  9.542724 trainAccurancy:  0.1171875 testCost:  9.564604 testAccurancy:  0.1015625\n",
            "\n",
            "Iteration:  14 trainCost:  8.671598 trainAccurancy:  0.140625 testCost:  9.523312 testAccurancy:  0.078125\n",
            "\n",
            "Iteration:  15 trainCost:  8.948647 trainAccurancy:  0.0703125 testCost:  8.088292 testAccurancy:  0.1640625\n",
            "\n",
            "Iteration:  16 trainCost:  8.660861 trainAccurancy:  0.1015625 testCost:  8.851568 testAccurancy:  0.09375\n",
            "\n",
            "Iteration:  17 trainCost:  8.930127 trainAccurancy:  0.078125 testCost:  7.882172 testAccurancy:  0.1328125\n",
            "\n",
            "Iteration:  18 trainCost:  7.8609247 trainAccurancy:  0.109375 testCost:  7.4337673 testAccurancy:  0.140625\n",
            "\n",
            "Iteration:  19 trainCost:  9.086246 trainAccurancy:  0.0625 testCost:  9.306919 testAccurancy:  0.0625\n",
            "\n",
            "Iteration:  20 trainCost:  7.909475 trainAccurancy:  0.078125 testCost:  8.532934 testAccurancy:  0.109375\n",
            "\n",
            "Iteration:  21 trainCost:  7.055643 trainAccurancy:  0.125 testCost:  7.4354887 testAccurancy:  0.0859375\n",
            "\n",
            "Iteration:  22 trainCost:  7.4811916 trainAccurancy:  0.0859375 testCost:  6.975968 testAccurancy:  0.0546875\n",
            "\n",
            "Iteration:  23 trainCost:  6.94241 trainAccurancy:  0.109375 testCost:  7.147172 testAccurancy:  0.0859375\n",
            "\n",
            "Iteration:  24 trainCost:  7.047086 trainAccurancy:  0.1015625 testCost:  7.3001904 testAccurancy:  0.0859375\n",
            "\n",
            "Iteration:  25 trainCost:  6.926713 trainAccurancy:  0.0859375 testCost:  6.1983805 testAccurancy:  0.1015625\n",
            "\n",
            "Iteration:  26 trainCost:  6.385327 trainAccurancy:  0.109375 testCost:  7.057649 testAccurancy:  0.09375\n",
            "\n",
            "Iteration:  27 trainCost:  6.569978 trainAccurancy:  0.1015625 testCost:  5.6312227 testAccurancy:  0.1171875\n",
            "\n",
            "Iteration:  28 trainCost:  6.3258257 trainAccurancy:  0.046875 testCost:  6.296877 testAccurancy:  0.1328125\n",
            "\n",
            "Iteration:  29 trainCost:  6.5791674 trainAccurancy:  0.1015625 testCost:  6.7567315 testAccurancy:  0.0625\n",
            "\n",
            "Iteration:  30 trainCost:  6.0965643 trainAccurancy:  0.125 testCost:  5.9085827 testAccurancy:  0.1015625\n",
            "\n",
            "Iteration:  31 trainCost:  4.741419 trainAccurancy:  0.1328125 testCost:  6.19965 testAccurancy:  0.125\n",
            "\n",
            "Iteration:  32 trainCost:  6.056394 trainAccurancy:  0.1328125 testCost:  6.128271 testAccurancy:  0.0859375\n",
            "\n",
            "Iteration:  33 trainCost:  5.9065475 trainAccurancy:  0.1015625 testCost:  6.210973 testAccurancy:  0.1171875\n",
            "\n",
            "Iteration:  34 trainCost:  5.6645565 trainAccurancy:  0.09375 testCost:  5.2356997 testAccurancy:  0.109375\n",
            "\n",
            "Iteration:  35 trainCost:  5.7063174 trainAccurancy:  0.1015625 testCost:  5.5943713 testAccurancy:  0.0859375\n",
            "\n",
            "Iteration:  36 trainCost:  5.2202153 trainAccurancy:  0.1484375 testCost:  5.5594597 testAccurancy:  0.140625\n",
            "\n",
            "Iteration:  37 trainCost:  5.0813923 trainAccurancy:  0.1328125 testCost:  5.5683355 testAccurancy:  0.078125\n",
            "\n",
            "Iteration:  38 trainCost:  4.8285875 trainAccurancy:  0.1328125 testCost:  5.5104723 testAccurancy:  0.125\n",
            "\n",
            "Iteration:  39 trainCost:  5.5412 trainAccurancy:  0.1171875 testCost:  5.013482 testAccurancy:  0.140625\n",
            "\n",
            "Iteration:  40 trainCost:  5.7260303 trainAccurancy:  0.1015625 testCost:  4.881274 testAccurancy:  0.1171875\n",
            "\n",
            "Iteration:  41 trainCost:  5.3893347 trainAccurancy:  0.1015625 testCost:  4.7260284 testAccurancy:  0.140625\n",
            "\n",
            "Iteration:  42 trainCost:  4.760726 trainAccurancy:  0.15625 testCost:  5.5350027 testAccurancy:  0.0703125\n",
            "\n",
            "Iteration:  43 trainCost:  4.1646404 trainAccurancy:  0.15625 testCost:  5.6813965 testAccurancy:  0.0703125\n",
            "\n",
            "Iteration:  44 trainCost:  4.4421835 trainAccurancy:  0.1875 testCost:  4.8278775 testAccurancy:  0.1875\n",
            "\n",
            "Iteration:  45 trainCost:  4.594876 trainAccurancy:  0.125 testCost:  5.089024 testAccurancy:  0.1640625\n",
            "\n",
            "Iteration:  46 trainCost:  4.895382 trainAccurancy:  0.125 testCost:  4.764258 testAccurancy:  0.140625\n",
            "\n",
            "Iteration:  47 trainCost:  3.8250294 trainAccurancy:  0.234375 testCost:  4.5737886 testAccurancy:  0.171875\n",
            "\n",
            "Iteration:  48 trainCost:  4.3819776 trainAccurancy:  0.1953125 testCost:  4.5494475 testAccurancy:  0.1640625\n",
            "\n",
            "Iteration:  49 trainCost:  4.5701113 trainAccurancy:  0.171875 testCost:  4.096942 testAccurancy:  0.1953125\n",
            "\n",
            "Iteration:  50 trainCost:  3.9768386 trainAccurancy:  0.2109375 testCost:  3.9835875 testAccurancy:  0.171875\n",
            "\n",
            "Iteration:  51 trainCost:  4.372519 trainAccurancy:  0.1484375 testCost:  4.253682 testAccurancy:  0.171875\n",
            "\n",
            "Iteration:  52 trainCost:  4.1975203 trainAccurancy:  0.234375 testCost:  4.4747577 testAccurancy:  0.2109375\n",
            "\n",
            "Iteration:  53 trainCost:  4.578973 trainAccurancy:  0.203125 testCost:  4.1766667 testAccurancy:  0.1640625\n",
            "\n",
            "Iteration:  54 trainCost:  4.416087 trainAccurancy:  0.140625 testCost:  3.9034357 testAccurancy:  0.1875\n",
            "\n",
            "Iteration:  55 trainCost:  4.11714 trainAccurancy:  0.1796875 testCost:  4.1559916 testAccurancy:  0.1796875\n",
            "\n",
            "Iteration:  56 trainCost:  3.8496122 trainAccurancy:  0.2109375 testCost:  3.7568836 testAccurancy:  0.1953125\n",
            "\n",
            "Iteration:  57 trainCost:  4.3602886 trainAccurancy:  0.2421875 testCost:  4.0878873 testAccurancy:  0.1796875\n",
            "\n",
            "Iteration:  58 trainCost:  3.7507741 trainAccurancy:  0.21875 testCost:  4.1398535 testAccurancy:  0.203125\n",
            "\n",
            "Iteration:  59 trainCost:  3.8921394 trainAccurancy:  0.2109375 testCost:  3.8097944 testAccurancy:  0.2421875\n",
            "\n",
            "Iteration:  60 trainCost:  3.7608838 trainAccurancy:  0.2109375 testCost:  3.9087827 testAccurancy:  0.203125\n",
            "\n",
            "Iteration:  61 trainCost:  3.88469 trainAccurancy:  0.1875 testCost:  3.3603516 testAccurancy:  0.2734375\n",
            "\n",
            "Iteration:  62 trainCost:  3.3074648 trainAccurancy:  0.328125 testCost:  3.655205 testAccurancy:  0.171875\n",
            "\n",
            "Iteration:  63 trainCost:  3.2644682 trainAccurancy:  0.234375 testCost:  3.3161216 testAccurancy:  0.2421875\n",
            "\n",
            "Iteration:  64 trainCost:  3.5582845 trainAccurancy:  0.265625 testCost:  3.7699072 testAccurancy:  0.15625\n",
            "\n",
            "Iteration:  65 trainCost:  3.284048 trainAccurancy:  0.265625 testCost:  3.1960099 testAccurancy:  0.2421875\n",
            "\n",
            "Iteration:  66 trainCost:  3.5779943 trainAccurancy:  0.234375 testCost:  3.3267508 testAccurancy:  0.2265625\n",
            "\n",
            "Iteration:  67 trainCost:  3.167493 trainAccurancy:  0.2734375 testCost:  3.3536987 testAccurancy:  0.2421875\n",
            "\n",
            "Iteration:  68 trainCost:  3.491742 trainAccurancy:  0.234375 testCost:  3.350008 testAccurancy:  0.2421875\n",
            "\n",
            "Iteration:  69 trainCost:  3.2164001 trainAccurancy:  0.21875 testCost:  3.3236666 testAccurancy:  0.265625\n",
            "\n",
            "Iteration:  70 trainCost:  3.0939674 trainAccurancy:  0.25 testCost:  3.026796 testAccurancy:  0.296875\n",
            "\n",
            "Iteration:  71 trainCost:  2.8720608 trainAccurancy:  0.2890625 testCost:  3.0702956 testAccurancy:  0.3203125\n",
            "\n",
            "Iteration:  72 trainCost:  3.2496736 trainAccurancy:  0.3046875 testCost:  2.9541252 testAccurancy:  0.2734375\n",
            "\n",
            "Iteration:  73 trainCost:  2.9747972 trainAccurancy:  0.296875 testCost:  3.0326676 testAccurancy:  0.234375\n",
            "\n",
            "Iteration:  74 trainCost:  2.9413166 trainAccurancy:  0.328125 testCost:  3.2705903 testAccurancy:  0.34375\n",
            "\n",
            "Iteration:  75 trainCost:  2.4906662 trainAccurancy:  0.3671875 testCost:  3.263872 testAccurancy:  0.2578125\n",
            "\n",
            "Iteration:  76 trainCost:  3.0159588 trainAccurancy:  0.2890625 testCost:  3.129815 testAccurancy:  0.28125\n",
            "\n",
            "Iteration:  77 trainCost:  3.0933633 trainAccurancy:  0.265625 testCost:  2.8934393 testAccurancy:  0.2890625\n",
            "\n",
            "Iteration:  78 trainCost:  3.0079713 trainAccurancy:  0.265625 testCost:  3.0652578 testAccurancy:  0.21875\n",
            "\n",
            "Iteration:  79 trainCost:  3.1821349 trainAccurancy:  0.265625 testCost:  2.9261162 testAccurancy:  0.296875\n",
            "\n",
            "Iteration:  80 trainCost:  3.0454762 trainAccurancy:  0.2734375 testCost:  2.8982873 testAccurancy:  0.296875\n",
            "\n",
            "Iteration:  81 trainCost:  2.4980855 trainAccurancy:  0.3359375 testCost:  2.5705657 testAccurancy:  0.3828125\n",
            "\n",
            "Iteration:  82 trainCost:  2.8085587 trainAccurancy:  0.328125 testCost:  2.9080682 testAccurancy:  0.265625\n",
            "\n",
            "Iteration:  83 trainCost:  3.4231527 trainAccurancy:  0.2578125 testCost:  2.2975795 testAccurancy:  0.359375\n",
            "\n",
            "Iteration:  84 trainCost:  3.341498 trainAccurancy:  0.2421875 testCost:  2.758493 testAccurancy:  0.3046875\n",
            "\n",
            "Iteration:  85 trainCost:  3.0291045 trainAccurancy:  0.25 testCost:  2.9128664 testAccurancy:  0.265625\n",
            "\n",
            "Iteration:  86 trainCost:  2.573495 trainAccurancy:  0.3515625 testCost:  2.613505 testAccurancy:  0.2890625\n",
            "\n",
            "Iteration:  87 trainCost:  2.8040028 trainAccurancy:  0.2734375 testCost:  2.602327 testAccurancy:  0.40625\n",
            "\n",
            "Iteration:  88 trainCost:  2.721703 trainAccurancy:  0.296875 testCost:  2.3128593 testAccurancy:  0.328125\n",
            "\n",
            "Iteration:  89 trainCost:  2.764583 trainAccurancy:  0.25 testCost:  2.5994308 testAccurancy:  0.3203125\n",
            "\n",
            "Iteration:  90 trainCost:  2.4046686 trainAccurancy:  0.40625 testCost:  2.4583142 testAccurancy:  0.375\n",
            "\n",
            "Iteration:  91 trainCost:  2.4624293 trainAccurancy:  0.375 testCost:  2.3972955 testAccurancy:  0.40625\n",
            "\n",
            "Iteration:  92 trainCost:  2.6157358 trainAccurancy:  0.3046875 testCost:  2.4161522 testAccurancy:  0.3046875\n",
            "\n",
            "Iteration:  93 trainCost:  2.7852328 trainAccurancy:  0.25 testCost:  2.3837485 testAccurancy:  0.3515625\n",
            "\n",
            "Iteration:  94 trainCost:  2.5194752 trainAccurancy:  0.3046875 testCost:  2.5964727 testAccurancy:  0.28125\n",
            "\n",
            "Iteration:  95 trainCost:  2.7177682 trainAccurancy:  0.28125 testCost:  2.4184308 testAccurancy:  0.3671875\n",
            "\n",
            "Iteration:  96 trainCost:  2.1230738 trainAccurancy:  0.3671875 testCost:  2.040128 testAccurancy:  0.4453125\n",
            "\n",
            "Iteration:  97 trainCost:  2.4831407 trainAccurancy:  0.3671875 testCost:  2.4694376 testAccurancy:  0.34375\n",
            "\n",
            "Iteration:  98 trainCost:  2.638525 trainAccurancy:  0.2890625 testCost:  2.4134083 testAccurancy:  0.3359375\n",
            "\n",
            "Iteration:  99 trainCost:  2.5631106 trainAccurancy:  0.3359375 testCost:  2.1175444 testAccurancy:  0.375\n",
            "\n",
            "Iteration:  100 trainCost:  2.619666 trainAccurancy:  0.3203125 testCost:  2.308998 testAccurancy:  0.3203125\n",
            "\n",
            "Iteration:  101 trainCost:  2.576726 trainAccurancy:  0.28125 testCost:  2.5374274 testAccurancy:  0.34375\n",
            "\n",
            "Iteration:  102 trainCost:  2.373367 trainAccurancy:  0.2734375 testCost:  2.636622 testAccurancy:  0.2890625\n",
            "\n",
            "Iteration:  103 trainCost:  2.232306 trainAccurancy:  0.34375 testCost:  2.0720024 testAccurancy:  0.34375\n",
            "\n",
            "Iteration:  104 trainCost:  2.4414415 trainAccurancy:  0.328125 testCost:  2.0069299 testAccurancy:  0.40625\n",
            "\n",
            "Iteration:  105 trainCost:  2.5027306 trainAccurancy:  0.328125 testCost:  2.4137864 testAccurancy:  0.3046875\n",
            "\n",
            "Iteration:  106 trainCost:  1.9514215 trainAccurancy:  0.390625 testCost:  2.174656 testAccurancy:  0.34375\n",
            "\n",
            "Iteration:  107 trainCost:  2.2329967 trainAccurancy:  0.375 testCost:  2.2515051 testAccurancy:  0.40625\n",
            "\n",
            "Iteration:  108 trainCost:  2.0026622 trainAccurancy:  0.4140625 testCost:  2.1465337 testAccurancy:  0.390625\n",
            "\n",
            "Iteration:  109 trainCost:  1.9599953 trainAccurancy:  0.4609375 testCost:  2.3271759 testAccurancy:  0.3671875\n",
            "\n",
            "Iteration:  110 trainCost:  2.152608 trainAccurancy:  0.359375 testCost:  2.3816516 testAccurancy:  0.3203125\n",
            "\n",
            "Iteration:  111 trainCost:  2.132535 trainAccurancy:  0.40625 testCost:  2.1415634 testAccurancy:  0.3359375\n",
            "\n",
            "Iteration:  112 trainCost:  2.1251655 trainAccurancy:  0.421875 testCost:  2.2014441 testAccurancy:  0.359375\n",
            "\n",
            "Iteration:  113 trainCost:  2.4320831 trainAccurancy:  0.3515625 testCost:  1.8193238 testAccurancy:  0.4609375\n",
            "\n",
            "Iteration:  114 trainCost:  2.0917711 trainAccurancy:  0.4375 testCost:  1.8313215 testAccurancy:  0.453125\n",
            "\n",
            "Iteration:  115 trainCost:  1.99864 trainAccurancy:  0.4296875 testCost:  1.9439867 testAccurancy:  0.4140625\n",
            "\n",
            "Iteration:  116 trainCost:  2.4024727 trainAccurancy:  0.3203125 testCost:  2.1889744 testAccurancy:  0.359375\n",
            "\n",
            "Iteration:  117 trainCost:  1.9156075 trainAccurancy:  0.40625 testCost:  2.3937192 testAccurancy:  0.359375\n",
            "\n",
            "Iteration:  118 trainCost:  2.2994404 trainAccurancy:  0.375 testCost:  2.1571634 testAccurancy:  0.3984375\n",
            "\n",
            "Iteration:  119 trainCost:  2.1301394 trainAccurancy:  0.359375 testCost:  2.2728446 testAccurancy:  0.421875\n",
            "\n",
            "Iteration:  120 trainCost:  2.138283 trainAccurancy:  0.359375 testCost:  1.9158893 testAccurancy:  0.4765625\n",
            "\n",
            "Iteration:  121 trainCost:  2.335658 trainAccurancy:  0.3671875 testCost:  2.05103 testAccurancy:  0.3828125\n",
            "\n",
            "Iteration:  122 trainCost:  2.3059092 trainAccurancy:  0.3671875 testCost:  2.097564 testAccurancy:  0.421875\n",
            "\n",
            "Iteration:  123 trainCost:  1.9176373 trainAccurancy:  0.375 testCost:  1.9686794 testAccurancy:  0.453125\n",
            "\n",
            "Iteration:  124 trainCost:  2.039114 trainAccurancy:  0.3984375 testCost:  2.075737 testAccurancy:  0.3828125\n",
            "\n",
            "Iteration:  125 trainCost:  1.9661199 trainAccurancy:  0.4375 testCost:  1.84374 testAccurancy:  0.421875\n",
            "\n",
            "Iteration:  126 trainCost:  2.1951628 trainAccurancy:  0.4140625 testCost:  1.9620764 testAccurancy:  0.4609375\n",
            "\n",
            "Iteration:  127 trainCost:  2.1149948 trainAccurancy:  0.421875 testCost:  2.0214124 testAccurancy:  0.40625\n",
            "\n",
            "Iteration:  128 trainCost:  1.9343071 trainAccurancy:  0.484375 testCost:  1.7565293 testAccurancy:  0.5078125\n",
            "\n",
            "Iteration:  129 trainCost:  2.1439028 trainAccurancy:  0.4453125 testCost:  2.0127661 testAccurancy:  0.4453125\n",
            "\n",
            "Iteration:  130 trainCost:  1.9522502 trainAccurancy:  0.4453125 testCost:  1.8487499 testAccurancy:  0.46875\n",
            "\n",
            "Iteration:  131 trainCost:  1.890694 trainAccurancy:  0.4375 testCost:  1.854265 testAccurancy:  0.453125\n",
            "\n",
            "Iteration:  132 trainCost:  2.1331353 trainAccurancy:  0.46875 testCost:  2.174908 testAccurancy:  0.3515625\n",
            "\n",
            "Iteration:  133 trainCost:  1.7788138 trainAccurancy:  0.4375 testCost:  1.5159266 testAccurancy:  0.4453125\n",
            "\n",
            "Iteration:  134 trainCost:  1.5508547 trainAccurancy:  0.5703125 testCost:  1.7885911 testAccurancy:  0.4453125\n",
            "\n",
            "Iteration:  135 trainCost:  1.9507196 trainAccurancy:  0.4765625 testCost:  1.9354813 testAccurancy:  0.4453125\n",
            "\n",
            "Iteration:  136 trainCost:  1.748239 trainAccurancy:  0.4921875 testCost:  1.918067 testAccurancy:  0.4921875\n",
            "\n",
            "Iteration:  137 trainCost:  1.7774459 trainAccurancy:  0.4140625 testCost:  1.8347231 testAccurancy:  0.46875\n",
            "\n",
            "Iteration:  138 trainCost:  2.0195389 trainAccurancy:  0.46875 testCost:  1.671886 testAccurancy:  0.484375\n",
            "\n",
            "Iteration:  139 trainCost:  1.81868 trainAccurancy:  0.4375 testCost:  1.6922297 testAccurancy:  0.4921875\n",
            "\n",
            "Iteration:  140 trainCost:  1.6578927 trainAccurancy:  0.515625 testCost:  1.9151443 testAccurancy:  0.4453125\n",
            "\n",
            "Iteration:  141 trainCost:  1.8307451 trainAccurancy:  0.453125 testCost:  1.7410692 testAccurancy:  0.4140625\n",
            "\n",
            "Iteration:  142 trainCost:  1.9970896 trainAccurancy:  0.390625 testCost:  1.9761053 testAccurancy:  0.390625\n",
            "\n",
            "Iteration:  143 trainCost:  1.7729871 trainAccurancy:  0.46875 testCost:  1.5599227 testAccurancy:  0.546875\n",
            "\n",
            "Iteration:  144 trainCost:  1.6192181 trainAccurancy:  0.484375 testCost:  1.6722593 testAccurancy:  0.5\n",
            "\n",
            "Iteration:  145 trainCost:  1.4184418 trainAccurancy:  0.5859375 testCost:  1.7924165 testAccurancy:  0.4296875\n",
            "\n",
            "Iteration:  146 trainCost:  1.4301335 trainAccurancy:  0.5234375 testCost:  1.6520239 testAccurancy:  0.453125\n",
            "\n",
            "Iteration:  147 trainCost:  1.6733898 trainAccurancy:  0.46875 testCost:  1.5722432 testAccurancy:  0.4765625\n",
            "\n",
            "Iteration:  148 trainCost:  1.670888 trainAccurancy:  0.5078125 testCost:  1.7387087 testAccurancy:  0.5\n",
            "\n",
            "Iteration:  149 trainCost:  1.3882432 trainAccurancy:  0.5390625 testCost:  1.9889998 testAccurancy:  0.4296875\n",
            "\n",
            "Iteration:  150 trainCost:  1.7288973 trainAccurancy:  0.4453125 testCost:  1.6702875 testAccurancy:  0.5\n",
            "\n",
            "Iteration:  151 trainCost:  1.8401878 trainAccurancy:  0.4453125 testCost:  1.8308419 testAccurancy:  0.5\n",
            "\n",
            "Iteration:  152 trainCost:  2.0222154 trainAccurancy:  0.453125 testCost:  1.8029337 testAccurancy:  0.4921875\n",
            "\n",
            "Iteration:  153 trainCost:  1.4643276 trainAccurancy:  0.5 testCost:  1.5219555 testAccurancy:  0.515625\n",
            "\n",
            "Iteration:  154 trainCost:  1.8199239 trainAccurancy:  0.4453125 testCost:  1.5164888 testAccurancy:  0.5234375\n",
            "\n",
            "Iteration:  155 trainCost:  1.8783257 trainAccurancy:  0.4609375 testCost:  1.5855684 testAccurancy:  0.453125\n",
            "\n",
            "Iteration:  156 trainCost:  1.6225052 trainAccurancy:  0.53125 testCost:  1.6195816 testAccurancy:  0.4765625\n",
            "\n",
            "Iteration:  157 trainCost:  1.5968189 trainAccurancy:  0.5703125 testCost:  1.5837753 testAccurancy:  0.4921875\n",
            "\n",
            "Iteration:  158 trainCost:  1.4966375 trainAccurancy:  0.546875 testCost:  1.5164243 testAccurancy:  0.5703125\n",
            "\n",
            "Iteration:  159 trainCost:  1.6193141 trainAccurancy:  0.4765625 testCost:  1.52032 testAccurancy:  0.5703125\n",
            "\n",
            "Iteration:  160 trainCost:  1.7158802 trainAccurancy:  0.46875 testCost:  1.6426508 testAccurancy:  0.453125\n",
            "\n",
            "Iteration:  161 trainCost:  1.7954148 trainAccurancy:  0.421875 testCost:  1.6776955 testAccurancy:  0.4921875\n",
            "\n",
            "Iteration:  162 trainCost:  1.5642157 trainAccurancy:  0.5 testCost:  1.6297586 testAccurancy:  0.546875\n",
            "\n",
            "Iteration:  163 trainCost:  1.4753429 trainAccurancy:  0.5390625 testCost:  1.7107203 testAccurancy:  0.5390625\n",
            "\n",
            "Iteration:  164 trainCost:  1.7224832 trainAccurancy:  0.4921875 testCost:  1.6089029 testAccurancy:  0.4765625\n",
            "\n",
            "Iteration:  165 trainCost:  1.6491139 trainAccurancy:  0.5546875 testCost:  1.3143625 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  166 trainCost:  1.3361225 trainAccurancy:  0.6015625 testCost:  1.5676494 testAccurancy:  0.484375\n",
            "\n",
            "Iteration:  167 trainCost:  1.4682753 trainAccurancy:  0.5390625 testCost:  1.6549144 testAccurancy:  0.4453125\n",
            "\n",
            "Iteration:  168 trainCost:  1.5319463 trainAccurancy:  0.5078125 testCost:  1.6664736 testAccurancy:  0.421875\n",
            "\n",
            "Iteration:  169 trainCost:  1.5403821 trainAccurancy:  0.515625 testCost:  1.6131777 testAccurancy:  0.484375\n",
            "\n",
            "Iteration:  170 trainCost:  1.6037921 trainAccurancy:  0.546875 testCost:  1.3234596 testAccurancy:  0.5546875\n",
            "\n",
            "Iteration:  171 trainCost:  1.6325674 trainAccurancy:  0.53125 testCost:  1.6557727 testAccurancy:  0.5078125\n",
            "\n",
            "Iteration:  172 trainCost:  1.608046 trainAccurancy:  0.484375 testCost:  1.6327763 testAccurancy:  0.46875\n",
            "\n",
            "Iteration:  173 trainCost:  1.3832589 trainAccurancy:  0.5390625 testCost:  1.4862831 testAccurancy:  0.5703125\n",
            "\n",
            "Iteration:  174 trainCost:  1.7826338 trainAccurancy:  0.4921875 testCost:  1.6977748 testAccurancy:  0.5078125\n",
            "\n",
            "Iteration:  175 trainCost:  1.6205573 trainAccurancy:  0.5234375 testCost:  1.8137997 testAccurancy:  0.4609375\n",
            "\n",
            "Iteration:  176 trainCost:  1.8083105 trainAccurancy:  0.484375 testCost:  1.7164698 testAccurancy:  0.5546875\n",
            "\n",
            "Iteration:  177 trainCost:  1.5803856 trainAccurancy:  0.5 testCost:  1.6082072 testAccurancy:  0.578125\n",
            "\n",
            "Iteration:  178 trainCost:  1.9571965 trainAccurancy:  0.46875 testCost:  1.2953401 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  179 trainCost:  1.2616261 trainAccurancy:  0.5859375 testCost:  1.3727269 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  180 trainCost:  1.5678841 trainAccurancy:  0.515625 testCost:  1.5054626 testAccurancy:  0.5234375\n",
            "\n",
            "Iteration:  181 trainCost:  1.3679401 trainAccurancy:  0.6328125 testCost:  1.4163016 testAccurancy:  0.5546875\n",
            "\n",
            "Iteration:  182 trainCost:  1.7067574 trainAccurancy:  0.484375 testCost:  1.3249574 testAccurancy:  0.5625\n",
            "\n",
            "Iteration:  183 trainCost:  1.377194 trainAccurancy:  0.5546875 testCost:  1.2933655 testAccurancy:  0.5703125\n",
            "\n",
            "Iteration:  184 trainCost:  1.7555311 trainAccurancy:  0.46875 testCost:  1.547226 testAccurancy:  0.4921875\n",
            "\n",
            "Iteration:  185 trainCost:  1.6673763 trainAccurancy:  0.5 testCost:  1.3386536 testAccurancy:  0.609375\n",
            "\n",
            "Iteration:  186 trainCost:  1.3510435 trainAccurancy:  0.5859375 testCost:  1.480478 testAccurancy:  0.5703125\n",
            "\n",
            "Iteration:  187 trainCost:  1.3023136 trainAccurancy:  0.5625 testCost:  1.3145425 testAccurancy:  0.5859375\n",
            "\n",
            "Iteration:  188 trainCost:  1.4701619 trainAccurancy:  0.5390625 testCost:  1.2384472 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  189 trainCost:  1.3303984 trainAccurancy:  0.5859375 testCost:  1.1592287 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  190 trainCost:  1.341206 trainAccurancy:  0.53125 testCost:  1.5680195 testAccurancy:  0.515625\n",
            "\n",
            "Iteration:  191 trainCost:  1.3483102 trainAccurancy:  0.59375 testCost:  1.4828835 testAccurancy:  0.5234375\n",
            "\n",
            "Iteration:  192 trainCost:  1.4998 trainAccurancy:  0.5234375 testCost:  1.3671261 testAccurancy:  0.5546875\n",
            "\n",
            "Iteration:  193 trainCost:  1.2766634 trainAccurancy:  0.625 testCost:  1.3207113 testAccurancy:  0.5859375\n",
            "\n",
            "Iteration:  194 trainCost:  1.3527765 trainAccurancy:  0.5546875 testCost:  1.5617223 testAccurancy:  0.5078125\n",
            "\n",
            "Iteration:  195 trainCost:  1.392945 trainAccurancy:  0.578125 testCost:  1.405231 testAccurancy:  0.5625\n",
            "\n",
            "Iteration:  196 trainCost:  1.4792072 trainAccurancy:  0.53125 testCost:  1.6206741 testAccurancy:  0.5078125\n",
            "\n",
            "Iteration:  197 trainCost:  1.5756546 trainAccurancy:  0.5 testCost:  1.4459264 testAccurancy:  0.5234375\n",
            "\n",
            "Iteration:  198 trainCost:  1.2457635 trainAccurancy:  0.6171875 testCost:  1.5085874 testAccurancy:  0.5546875\n",
            "\n",
            "Iteration:  199 trainCost:  1.5492098 trainAccurancy:  0.4921875 testCost:  1.4616001 testAccurancy:  0.5234375\n",
            "\n",
            "Iteration:  200 trainCost:  1.3125814 trainAccurancy:  0.59375 testCost:  1.5482237 testAccurancy:  0.53125\n",
            "\n",
            "Iteration:  201 trainCost:  1.0524774 trainAccurancy:  0.6484375 testCost:  1.3551795 testAccurancy:  0.546875\n",
            "\n",
            "Iteration:  202 trainCost:  1.2745874 trainAccurancy:  0.6171875 testCost:  1.1890289 testAccurancy:  0.5859375\n",
            "\n",
            "Iteration:  203 trainCost:  1.2244486 trainAccurancy:  0.625 testCost:  1.1935685 testAccurancy:  0.6328125\n",
            "\n",
            "Iteration:  204 trainCost:  1.0147883 trainAccurancy:  0.6328125 testCost:  1.3704658 testAccurancy:  0.59375\n",
            "\n",
            "Iteration:  205 trainCost:  1.3531141 trainAccurancy:  0.5703125 testCost:  1.1257194 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  206 trainCost:  1.3075122 trainAccurancy:  0.578125 testCost:  1.3851557 testAccurancy:  0.59375\n",
            "\n",
            "Iteration:  207 trainCost:  1.2416694 trainAccurancy:  0.6015625 testCost:  1.2354331 testAccurancy:  0.609375\n",
            "\n",
            "Iteration:  208 trainCost:  1.363263 trainAccurancy:  0.59375 testCost:  1.2176261 testAccurancy:  0.609375\n",
            "\n",
            "Iteration:  209 trainCost:  1.4421006 trainAccurancy:  0.59375 testCost:  1.2049952 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  210 trainCost:  1.2969369 trainAccurancy:  0.6328125 testCost:  1.1985972 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  211 trainCost:  1.4995033 trainAccurancy:  0.5546875 testCost:  1.2653968 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  212 trainCost:  1.3040851 trainAccurancy:  0.5546875 testCost:  1.1701721 testAccurancy:  0.609375\n",
            "\n",
            "Iteration:  213 trainCost:  1.4226438 trainAccurancy:  0.5703125 testCost:  1.189429 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  214 trainCost:  1.2532036 trainAccurancy:  0.59375 testCost:  1.1663306 testAccurancy:  0.65625\n",
            "\n",
            "Iteration:  215 trainCost:  1.3970096 trainAccurancy:  0.515625 testCost:  1.0935503 testAccurancy:  0.6640625\n",
            "\n",
            "Iteration:  216 trainCost:  1.4574769 trainAccurancy:  0.5546875 testCost:  1.2483655 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  217 trainCost:  1.2098945 trainAccurancy:  0.625 testCost:  1.3308597 testAccurancy:  0.53125\n",
            "\n",
            "Iteration:  218 trainCost:  1.4670688 trainAccurancy:  0.5859375 testCost:  1.3034227 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  219 trainCost:  1.1810133 trainAccurancy:  0.671875 testCost:  1.364801 testAccurancy:  0.5703125\n",
            "\n",
            "Iteration:  220 trainCost:  1.5377021 trainAccurancy:  0.5859375 testCost:  1.0828695 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  221 trainCost:  1.6849253 trainAccurancy:  0.515625 testCost:  1.3212099 testAccurancy:  0.59375\n",
            "\n",
            "Iteration:  222 trainCost:  1.0467819 trainAccurancy:  0.6328125 testCost:  1.2212179 testAccurancy:  0.609375\n",
            "\n",
            "Iteration:  223 trainCost:  1.1733189 trainAccurancy:  0.6796875 testCost:  1.3781393 testAccurancy:  0.59375\n",
            "\n",
            "Iteration:  224 trainCost:  1.2654833 trainAccurancy:  0.609375 testCost:  1.1181173 testAccurancy:  0.609375\n",
            "\n",
            "Iteration:  225 trainCost:  1.144913 trainAccurancy:  0.609375 testCost:  1.1555586 testAccurancy:  0.59375\n",
            "\n",
            "Iteration:  226 trainCost:  1.1717913 trainAccurancy:  0.6328125 testCost:  1.1949306 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  227 trainCost:  1.3415489 trainAccurancy:  0.6328125 testCost:  1.3139104 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  228 trainCost:  1.4808385 trainAccurancy:  0.5703125 testCost:  1.1354614 testAccurancy:  0.6640625\n",
            "\n",
            "Iteration:  229 trainCost:  1.4597592 trainAccurancy:  0.515625 testCost:  1.247055 testAccurancy:  0.5859375\n",
            "\n",
            "Iteration:  230 trainCost:  0.9913675 trainAccurancy:  0.671875 testCost:  1.0611403 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  231 trainCost:  1.258785 trainAccurancy:  0.6171875 testCost:  1.3244584 testAccurancy:  0.5625\n",
            "\n",
            "Iteration:  232 trainCost:  1.2790294 trainAccurancy:  0.59375 testCost:  1.1871548 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  233 trainCost:  1.3088075 trainAccurancy:  0.5703125 testCost:  1.2106367 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  234 trainCost:  1.208967 trainAccurancy:  0.5859375 testCost:  1.1240196 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  235 trainCost:  1.3199346 trainAccurancy:  0.5625 testCost:  1.1494701 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  236 trainCost:  1.279975 trainAccurancy:  0.640625 testCost:  1.2303718 testAccurancy:  0.59375\n",
            "\n",
            "Iteration:  237 trainCost:  1.2722845 trainAccurancy:  0.6328125 testCost:  1.2867332 testAccurancy:  0.578125\n",
            "\n",
            "Iteration:  238 trainCost:  1.0805463 trainAccurancy:  0.625 testCost:  1.3237908 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  239 trainCost:  1.2863137 trainAccurancy:  0.59375 testCost:  1.0167558 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  240 trainCost:  1.0189784 trainAccurancy:  0.6484375 testCost:  1.1463284 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  241 trainCost:  0.9779763 trainAccurancy:  0.671875 testCost:  1.2977252 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  242 trainCost:  1.0595379 trainAccurancy:  0.671875 testCost:  1.0660825 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  243 trainCost:  1.3169602 trainAccurancy:  0.6171875 testCost:  1.0578465 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  244 trainCost:  1.0122077 trainAccurancy:  0.6171875 testCost:  1.0226647 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  245 trainCost:  1.194571 trainAccurancy:  0.6171875 testCost:  1.2039522 testAccurancy:  0.6640625\n",
            "\n",
            "Iteration:  246 trainCost:  1.1541748 trainAccurancy:  0.6328125 testCost:  1.3082138 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  247 trainCost:  1.2747241 trainAccurancy:  0.6640625 testCost:  1.1417382 testAccurancy:  0.609375\n",
            "\n",
            "Iteration:  248 trainCost:  1.205155 trainAccurancy:  0.6484375 testCost:  1.076737 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  249 trainCost:  1.2139332 trainAccurancy:  0.625 testCost:  1.2377845 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  250 trainCost:  1.412083 trainAccurancy:  0.5546875 testCost:  0.9170612 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  251 trainCost:  1.2408736 trainAccurancy:  0.625 testCost:  1.1341707 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  252 trainCost:  1.1411264 trainAccurancy:  0.6484375 testCost:  1.1491877 testAccurancy:  0.65625\n",
            "\n",
            "Iteration:  253 trainCost:  1.2570475 trainAccurancy:  0.6328125 testCost:  1.1141831 testAccurancy:  0.6328125\n",
            "\n",
            "Iteration:  254 trainCost:  1.2568004 trainAccurancy:  0.6484375 testCost:  1.2309892 testAccurancy:  0.6328125\n",
            "\n",
            "Iteration:  255 trainCost:  1.18347 trainAccurancy:  0.5859375 testCost:  0.9331496 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  256 trainCost:  1.2041175 trainAccurancy:  0.625 testCost:  1.2659063 testAccurancy:  0.5859375\n",
            "\n",
            "Iteration:  257 trainCost:  1.2403617 trainAccurancy:  0.6328125 testCost:  1.2080477 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  258 trainCost:  1.1014568 trainAccurancy:  0.6796875 testCost:  1.2880054 testAccurancy:  0.5859375\n",
            "\n",
            "Iteration:  259 trainCost:  1.3773315 trainAccurancy:  0.5703125 testCost:  1.1140285 testAccurancy:  0.6640625\n",
            "\n",
            "Iteration:  260 trainCost:  1.3814669 trainAccurancy:  0.5390625 testCost:  0.97833145 testAccurancy:  0.65625\n",
            "\n",
            "Iteration:  261 trainCost:  1.2079577 trainAccurancy:  0.59375 testCost:  0.9811875 testAccurancy:  0.6640625\n",
            "\n",
            "Iteration:  262 trainCost:  1.1093068 trainAccurancy:  0.640625 testCost:  1.227591 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  263 trainCost:  1.1518414 trainAccurancy:  0.6015625 testCost:  1.0019883 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  264 trainCost:  1.071051 trainAccurancy:  0.703125 testCost:  1.0919716 testAccurancy:  0.6640625\n",
            "\n",
            "Iteration:  265 trainCost:  1.1432676 trainAccurancy:  0.6171875 testCost:  1.2129278 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  266 trainCost:  1.0691574 trainAccurancy:  0.609375 testCost:  1.2300212 testAccurancy:  0.640625\n",
            "\n",
            "Iteration:  267 trainCost:  1.2620721 trainAccurancy:  0.6171875 testCost:  0.9352557 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  268 trainCost:  1.0500963 trainAccurancy:  0.6875 testCost:  1.1252346 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  269 trainCost:  1.0294273 trainAccurancy:  0.65625 testCost:  1.0479224 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  270 trainCost:  1.0943553 trainAccurancy:  0.65625 testCost:  1.1943307 testAccurancy:  0.640625\n",
            "\n",
            "Iteration:  271 trainCost:  1.1281224 trainAccurancy:  0.6640625 testCost:  0.99762 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  272 trainCost:  1.073242 trainAccurancy:  0.7265625 testCost:  0.9743127 testAccurancy:  0.6953125\n",
            "\n",
            "Iteration:  273 trainCost:  1.135 trainAccurancy:  0.625 testCost:  1.1383052 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  274 trainCost:  1.133564 trainAccurancy:  0.625 testCost:  1.4053767 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  275 trainCost:  1.1760074 trainAccurancy:  0.59375 testCost:  1.0612509 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  276 trainCost:  1.1715789 trainAccurancy:  0.625 testCost:  1.1168125 testAccurancy:  0.65625\n",
            "\n",
            "Iteration:  277 trainCost:  1.0866199 trainAccurancy:  0.59375 testCost:  1.063812 testAccurancy:  0.6328125\n",
            "\n",
            "Iteration:  278 trainCost:  0.91669846 trainAccurancy:  0.703125 testCost:  0.8380575 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  279 trainCost:  1.096684 trainAccurancy:  0.6328125 testCost:  0.99274343 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  280 trainCost:  1.1543727 trainAccurancy:  0.609375 testCost:  1.201101 testAccurancy:  0.6015625\n",
            "\n",
            "Iteration:  281 trainCost:  1.2263287 trainAccurancy:  0.625 testCost:  1.0466431 testAccurancy:  0.6328125\n",
            "\n",
            "Iteration:  282 trainCost:  1.0521231 trainAccurancy:  0.703125 testCost:  0.9658464 testAccurancy:  0.6953125\n",
            "\n",
            "Iteration:  283 trainCost:  1.2303419 trainAccurancy:  0.6484375 testCost:  1.2434019 testAccurancy:  0.6171875\n",
            "\n",
            "Iteration:  284 trainCost:  1.0751435 trainAccurancy:  0.6484375 testCost:  0.84915185 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  285 trainCost:  0.97624266 trainAccurancy:  0.671875 testCost:  0.93825686 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  286 trainCost:  1.198848 trainAccurancy:  0.65625 testCost:  0.93317986 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  287 trainCost:  1.0389745 trainAccurancy:  0.703125 testCost:  1.0270844 testAccurancy:  0.640625\n",
            "\n",
            "Iteration:  288 trainCost:  1.1445022 trainAccurancy:  0.6875 testCost:  1.0652083 testAccurancy:  0.640625\n",
            "\n",
            "Iteration:  289 trainCost:  0.9586334 trainAccurancy:  0.6953125 testCost:  0.94219756 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  290 trainCost:  1.058431 trainAccurancy:  0.6484375 testCost:  0.8964951 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  291 trainCost:  1.280066 trainAccurancy:  0.6171875 testCost:  0.7970873 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  292 trainCost:  0.9758327 trainAccurancy:  0.6875 testCost:  0.9227079 testAccurancy:  0.6953125\n",
            "\n",
            "Iteration:  293 trainCost:  1.0799799 trainAccurancy:  0.625 testCost:  0.97584265 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  294 trainCost:  1.1478641 trainAccurancy:  0.6171875 testCost:  1.1295823 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  295 trainCost:  1.2936282 trainAccurancy:  0.6484375 testCost:  0.9421445 testAccurancy:  0.6640625\n",
            "\n",
            "Iteration:  296 trainCost:  0.96548045 trainAccurancy:  0.703125 testCost:  0.7755599 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  297 trainCost:  1.109627 trainAccurancy:  0.6484375 testCost:  0.9979265 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  298 trainCost:  0.9545994 trainAccurancy:  0.6953125 testCost:  1.0888823 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  299 trainCost:  0.9479772 trainAccurancy:  0.6796875 testCost:  1.1273038 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  300 trainCost:  0.87971973 trainAccurancy:  0.6640625 testCost:  0.98854923 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  301 trainCost:  1.0436082 trainAccurancy:  0.6875 testCost:  1.0472062 testAccurancy:  0.640625\n",
            "\n",
            "Iteration:  302 trainCost:  1.1845068 trainAccurancy:  0.609375 testCost:  0.9800795 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  303 trainCost:  0.86402464 trainAccurancy:  0.734375 testCost:  1.0595214 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  304 trainCost:  1.0638403 trainAccurancy:  0.6796875 testCost:  0.9944029 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  305 trainCost:  0.9952992 trainAccurancy:  0.6953125 testCost:  1.0405318 testAccurancy:  0.65625\n",
            "\n",
            "Iteration:  306 trainCost:  1.0441648 trainAccurancy:  0.671875 testCost:  0.8509798 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  307 trainCost:  1.0969977 trainAccurancy:  0.671875 testCost:  0.96528757 testAccurancy:  0.65625\n",
            "\n",
            "Iteration:  308 trainCost:  1.1983371 trainAccurancy:  0.625 testCost:  1.1768169 testAccurancy:  0.640625\n",
            "\n",
            "Iteration:  309 trainCost:  0.9085975 trainAccurancy:  0.734375 testCost:  1.0048131 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  310 trainCost:  1.0579468 trainAccurancy:  0.6796875 testCost:  0.8422494 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  311 trainCost:  1.3201041 trainAccurancy:  0.6015625 testCost:  0.962572 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  312 trainCost:  1.1385758 trainAccurancy:  0.5859375 testCost:  0.8981241 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  313 trainCost:  0.91606736 trainAccurancy:  0.7109375 testCost:  1.0545058 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  314 trainCost:  1.0397066 trainAccurancy:  0.671875 testCost:  0.96075606 testAccurancy:  0.65625\n",
            "\n",
            "Iteration:  315 trainCost:  1.2017539 trainAccurancy:  0.640625 testCost:  1.0940973 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  316 trainCost:  1.0538723 trainAccurancy:  0.6875 testCost:  1.0795051 testAccurancy:  0.640625\n",
            "\n",
            "Iteration:  317 trainCost:  1.1587387 trainAccurancy:  0.6171875 testCost:  0.8438412 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  318 trainCost:  0.8956435 trainAccurancy:  0.7421875 testCost:  0.7730456 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  319 trainCost:  0.9395751 trainAccurancy:  0.703125 testCost:  0.8493433 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  320 trainCost:  1.0161641 trainAccurancy:  0.6484375 testCost:  0.9831683 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  321 trainCost:  0.89124906 trainAccurancy:  0.7109375 testCost:  1.0676427 testAccurancy:  0.640625\n",
            "\n",
            "Iteration:  322 trainCost:  1.1892756 trainAccurancy:  0.6796875 testCost:  0.7946627 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  323 trainCost:  1.0314589 trainAccurancy:  0.6796875 testCost:  0.93041414 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  324 trainCost:  1.0971074 trainAccurancy:  0.65625 testCost:  0.8378838 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  325 trainCost:  0.86314476 trainAccurancy:  0.7421875 testCost:  0.88294387 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  326 trainCost:  1.0395961 trainAccurancy:  0.6953125 testCost:  0.82718027 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  327 trainCost:  1.0988964 trainAccurancy:  0.6328125 testCost:  0.7523121 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  328 trainCost:  0.9373024 trainAccurancy:  0.65625 testCost:  0.89147174 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  329 trainCost:  1.0618335 trainAccurancy:  0.6640625 testCost:  0.7837266 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  330 trainCost:  1.1029158 trainAccurancy:  0.59375 testCost:  0.83958507 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  331 trainCost:  0.9737965 trainAccurancy:  0.71875 testCost:  0.92853934 testAccurancy:  0.6953125\n",
            "\n",
            "Iteration:  332 trainCost:  1.0886699 trainAccurancy:  0.65625 testCost:  0.92729646 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  333 trainCost:  0.84463346 trainAccurancy:  0.734375 testCost:  1.241928 testAccurancy:  0.625\n",
            "\n",
            "Iteration:  334 trainCost:  0.9285438 trainAccurancy:  0.7109375 testCost:  0.8412589 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  335 trainCost:  1.0350062 trainAccurancy:  0.6484375 testCost:  0.8980868 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  336 trainCost:  0.9845013 trainAccurancy:  0.703125 testCost:  1.0171857 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  337 trainCost:  0.99195814 trainAccurancy:  0.6875 testCost:  1.0702335 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  338 trainCost:  1.0174556 trainAccurancy:  0.71875 testCost:  0.67953765 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  339 trainCost:  1.0691175 trainAccurancy:  0.6875 testCost:  1.0452585 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  340 trainCost:  0.8441605 trainAccurancy:  0.7109375 testCost:  0.82311416 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  341 trainCost:  0.905168 trainAccurancy:  0.6875 testCost:  0.96245646 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  342 trainCost:  0.98414457 trainAccurancy:  0.671875 testCost:  0.82493496 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  343 trainCost:  0.9833172 trainAccurancy:  0.7109375 testCost:  1.1032832 testAccurancy:  0.6640625\n",
            "\n",
            "Iteration:  344 trainCost:  1.0217271 trainAccurancy:  0.7109375 testCost:  0.79755145 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  345 trainCost:  0.7973496 trainAccurancy:  0.8046875 testCost:  0.87593675 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  346 trainCost:  0.9883449 trainAccurancy:  0.6640625 testCost:  0.97553957 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  347 trainCost:  1.027147 trainAccurancy:  0.6640625 testCost:  0.6985963 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  348 trainCost:  0.8172318 trainAccurancy:  0.734375 testCost:  1.0563898 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  349 trainCost:  0.9151684 trainAccurancy:  0.7421875 testCost:  0.88131523 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  350 trainCost:  0.9345223 trainAccurancy:  0.7109375 testCost:  0.75915676 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  351 trainCost:  1.1735774 trainAccurancy:  0.6328125 testCost:  0.8245208 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  352 trainCost:  0.91859245 trainAccurancy:  0.7421875 testCost:  0.96005017 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  353 trainCost:  1.0017306 trainAccurancy:  0.65625 testCost:  0.82376707 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  354 trainCost:  0.8316734 trainAccurancy:  0.734375 testCost:  0.95621514 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  355 trainCost:  0.8139982 trainAccurancy:  0.734375 testCost:  0.8273481 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  356 trainCost:  1.006752 trainAccurancy:  0.6875 testCost:  0.94625676 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  357 trainCost:  1.1801783 trainAccurancy:  0.671875 testCost:  0.7899292 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  358 trainCost:  0.7860092 trainAccurancy:  0.734375 testCost:  0.8637855 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  359 trainCost:  0.75493884 trainAccurancy:  0.75 testCost:  1.0934993 testAccurancy:  0.6953125\n",
            "\n",
            "Iteration:  360 trainCost:  1.1715416 trainAccurancy:  0.640625 testCost:  0.8486164 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  361 trainCost:  0.87383914 trainAccurancy:  0.6953125 testCost:  0.89098155 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  362 trainCost:  0.94211257 trainAccurancy:  0.6796875 testCost:  0.7851683 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  363 trainCost:  0.94736797 trainAccurancy:  0.7109375 testCost:  0.80193853 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  364 trainCost:  0.88708735 trainAccurancy:  0.7109375 testCost:  0.851608 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  365 trainCost:  0.9564876 trainAccurancy:  0.75 testCost:  0.90513575 testAccurancy:  0.6953125\n",
            "\n",
            "Iteration:  366 trainCost:  0.7114513 trainAccurancy:  0.75 testCost:  0.8980297 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  367 trainCost:  0.73452747 trainAccurancy:  0.7421875 testCost:  0.74275833 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  368 trainCost:  0.72368944 trainAccurancy:  0.734375 testCost:  1.0775776 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  369 trainCost:  0.96466184 trainAccurancy:  0.6484375 testCost:  0.7955656 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  370 trainCost:  0.858458 trainAccurancy:  0.7734375 testCost:  0.76760554 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  371 trainCost:  1.0361449 trainAccurancy:  0.703125 testCost:  0.91953385 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  372 trainCost:  0.8986962 trainAccurancy:  0.75 testCost:  0.9401642 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  373 trainCost:  0.7597544 trainAccurancy:  0.796875 testCost:  0.96804774 testAccurancy:  0.6796875\n",
            "\n",
            "Iteration:  374 trainCost:  1.0448569 trainAccurancy:  0.6640625 testCost:  1.0777315 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  375 trainCost:  0.8344536 trainAccurancy:  0.734375 testCost:  0.8881804 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  376 trainCost:  1.0276115 trainAccurancy:  0.671875 testCost:  0.7965015 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  377 trainCost:  0.8019252 trainAccurancy:  0.7421875 testCost:  0.6988586 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  378 trainCost:  0.79544383 trainAccurancy:  0.796875 testCost:  0.81950986 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  379 trainCost:  0.93675756 trainAccurancy:  0.734375 testCost:  0.8086273 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  380 trainCost:  0.8573177 trainAccurancy:  0.75 testCost:  0.88093054 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  381 trainCost:  0.7014095 trainAccurancy:  0.765625 testCost:  0.7209804 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  382 trainCost:  0.80936384 trainAccurancy:  0.7421875 testCost:  0.8042332 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  383 trainCost:  0.7740844 trainAccurancy:  0.7734375 testCost:  1.0497355 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  384 trainCost:  0.80038524 trainAccurancy:  0.7578125 testCost:  0.92340904 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  385 trainCost:  0.93200815 trainAccurancy:  0.71875 testCost:  0.9957544 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  386 trainCost:  0.8874264 trainAccurancy:  0.7265625 testCost:  0.67594767 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  387 trainCost:  0.87648106 trainAccurancy:  0.7421875 testCost:  0.90049183 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  388 trainCost:  0.7335221 trainAccurancy:  0.7578125 testCost:  0.6532329 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  389 trainCost:  0.8941831 trainAccurancy:  0.7109375 testCost:  0.8212052 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  390 trainCost:  0.802268 trainAccurancy:  0.7109375 testCost:  0.78597134 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  391 trainCost:  1.011445 trainAccurancy:  0.6953125 testCost:  0.71832526 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  392 trainCost:  0.80148745 trainAccurancy:  0.75 testCost:  0.69430685 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  393 trainCost:  0.9368237 trainAccurancy:  0.6953125 testCost:  0.88245994 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  394 trainCost:  0.995876 trainAccurancy:  0.6953125 testCost:  0.77945167 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  395 trainCost:  0.7575129 trainAccurancy:  0.75 testCost:  0.7436007 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  396 trainCost:  0.8882433 trainAccurancy:  0.7421875 testCost:  0.8785412 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  397 trainCost:  0.86273634 trainAccurancy:  0.7109375 testCost:  0.9514677 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  398 trainCost:  0.8217679 trainAccurancy:  0.75 testCost:  0.96443325 testAccurancy:  0.671875\n",
            "\n",
            "Iteration:  399 trainCost:  1.0089769 trainAccurancy:  0.6640625 testCost:  0.85996914 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  400 trainCost:  1.0058318 trainAccurancy:  0.6875 testCost:  0.62227464 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  401 trainCost:  0.80494124 trainAccurancy:  0.703125 testCost:  0.71901155 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  402 trainCost:  0.85758716 trainAccurancy:  0.7578125 testCost:  0.8506304 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  403 trainCost:  0.92845494 trainAccurancy:  0.6953125 testCost:  0.7711824 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  404 trainCost:  0.87968826 trainAccurancy:  0.7109375 testCost:  0.6907289 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  405 trainCost:  0.8519935 trainAccurancy:  0.703125 testCost:  0.95907426 testAccurancy:  0.6953125\n",
            "\n",
            "Iteration:  406 trainCost:  1.082996 trainAccurancy:  0.7109375 testCost:  0.6472275 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  407 trainCost:  0.888287 trainAccurancy:  0.7421875 testCost:  0.6085918 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  408 trainCost:  0.8193741 trainAccurancy:  0.703125 testCost:  0.9101271 testAccurancy:  0.6875\n",
            "\n",
            "Iteration:  409 trainCost:  0.6270137 trainAccurancy:  0.796875 testCost:  0.7823458 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  410 trainCost:  0.865396 trainAccurancy:  0.734375 testCost:  0.77093637 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  411 trainCost:  0.96863914 trainAccurancy:  0.6953125 testCost:  0.6281625 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  412 trainCost:  0.84851927 trainAccurancy:  0.734375 testCost:  0.642678 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  413 trainCost:  0.8403079 trainAccurancy:  0.75 testCost:  0.5824921 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  414 trainCost:  0.8258389 trainAccurancy:  0.7734375 testCost:  0.8779706 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  415 trainCost:  0.67676705 trainAccurancy:  0.796875 testCost:  0.73510945 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  416 trainCost:  0.93435585 trainAccurancy:  0.7109375 testCost:  0.8619133 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  417 trainCost:  0.7305434 trainAccurancy:  0.765625 testCost:  0.8135327 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  418 trainCost:  0.96434426 trainAccurancy:  0.7265625 testCost:  0.7436003 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  419 trainCost:  0.83082354 trainAccurancy:  0.78125 testCost:  0.87894595 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  420 trainCost:  0.8124367 trainAccurancy:  0.7421875 testCost:  0.8957103 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  421 trainCost:  0.9894566 trainAccurancy:  0.6953125 testCost:  0.7136923 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  422 trainCost:  0.65091044 trainAccurancy:  0.78125 testCost:  0.90756893 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  423 trainCost:  0.7297716 trainAccurancy:  0.765625 testCost:  0.7819864 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  424 trainCost:  0.9378776 trainAccurancy:  0.6484375 testCost:  0.76170295 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  425 trainCost:  0.8288827 trainAccurancy:  0.7109375 testCost:  0.76681626 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  426 trainCost:  0.7635037 trainAccurancy:  0.75 testCost:  0.83009434 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  427 trainCost:  0.89863986 trainAccurancy:  0.7265625 testCost:  0.8798893 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  428 trainCost:  0.5674913 trainAccurancy:  0.8046875 testCost:  0.5902021 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  429 trainCost:  0.8208862 trainAccurancy:  0.75 testCost:  0.6312771 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  430 trainCost:  0.8205344 trainAccurancy:  0.75 testCost:  0.59230226 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  431 trainCost:  0.82623506 trainAccurancy:  0.7734375 testCost:  0.7784107 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  432 trainCost:  0.71655446 trainAccurancy:  0.7734375 testCost:  0.9709562 testAccurancy:  0.6484375\n",
            "\n",
            "Iteration:  433 trainCost:  1.0647955 trainAccurancy:  0.703125 testCost:  0.72181696 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  434 trainCost:  0.6703876 trainAccurancy:  0.796875 testCost:  0.7970674 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  435 trainCost:  0.84414583 trainAccurancy:  0.7578125 testCost:  0.7067127 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  436 trainCost:  0.7139497 trainAccurancy:  0.734375 testCost:  0.67560124 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  437 trainCost:  0.8671495 trainAccurancy:  0.734375 testCost:  0.7814919 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  438 trainCost:  0.78284335 trainAccurancy:  0.7265625 testCost:  0.8152336 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  439 trainCost:  0.7258179 trainAccurancy:  0.8125 testCost:  0.8468362 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  440 trainCost:  0.66286916 trainAccurancy:  0.8046875 testCost:  0.7564753 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  441 trainCost:  0.81377643 trainAccurancy:  0.75 testCost:  0.83267975 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  442 trainCost:  0.8284742 trainAccurancy:  0.7421875 testCost:  0.75776243 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  443 trainCost:  0.89875996 trainAccurancy:  0.703125 testCost:  0.9259351 testAccurancy:  0.6953125\n",
            "\n",
            "Iteration:  444 trainCost:  0.749428 trainAccurancy:  0.7578125 testCost:  0.6695849 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  445 trainCost:  0.8000686 trainAccurancy:  0.765625 testCost:  0.67757607 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  446 trainCost:  0.9524208 trainAccurancy:  0.6875 testCost:  0.84603846 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  447 trainCost:  0.77024937 trainAccurancy:  0.7734375 testCost:  0.8300198 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  448 trainCost:  0.9031407 trainAccurancy:  0.6875 testCost:  0.9270818 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  449 trainCost:  0.74112797 trainAccurancy:  0.78125 testCost:  0.7361479 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  450 trainCost:  0.7055961 trainAccurancy:  0.75 testCost:  0.5323667 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  451 trainCost:  0.6887602 trainAccurancy:  0.7890625 testCost:  0.8093262 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  452 trainCost:  0.6782798 trainAccurancy:  0.78125 testCost:  0.9260863 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  453 trainCost:  0.69472253 trainAccurancy:  0.7734375 testCost:  0.7682731 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  454 trainCost:  0.7440549 trainAccurancy:  0.765625 testCost:  0.77992916 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  455 trainCost:  0.7026387 trainAccurancy:  0.75 testCost:  0.8163384 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  456 trainCost:  0.772732 trainAccurancy:  0.75 testCost:  0.8348945 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  457 trainCost:  0.6719091 trainAccurancy:  0.78125 testCost:  0.70852494 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  458 trainCost:  0.8413481 trainAccurancy:  0.7421875 testCost:  0.74441385 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  459 trainCost:  0.58381724 trainAccurancy:  0.8125 testCost:  0.6992748 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  460 trainCost:  0.80972004 trainAccurancy:  0.75 testCost:  0.53375274 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  461 trainCost:  0.6897793 trainAccurancy:  0.796875 testCost:  0.79268306 testAccurancy:  0.7109375\n",
            "\n",
            "Iteration:  462 trainCost:  0.76697755 trainAccurancy:  0.765625 testCost:  0.8326813 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  463 trainCost:  0.7232495 trainAccurancy:  0.7890625 testCost:  0.6931782 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  464 trainCost:  0.74444103 trainAccurancy:  0.7734375 testCost:  0.9113611 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  465 trainCost:  0.72043484 trainAccurancy:  0.75 testCost:  0.60796016 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  466 trainCost:  0.7134118 trainAccurancy:  0.71875 testCost:  0.8296293 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  467 trainCost:  0.6884463 trainAccurancy:  0.7890625 testCost:  0.70131993 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  468 trainCost:  0.78138506 trainAccurancy:  0.7890625 testCost:  0.6429294 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  469 trainCost:  0.87505966 trainAccurancy:  0.7421875 testCost:  0.7252469 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  470 trainCost:  0.7039216 trainAccurancy:  0.8046875 testCost:  0.6546812 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  471 trainCost:  0.7012956 trainAccurancy:  0.8046875 testCost:  0.69536614 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  472 trainCost:  0.6861955 trainAccurancy:  0.765625 testCost:  0.50784093 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  473 trainCost:  0.6962893 trainAccurancy:  0.7890625 testCost:  0.76599085 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  474 trainCost:  0.74882245 trainAccurancy:  0.734375 testCost:  0.749811 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  475 trainCost:  0.76394296 trainAccurancy:  0.7734375 testCost:  0.7278559 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  476 trainCost:  0.72167426 trainAccurancy:  0.7578125 testCost:  0.56168914 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  477 trainCost:  0.67885983 trainAccurancy:  0.7734375 testCost:  0.86000884 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  478 trainCost:  0.62269795 trainAccurancy:  0.796875 testCost:  1.030896 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  479 trainCost:  0.77707046 trainAccurancy:  0.765625 testCost:  0.62745297 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  480 trainCost:  0.7412702 trainAccurancy:  0.7734375 testCost:  0.7415122 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  481 trainCost:  0.9327812 trainAccurancy:  0.75 testCost:  0.5992066 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  482 trainCost:  0.7378868 trainAccurancy:  0.78125 testCost:  0.62684 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  483 trainCost:  1.081095 trainAccurancy:  0.703125 testCost:  0.91386044 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  484 trainCost:  0.9916058 trainAccurancy:  0.7109375 testCost:  0.76572454 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  485 trainCost:  0.6748613 trainAccurancy:  0.8125 testCost:  0.55290943 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  486 trainCost:  0.5513763 trainAccurancy:  0.8203125 testCost:  0.687014 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  487 trainCost:  0.7032751 trainAccurancy:  0.765625 testCost:  0.8584478 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  488 trainCost:  0.7020316 trainAccurancy:  0.75 testCost:  0.5878222 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  489 trainCost:  0.9047899 trainAccurancy:  0.6953125 testCost:  0.68151736 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  490 trainCost:  0.90406555 trainAccurancy:  0.7421875 testCost:  0.73375696 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  491 trainCost:  0.8187338 trainAccurancy:  0.7578125 testCost:  0.71214426 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  492 trainCost:  0.89461136 trainAccurancy:  0.703125 testCost:  0.8065053 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  493 trainCost:  0.58113444 trainAccurancy:  0.8203125 testCost:  0.7148916 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  494 trainCost:  0.65646327 trainAccurancy:  0.8125 testCost:  0.6224797 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  495 trainCost:  0.7197263 trainAccurancy:  0.765625 testCost:  0.83655214 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  496 trainCost:  0.7846229 trainAccurancy:  0.75 testCost:  0.7468512 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  497 trainCost:  0.91037977 trainAccurancy:  0.703125 testCost:  0.64836276 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  498 trainCost:  0.72838277 trainAccurancy:  0.765625 testCost:  0.77706337 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  499 trainCost:  0.8149445 trainAccurancy:  0.6875 testCost:  0.7929281 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  500 trainCost:  0.7339325 trainAccurancy:  0.765625 testCost:  0.8074444 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  501 trainCost:  0.8502361 trainAccurancy:  0.734375 testCost:  0.7791768 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  502 trainCost:  0.7039327 trainAccurancy:  0.75 testCost:  0.59464765 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  503 trainCost:  0.7105595 trainAccurancy:  0.7578125 testCost:  0.60737896 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  504 trainCost:  0.7290057 trainAccurancy:  0.7890625 testCost:  0.68448716 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  505 trainCost:  0.8702214 trainAccurancy:  0.75 testCost:  0.6553585 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  506 trainCost:  0.6282871 trainAccurancy:  0.7890625 testCost:  0.65801764 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  507 trainCost:  0.894953 trainAccurancy:  0.7421875 testCost:  0.6815469 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  508 trainCost:  0.6752939 trainAccurancy:  0.7890625 testCost:  0.8767671 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  509 trainCost:  0.75483614 trainAccurancy:  0.7890625 testCost:  0.7953528 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  510 trainCost:  0.65404534 trainAccurancy:  0.796875 testCost:  0.7329817 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  511 trainCost:  0.5288485 trainAccurancy:  0.8203125 testCost:  0.7275036 testAccurancy:  0.71875\n",
            "\n",
            "Iteration:  512 trainCost:  0.71416795 trainAccurancy:  0.8046875 testCost:  0.519929 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  513 trainCost:  0.8038597 trainAccurancy:  0.7421875 testCost:  0.6045028 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  514 trainCost:  0.7174988 trainAccurancy:  0.75 testCost:  0.7375773 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  515 trainCost:  0.83206236 trainAccurancy:  0.7421875 testCost:  0.7283625 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  516 trainCost:  0.85209 trainAccurancy:  0.7734375 testCost:  0.6971626 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  517 trainCost:  0.5980869 trainAccurancy:  0.7578125 testCost:  0.7392098 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  518 trainCost:  0.7480406 trainAccurancy:  0.7578125 testCost:  0.6667494 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  519 trainCost:  0.6723128 trainAccurancy:  0.8125 testCost:  0.54751754 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  520 trainCost:  0.69312394 trainAccurancy:  0.7578125 testCost:  0.6980033 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  521 trainCost:  0.56409985 trainAccurancy:  0.8515625 testCost:  0.5612052 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  522 trainCost:  0.7155113 trainAccurancy:  0.7578125 testCost:  0.61593187 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  523 trainCost:  0.7037341 trainAccurancy:  0.75 testCost:  0.72695076 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  524 trainCost:  0.6297904 trainAccurancy:  0.8125 testCost:  0.7110858 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  525 trainCost:  0.73128587 trainAccurancy:  0.7734375 testCost:  0.5457722 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  526 trainCost:  0.8856147 trainAccurancy:  0.7421875 testCost:  0.59728724 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  527 trainCost:  0.7577938 trainAccurancy:  0.765625 testCost:  0.6128886 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  528 trainCost:  0.659384 trainAccurancy:  0.8203125 testCost:  0.78585434 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  529 trainCost:  0.5298054 trainAccurancy:  0.8515625 testCost:  0.90333164 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  530 trainCost:  0.6376625 trainAccurancy:  0.78125 testCost:  0.73251545 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  531 trainCost:  0.7268795 trainAccurancy:  0.7578125 testCost:  0.53456426 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  532 trainCost:  0.5486965 trainAccurancy:  0.859375 testCost:  0.7909599 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  533 trainCost:  0.58363605 trainAccurancy:  0.828125 testCost:  0.6028054 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  534 trainCost:  0.80523837 trainAccurancy:  0.765625 testCost:  0.7615697 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  535 trainCost:  0.6693967 trainAccurancy:  0.78125 testCost:  0.43178532 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  536 trainCost:  0.6782229 trainAccurancy:  0.78125 testCost:  0.70877695 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  537 trainCost:  0.7320422 trainAccurancy:  0.796875 testCost:  0.50994325 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  538 trainCost:  0.6467141 trainAccurancy:  0.7734375 testCost:  0.7431716 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  539 trainCost:  0.6119947 trainAccurancy:  0.78125 testCost:  0.63672626 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  540 trainCost:  0.81363857 trainAccurancy:  0.7265625 testCost:  0.74216 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  541 trainCost:  0.7540723 trainAccurancy:  0.71875 testCost:  0.7281524 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  542 trainCost:  0.7099675 trainAccurancy:  0.7890625 testCost:  0.5793498 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  543 trainCost:  0.943539 trainAccurancy:  0.6796875 testCost:  0.44532108 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  544 trainCost:  0.87559 trainAccurancy:  0.734375 testCost:  0.60262346 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  545 trainCost:  0.65734494 trainAccurancy:  0.7734375 testCost:  0.72147894 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  546 trainCost:  0.7647202 trainAccurancy:  0.734375 testCost:  0.64723563 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  547 trainCost:  0.72101605 trainAccurancy:  0.7890625 testCost:  0.557456 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  548 trainCost:  0.7208302 trainAccurancy:  0.7890625 testCost:  0.71053565 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  549 trainCost:  0.7179192 trainAccurancy:  0.734375 testCost:  0.7220392 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  550 trainCost:  0.7811496 trainAccurancy:  0.734375 testCost:  0.5981858 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  551 trainCost:  0.7286185 trainAccurancy:  0.7578125 testCost:  0.58460444 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  552 trainCost:  0.600671 trainAccurancy:  0.828125 testCost:  0.79331183 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  553 trainCost:  0.81641924 trainAccurancy:  0.765625 testCost:  0.73566353 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  554 trainCost:  0.58896804 trainAccurancy:  0.765625 testCost:  0.5456854 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  555 trainCost:  0.63812745 trainAccurancy:  0.796875 testCost:  0.51903164 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  556 trainCost:  0.6389282 trainAccurancy:  0.796875 testCost:  0.59864265 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  557 trainCost:  0.72653913 trainAccurancy:  0.7421875 testCost:  0.5218735 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  558 trainCost:  0.5563853 trainAccurancy:  0.828125 testCost:  0.5007657 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  559 trainCost:  0.80843514 trainAccurancy:  0.75 testCost:  0.54800224 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  560 trainCost:  0.85263216 trainAccurancy:  0.734375 testCost:  0.6807983 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  561 trainCost:  0.7168498 trainAccurancy:  0.78125 testCost:  0.579672 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  562 trainCost:  0.6456946 trainAccurancy:  0.8125 testCost:  0.72343117 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  563 trainCost:  0.6023185 trainAccurancy:  0.8125 testCost:  0.82709086 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  564 trainCost:  0.74302703 trainAccurancy:  0.765625 testCost:  0.5915389 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  565 trainCost:  0.6948165 trainAccurancy:  0.734375 testCost:  0.67295355 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  566 trainCost:  0.6572195 trainAccurancy:  0.8046875 testCost:  0.7893575 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  567 trainCost:  0.7394917 trainAccurancy:  0.7734375 testCost:  0.5962944 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  568 trainCost:  0.532061 trainAccurancy:  0.8359375 testCost:  0.6495553 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  569 trainCost:  0.720361 trainAccurancy:  0.78125 testCost:  0.7094409 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  570 trainCost:  0.6753844 trainAccurancy:  0.78125 testCost:  0.71917945 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  571 trainCost:  0.65895915 trainAccurancy:  0.828125 testCost:  0.65663457 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  572 trainCost:  0.6337801 trainAccurancy:  0.8046875 testCost:  0.7035496 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  573 trainCost:  0.8680796 trainAccurancy:  0.703125 testCost:  0.66321325 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  574 trainCost:  0.71554536 trainAccurancy:  0.765625 testCost:  0.6155206 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  575 trainCost:  0.81769454 trainAccurancy:  0.734375 testCost:  0.5926305 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  576 trainCost:  0.61454767 trainAccurancy:  0.8359375 testCost:  0.6355967 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  577 trainCost:  0.62440175 trainAccurancy:  0.8046875 testCost:  0.6195775 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  578 trainCost:  0.7264 trainAccurancy:  0.7890625 testCost:  0.69316036 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  579 trainCost:  0.64999014 trainAccurancy:  0.8046875 testCost:  0.6453748 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  580 trainCost:  0.7800416 trainAccurancy:  0.7734375 testCost:  0.73855853 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  581 trainCost:  0.6385752 trainAccurancy:  0.78125 testCost:  0.534702 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  582 trainCost:  0.5523089 trainAccurancy:  0.8203125 testCost:  0.58485496 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  583 trainCost:  0.61601484 trainAccurancy:  0.8046875 testCost:  0.53243434 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  584 trainCost:  0.64667773 trainAccurancy:  0.8125 testCost:  0.8936781 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  585 trainCost:  0.63572395 trainAccurancy:  0.796875 testCost:  0.58553123 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  586 trainCost:  0.5950836 trainAccurancy:  0.8046875 testCost:  0.6265476 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  587 trainCost:  0.62589085 trainAccurancy:  0.78125 testCost:  0.83333284 testAccurancy:  0.703125\n",
            "\n",
            "Iteration:  588 trainCost:  0.56577253 trainAccurancy:  0.796875 testCost:  0.72731775 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  589 trainCost:  0.56530106 trainAccurancy:  0.8125 testCost:  0.56003296 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  590 trainCost:  0.5421847 trainAccurancy:  0.78125 testCost:  0.6109884 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  591 trainCost:  0.71287835 trainAccurancy:  0.7421875 testCost:  0.89184195 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  592 trainCost:  0.64261556 trainAccurancy:  0.765625 testCost:  0.56434333 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  593 trainCost:  0.90260166 trainAccurancy:  0.71875 testCost:  0.6006799 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  594 trainCost:  0.6215169 trainAccurancy:  0.7734375 testCost:  0.5449754 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  595 trainCost:  0.43189096 trainAccurancy:  0.8671875 testCost:  0.45984054 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  596 trainCost:  0.6142776 trainAccurancy:  0.8203125 testCost:  0.6159886 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  597 trainCost:  0.4728587 trainAccurancy:  0.890625 testCost:  0.5760284 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  598 trainCost:  0.59611815 trainAccurancy:  0.796875 testCost:  0.65134686 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  599 trainCost:  0.6446817 trainAccurancy:  0.7890625 testCost:  0.6715142 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  600 trainCost:  0.63490915 trainAccurancy:  0.8203125 testCost:  0.4876604 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  601 trainCost:  0.761565 trainAccurancy:  0.7421875 testCost:  0.61606014 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  602 trainCost:  0.6990001 trainAccurancy:  0.7890625 testCost:  0.59603333 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  603 trainCost:  0.681272 trainAccurancy:  0.765625 testCost:  0.8238249 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  604 trainCost:  0.64641035 trainAccurancy:  0.8359375 testCost:  0.6300279 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  605 trainCost:  0.64032495 trainAccurancy:  0.8203125 testCost:  0.6713844 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  606 trainCost:  0.76159585 trainAccurancy:  0.765625 testCost:  0.45254958 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  607 trainCost:  0.5345508 trainAccurancy:  0.84375 testCost:  0.63637614 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  608 trainCost:  0.6783096 trainAccurancy:  0.7578125 testCost:  0.47446388 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  609 trainCost:  0.6753819 trainAccurancy:  0.8125 testCost:  0.5912497 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  610 trainCost:  0.69006276 trainAccurancy:  0.828125 testCost:  0.57681715 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  611 trainCost:  0.5982989 trainAccurancy:  0.8203125 testCost:  0.45299083 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  612 trainCost:  0.6552545 trainAccurancy:  0.7890625 testCost:  0.61788154 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  613 trainCost:  0.66042274 trainAccurancy:  0.78125 testCost:  0.7755989 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  614 trainCost:  0.36304685 trainAccurancy:  0.890625 testCost:  0.70267004 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  615 trainCost:  0.674503 trainAccurancy:  0.7734375 testCost:  0.5629287 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  616 trainCost:  0.6687367 trainAccurancy:  0.796875 testCost:  0.62296164 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  617 trainCost:  0.58347327 trainAccurancy:  0.8203125 testCost:  0.7110842 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  618 trainCost:  0.69154704 trainAccurancy:  0.796875 testCost:  0.5706687 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  619 trainCost:  0.55868596 trainAccurancy:  0.859375 testCost:  0.59259325 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  620 trainCost:  0.6911377 trainAccurancy:  0.78125 testCost:  0.6173699 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  621 trainCost:  0.68507814 trainAccurancy:  0.78125 testCost:  0.6714202 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  622 trainCost:  0.56606853 trainAccurancy:  0.8125 testCost:  0.5834645 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  623 trainCost:  0.64556646 trainAccurancy:  0.8046875 testCost:  0.56642854 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  624 trainCost:  0.5574737 trainAccurancy:  0.8359375 testCost:  0.6737373 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  625 trainCost:  0.6820728 trainAccurancy:  0.8125 testCost:  0.62365377 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  626 trainCost:  0.6325486 trainAccurancy:  0.8203125 testCost:  0.58200216 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  627 trainCost:  0.8634232 trainAccurancy:  0.765625 testCost:  0.6558399 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  628 trainCost:  0.66719884 trainAccurancy:  0.78125 testCost:  0.47909668 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  629 trainCost:  0.6094652 trainAccurancy:  0.8046875 testCost:  0.5783425 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  630 trainCost:  0.7049689 trainAccurancy:  0.7734375 testCost:  0.75765073 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  631 trainCost:  0.59294164 trainAccurancy:  0.84375 testCost:  0.53790474 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  632 trainCost:  0.58493453 trainAccurancy:  0.796875 testCost:  0.76767355 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  633 trainCost:  0.52068377 trainAccurancy:  0.796875 testCost:  0.55262196 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  634 trainCost:  0.625622 trainAccurancy:  0.8359375 testCost:  0.5716358 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  635 trainCost:  0.60157 trainAccurancy:  0.78125 testCost:  0.6424136 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  636 trainCost:  0.65620613 trainAccurancy:  0.8046875 testCost:  0.49840385 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  637 trainCost:  0.48927268 trainAccurancy:  0.84375 testCost:  0.49326888 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  638 trainCost:  0.64117056 trainAccurancy:  0.796875 testCost:  0.6483158 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  639 trainCost:  0.7425918 trainAccurancy:  0.765625 testCost:  0.77250683 testAccurancy:  0.75\n",
            "\n",
            "Iteration:  640 trainCost:  0.601544 trainAccurancy:  0.8359375 testCost:  0.6863589 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  641 trainCost:  0.47060776 trainAccurancy:  0.8671875 testCost:  0.6270524 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  642 trainCost:  0.6487475 trainAccurancy:  0.8125 testCost:  0.5368947 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  643 trainCost:  0.6019804 trainAccurancy:  0.828125 testCost:  0.55989856 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  644 trainCost:  0.6257963 trainAccurancy:  0.796875 testCost:  0.48879403 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  645 trainCost:  0.6953966 trainAccurancy:  0.7890625 testCost:  0.630692 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  646 trainCost:  0.74071264 trainAccurancy:  0.7890625 testCost:  0.61515963 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  647 trainCost:  0.72198284 trainAccurancy:  0.7421875 testCost:  0.6471188 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  648 trainCost:  0.7128752 trainAccurancy:  0.75 testCost:  0.71705794 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  649 trainCost:  0.44730836 trainAccurancy:  0.84375 testCost:  0.584684 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  650 trainCost:  0.4868008 trainAccurancy:  0.859375 testCost:  0.5810928 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  651 trainCost:  0.792275 trainAccurancy:  0.7421875 testCost:  0.5857934 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  652 trainCost:  0.73319983 trainAccurancy:  0.8125 testCost:  0.5171097 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  653 trainCost:  0.6461443 trainAccurancy:  0.8046875 testCost:  0.6902086 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  654 trainCost:  0.62591237 trainAccurancy:  0.8203125 testCost:  0.5986161 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  655 trainCost:  0.45394343 trainAccurancy:  0.8828125 testCost:  0.54292244 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  656 trainCost:  0.6093184 trainAccurancy:  0.8203125 testCost:  0.6073288 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  657 trainCost:  0.74934375 trainAccurancy:  0.7734375 testCost:  0.6947979 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  658 trainCost:  0.5971113 trainAccurancy:  0.8359375 testCost:  0.47531205 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  659 trainCost:  0.623647 trainAccurancy:  0.7890625 testCost:  0.704926 testAccurancy:  0.734375\n",
            "\n",
            "Iteration:  660 trainCost:  0.48621547 trainAccurancy:  0.875 testCost:  0.47542477 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  661 trainCost:  0.5864673 trainAccurancy:  0.8359375 testCost:  0.4480795 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  662 trainCost:  0.7845638 trainAccurancy:  0.7578125 testCost:  0.69533676 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  663 trainCost:  0.75148773 trainAccurancy:  0.7578125 testCost:  0.47792667 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  664 trainCost:  0.5047682 trainAccurancy:  0.8359375 testCost:  0.63523215 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  665 trainCost:  0.44353122 trainAccurancy:  0.84375 testCost:  0.6196797 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  666 trainCost:  0.7886911 trainAccurancy:  0.78125 testCost:  0.59997046 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  667 trainCost:  0.49166882 trainAccurancy:  0.84375 testCost:  0.51342076 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  668 trainCost:  0.54202724 trainAccurancy:  0.84375 testCost:  0.6478484 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  669 trainCost:  0.6116295 trainAccurancy:  0.828125 testCost:  0.5719888 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  670 trainCost:  0.5625994 trainAccurancy:  0.859375 testCost:  0.5121929 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  671 trainCost:  0.69415843 trainAccurancy:  0.7421875 testCost:  0.60542953 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  672 trainCost:  0.8053405 trainAccurancy:  0.75 testCost:  0.5793257 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  673 trainCost:  0.5237125 trainAccurancy:  0.828125 testCost:  0.54356325 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  674 trainCost:  0.5837023 trainAccurancy:  0.8203125 testCost:  0.5871972 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  675 trainCost:  0.64401823 trainAccurancy:  0.7890625 testCost:  0.6150222 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  676 trainCost:  0.59901065 trainAccurancy:  0.8515625 testCost:  0.55498505 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  677 trainCost:  0.57843286 trainAccurancy:  0.84375 testCost:  0.5854722 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  678 trainCost:  0.75684917 trainAccurancy:  0.7734375 testCost:  0.6596719 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  679 trainCost:  0.61796695 trainAccurancy:  0.796875 testCost:  0.8283052 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  680 trainCost:  0.6174398 trainAccurancy:  0.84375 testCost:  0.40099448 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  681 trainCost:  0.82597834 trainAccurancy:  0.75 testCost:  0.41903952 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  682 trainCost:  0.7787329 trainAccurancy:  0.7578125 testCost:  0.5624222 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  683 trainCost:  0.7458066 trainAccurancy:  0.8046875 testCost:  0.60285366 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  684 trainCost:  0.67983013 trainAccurancy:  0.7890625 testCost:  0.67903966 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  685 trainCost:  0.625505 trainAccurancy:  0.8359375 testCost:  0.70894194 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  686 trainCost:  0.5619776 trainAccurancy:  0.8203125 testCost:  0.51410306 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  687 trainCost:  0.7354553 trainAccurancy:  0.7890625 testCost:  0.5341914 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  688 trainCost:  0.545943 trainAccurancy:  0.8046875 testCost:  0.48783073 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  689 trainCost:  0.6244198 trainAccurancy:  0.7734375 testCost:  0.5514272 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  690 trainCost:  0.7542889 trainAccurancy:  0.78125 testCost:  0.5986334 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  691 trainCost:  0.35979876 trainAccurancy:  0.8828125 testCost:  0.56345266 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  692 trainCost:  0.5367706 trainAccurancy:  0.8125 testCost:  0.54107064 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  693 trainCost:  0.60888314 trainAccurancy:  0.8203125 testCost:  0.5662474 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  694 trainCost:  0.7151841 trainAccurancy:  0.8125 testCost:  0.6716324 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  695 trainCost:  0.77635115 trainAccurancy:  0.765625 testCost:  0.44571334 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  696 trainCost:  1.0063477 trainAccurancy:  0.703125 testCost:  0.4193573 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  697 trainCost:  0.58200043 trainAccurancy:  0.796875 testCost:  0.61213034 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  698 trainCost:  0.5753994 trainAccurancy:  0.8046875 testCost:  0.50350857 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  699 trainCost:  0.5725845 trainAccurancy:  0.7890625 testCost:  0.47597498 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  700 trainCost:  0.45146272 trainAccurancy:  0.859375 testCost:  0.56208503 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  701 trainCost:  0.60996205 trainAccurancy:  0.84375 testCost:  0.57120085 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  702 trainCost:  0.63852733 trainAccurancy:  0.8359375 testCost:  0.7295859 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  703 trainCost:  0.61922306 trainAccurancy:  0.78125 testCost:  0.4840383 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  704 trainCost:  0.5167743 trainAccurancy:  0.8359375 testCost:  0.6928004 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  705 trainCost:  0.6237217 trainAccurancy:  0.8046875 testCost:  0.45283026 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  706 trainCost:  0.44243103 trainAccurancy:  0.875 testCost:  0.50988996 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  707 trainCost:  0.6842668 trainAccurancy:  0.7734375 testCost:  0.5190767 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  708 trainCost:  0.6569421 trainAccurancy:  0.8046875 testCost:  0.46009636 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  709 trainCost:  0.57861114 trainAccurancy:  0.8203125 testCost:  0.5640174 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  710 trainCost:  0.6486621 trainAccurancy:  0.828125 testCost:  0.7409057 testAccurancy:  0.7421875\n",
            "\n",
            "Iteration:  711 trainCost:  0.5716732 trainAccurancy:  0.84375 testCost:  0.5100502 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  712 trainCost:  0.46109146 trainAccurancy:  0.8515625 testCost:  0.73841965 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  713 trainCost:  0.7307633 trainAccurancy:  0.78125 testCost:  0.54308534 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  714 trainCost:  0.3836032 trainAccurancy:  0.890625 testCost:  0.59316576 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  715 trainCost:  0.7203404 trainAccurancy:  0.8046875 testCost:  0.5507365 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  716 trainCost:  0.7751973 trainAccurancy:  0.7890625 testCost:  0.5741396 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  717 trainCost:  0.41931143 trainAccurancy:  0.875 testCost:  0.67267257 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  718 trainCost:  0.71368 trainAccurancy:  0.7734375 testCost:  0.6016205 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  719 trainCost:  0.6427382 trainAccurancy:  0.8046875 testCost:  0.5896522 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  720 trainCost:  0.6258177 trainAccurancy:  0.7734375 testCost:  0.5185637 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  721 trainCost:  0.5071951 trainAccurancy:  0.828125 testCost:  0.59594935 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  722 trainCost:  0.60539126 trainAccurancy:  0.8046875 testCost:  0.46490604 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  723 trainCost:  0.5407957 trainAccurancy:  0.8125 testCost:  0.59890974 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  724 trainCost:  0.65576386 trainAccurancy:  0.8046875 testCost:  0.37993857 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  725 trainCost:  0.51484805 trainAccurancy:  0.84375 testCost:  0.3673463 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  726 trainCost:  0.5532365 trainAccurancy:  0.84375 testCost:  0.55276704 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  727 trainCost:  0.5087805 trainAccurancy:  0.8359375 testCost:  0.45166916 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  728 trainCost:  0.68465585 trainAccurancy:  0.796875 testCost:  0.54021966 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  729 trainCost:  0.5984204 trainAccurancy:  0.7890625 testCost:  0.66164017 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  730 trainCost:  0.48605877 trainAccurancy:  0.875 testCost:  0.5238925 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  731 trainCost:  0.53443325 trainAccurancy:  0.8203125 testCost:  0.5003694 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  732 trainCost:  0.52195156 trainAccurancy:  0.8359375 testCost:  0.56069535 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  733 trainCost:  0.55606514 trainAccurancy:  0.8359375 testCost:  0.6334486 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  734 trainCost:  0.55589545 trainAccurancy:  0.84375 testCost:  0.5945126 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  735 trainCost:  0.684735 trainAccurancy:  0.84375 testCost:  0.43429816 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  736 trainCost:  0.506521 trainAccurancy:  0.8515625 testCost:  0.74096376 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  737 trainCost:  0.5049849 trainAccurancy:  0.84375 testCost:  0.50905883 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  738 trainCost:  0.4866242 trainAccurancy:  0.8359375 testCost:  0.6507609 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  739 trainCost:  0.4964719 trainAccurancy:  0.84375 testCost:  0.7006315 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  740 trainCost:  0.5436541 trainAccurancy:  0.84375 testCost:  0.58062494 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  741 trainCost:  0.57413524 trainAccurancy:  0.8203125 testCost:  0.46824384 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  742 trainCost:  0.47387034 trainAccurancy:  0.890625 testCost:  0.62526834 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  743 trainCost:  0.66635764 trainAccurancy:  0.796875 testCost:  0.56974804 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  744 trainCost:  0.5517158 trainAccurancy:  0.828125 testCost:  0.5626035 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  745 trainCost:  0.66985625 trainAccurancy:  0.765625 testCost:  0.5167459 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  746 trainCost:  0.44113314 trainAccurancy:  0.8203125 testCost:  0.5182017 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  747 trainCost:  0.636521 trainAccurancy:  0.8125 testCost:  0.57353294 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  748 trainCost:  0.5321681 trainAccurancy:  0.84375 testCost:  0.48820654 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  749 trainCost:  0.72256726 trainAccurancy:  0.7890625 testCost:  0.48486006 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  750 trainCost:  0.63723314 trainAccurancy:  0.828125 testCost:  0.45160037 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  751 trainCost:  0.6452811 trainAccurancy:  0.8125 testCost:  0.74285376 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  752 trainCost:  0.46543628 trainAccurancy:  0.875 testCost:  0.49340934 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  753 trainCost:  0.5058955 trainAccurancy:  0.8359375 testCost:  0.557697 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  754 trainCost:  0.48339117 trainAccurancy:  0.859375 testCost:  0.596123 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  755 trainCost:  0.52946186 trainAccurancy:  0.796875 testCost:  0.56954235 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  756 trainCost:  0.5210399 trainAccurancy:  0.8125 testCost:  0.5146205 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  757 trainCost:  0.64098126 trainAccurancy:  0.78125 testCost:  0.52255994 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  758 trainCost:  0.58765453 trainAccurancy:  0.8046875 testCost:  0.614444 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  759 trainCost:  0.5812783 trainAccurancy:  0.8125 testCost:  0.6458205 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  760 trainCost:  0.6794876 trainAccurancy:  0.796875 testCost:  0.5607984 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  761 trainCost:  0.6048075 trainAccurancy:  0.828125 testCost:  0.61247516 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  762 trainCost:  0.43432346 trainAccurancy:  0.828125 testCost:  0.53664696 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  763 trainCost:  0.6946338 trainAccurancy:  0.828125 testCost:  0.48125246 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  764 trainCost:  0.52635777 trainAccurancy:  0.8359375 testCost:  0.373349 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  765 trainCost:  0.6371977 trainAccurancy:  0.8125 testCost:  0.51915395 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  766 trainCost:  0.38505122 trainAccurancy:  0.890625 testCost:  0.6362332 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  767 trainCost:  0.55857855 trainAccurancy:  0.7890625 testCost:  0.39498618 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  768 trainCost:  0.4799838 trainAccurancy:  0.8359375 testCost:  0.3543745 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  769 trainCost:  0.8032742 trainAccurancy:  0.78125 testCost:  0.4263645 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  770 trainCost:  0.5875697 trainAccurancy:  0.8203125 testCost:  0.6148475 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  771 trainCost:  0.38363785 trainAccurancy:  0.890625 testCost:  0.63910335 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  772 trainCost:  0.41024658 trainAccurancy:  0.890625 testCost:  0.6542792 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  773 trainCost:  0.7221117 trainAccurancy:  0.7890625 testCost:  0.583273 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  774 trainCost:  0.6983029 trainAccurancy:  0.7734375 testCost:  0.47634482 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  775 trainCost:  0.48831767 trainAccurancy:  0.828125 testCost:  0.9286082 testAccurancy:  0.7265625\n",
            "\n",
            "Iteration:  776 trainCost:  0.49470168 trainAccurancy:  0.8203125 testCost:  0.4402203 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  777 trainCost:  0.5557661 trainAccurancy:  0.8125 testCost:  0.48891985 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  778 trainCost:  0.64270407 trainAccurancy:  0.765625 testCost:  0.4427871 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  779 trainCost:  0.6859566 trainAccurancy:  0.7734375 testCost:  0.378218 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  780 trainCost:  0.466555 trainAccurancy:  0.859375 testCost:  0.43380475 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  781 trainCost:  0.6387912 trainAccurancy:  0.828125 testCost:  0.6387704 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  782 trainCost:  0.52227145 trainAccurancy:  0.84375 testCost:  0.5093451 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  783 trainCost:  0.6663153 trainAccurancy:  0.796875 testCost:  0.39360064 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  784 trainCost:  0.57848525 trainAccurancy:  0.8359375 testCost:  0.63428974 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  785 trainCost:  0.59537387 trainAccurancy:  0.84375 testCost:  0.56901526 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  786 trainCost:  0.53251374 trainAccurancy:  0.8359375 testCost:  0.4776734 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  787 trainCost:  0.5129403 trainAccurancy:  0.8203125 testCost:  0.45163327 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  788 trainCost:  0.51386774 trainAccurancy:  0.84375 testCost:  0.65465236 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  789 trainCost:  0.5391984 trainAccurancy:  0.828125 testCost:  0.38397473 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  790 trainCost:  0.66466004 trainAccurancy:  0.78125 testCost:  0.5664729 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  791 trainCost:  0.6181458 trainAccurancy:  0.8203125 testCost:  0.6350713 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  792 trainCost:  0.45682466 trainAccurancy:  0.8671875 testCost:  0.67474264 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  793 trainCost:  0.6815175 trainAccurancy:  0.84375 testCost:  0.5454564 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  794 trainCost:  0.5738317 trainAccurancy:  0.8125 testCost:  0.5622272 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  795 trainCost:  0.6468506 trainAccurancy:  0.7890625 testCost:  0.55300397 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  796 trainCost:  0.5426166 trainAccurancy:  0.8515625 testCost:  0.62418354 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  797 trainCost:  0.39986452 trainAccurancy:  0.8671875 testCost:  0.4694247 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  798 trainCost:  0.58011544 trainAccurancy:  0.8359375 testCost:  0.41769958 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  799 trainCost:  0.5528691 trainAccurancy:  0.8515625 testCost:  0.57661384 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  800 trainCost:  0.51841366 trainAccurancy:  0.84375 testCost:  0.48825186 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  801 trainCost:  0.43737292 trainAccurancy:  0.8515625 testCost:  0.5101623 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  802 trainCost:  0.64267504 trainAccurancy:  0.78125 testCost:  0.45810533 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  803 trainCost:  0.55724335 trainAccurancy:  0.8359375 testCost:  0.5334904 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  804 trainCost:  0.616243 trainAccurancy:  0.8203125 testCost:  0.5850183 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  805 trainCost:  0.40495116 trainAccurancy:  0.890625 testCost:  0.4174105 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  806 trainCost:  0.44818407 trainAccurancy:  0.859375 testCost:  0.55459034 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  807 trainCost:  0.60843885 trainAccurancy:  0.7890625 testCost:  0.5868863 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  808 trainCost:  0.7595531 trainAccurancy:  0.8125 testCost:  0.6633357 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  809 trainCost:  0.52131104 trainAccurancy:  0.859375 testCost:  0.38922393 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  810 trainCost:  0.7824959 trainAccurancy:  0.78125 testCost:  0.5496589 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  811 trainCost:  0.60656536 trainAccurancy:  0.828125 testCost:  0.7098684 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  812 trainCost:  0.35661846 trainAccurancy:  0.8984375 testCost:  0.4084177 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  813 trainCost:  0.55679435 trainAccurancy:  0.84375 testCost:  0.5660792 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  814 trainCost:  0.495084 trainAccurancy:  0.8125 testCost:  0.51251596 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  815 trainCost:  0.4861913 trainAccurancy:  0.828125 testCost:  0.6368362 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  816 trainCost:  0.40749326 trainAccurancy:  0.875 testCost:  0.5748853 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  817 trainCost:  0.60495496 trainAccurancy:  0.796875 testCost:  0.5339592 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  818 trainCost:  0.60248154 trainAccurancy:  0.8125 testCost:  0.39586776 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  819 trainCost:  0.47179753 trainAccurancy:  0.8359375 testCost:  0.5621947 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  820 trainCost:  0.5905502 trainAccurancy:  0.828125 testCost:  0.4761203 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  821 trainCost:  0.5271605 trainAccurancy:  0.828125 testCost:  0.6832653 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  822 trainCost:  0.53683364 trainAccurancy:  0.8046875 testCost:  0.3364973 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  823 trainCost:  0.5957158 trainAccurancy:  0.8359375 testCost:  0.43764615 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  824 trainCost:  0.49045962 trainAccurancy:  0.828125 testCost:  0.5297177 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  825 trainCost:  0.5276041 trainAccurancy:  0.8203125 testCost:  0.45153263 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  826 trainCost:  0.5397258 trainAccurancy:  0.8359375 testCost:  0.54414415 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  827 trainCost:  0.47207674 trainAccurancy:  0.796875 testCost:  0.46544164 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  828 trainCost:  0.61337006 trainAccurancy:  0.8125 testCost:  0.508278 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  829 trainCost:  0.60460556 trainAccurancy:  0.7890625 testCost:  0.46014178 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  830 trainCost:  0.4259136 trainAccurancy:  0.8671875 testCost:  0.5987459 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  831 trainCost:  0.5525291 trainAccurancy:  0.84375 testCost:  0.4985414 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  832 trainCost:  0.59010506 trainAccurancy:  0.8203125 testCost:  0.5743406 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  833 trainCost:  0.3573622 trainAccurancy:  0.9140625 testCost:  0.58013344 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  834 trainCost:  0.5806754 trainAccurancy:  0.859375 testCost:  0.6165115 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  835 trainCost:  0.630341 trainAccurancy:  0.796875 testCost:  0.40795034 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  836 trainCost:  0.480497 trainAccurancy:  0.828125 testCost:  0.3736623 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  837 trainCost:  0.49965632 trainAccurancy:  0.859375 testCost:  0.65003127 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  838 trainCost:  0.5613172 trainAccurancy:  0.8125 testCost:  0.51670367 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  839 trainCost:  0.49735516 trainAccurancy:  0.8515625 testCost:  0.4012025 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  840 trainCost:  0.47609794 trainAccurancy:  0.8515625 testCost:  0.6053122 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  841 trainCost:  0.38606358 trainAccurancy:  0.90625 testCost:  0.53808993 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  842 trainCost:  0.546885 trainAccurancy:  0.8515625 testCost:  0.46180463 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  843 trainCost:  0.44299868 trainAccurancy:  0.84375 testCost:  0.5698448 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  844 trainCost:  0.6384758 trainAccurancy:  0.8125 testCost:  0.6639731 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  845 trainCost:  0.5152041 trainAccurancy:  0.8203125 testCost:  0.55942726 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  846 trainCost:  0.57824284 trainAccurancy:  0.8203125 testCost:  0.34162265 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  847 trainCost:  0.6081135 trainAccurancy:  0.8359375 testCost:  0.46417373 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  848 trainCost:  0.40870917 trainAccurancy:  0.8671875 testCost:  0.5597099 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  849 trainCost:  0.48566067 trainAccurancy:  0.84375 testCost:  0.668222 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  850 trainCost:  0.48683268 trainAccurancy:  0.84375 testCost:  0.37619042 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  851 trainCost:  0.60641694 trainAccurancy:  0.8515625 testCost:  0.41312557 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  852 trainCost:  0.51873887 trainAccurancy:  0.84375 testCost:  0.3442168 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  853 trainCost:  0.4341496 trainAccurancy:  0.84375 testCost:  0.56867313 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  854 trainCost:  0.681933 trainAccurancy:  0.828125 testCost:  0.5013714 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  855 trainCost:  0.49140793 trainAccurancy:  0.8671875 testCost:  0.36972004 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  856 trainCost:  0.58650565 trainAccurancy:  0.8046875 testCost:  0.41583484 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  857 trainCost:  0.41674882 trainAccurancy:  0.8671875 testCost:  0.5022224 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  858 trainCost:  0.5925706 trainAccurancy:  0.8125 testCost:  0.455997 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  859 trainCost:  0.7077919 trainAccurancy:  0.7890625 testCost:  0.40736818 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  860 trainCost:  0.50498754 trainAccurancy:  0.84375 testCost:  0.5484711 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  861 trainCost:  0.6359611 trainAccurancy:  0.828125 testCost:  0.5163573 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  862 trainCost:  0.5835987 trainAccurancy:  0.8046875 testCost:  0.45136452 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  863 trainCost:  0.4625492 trainAccurancy:  0.8515625 testCost:  0.5013514 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  864 trainCost:  0.47403824 trainAccurancy:  0.859375 testCost:  0.45083845 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  865 trainCost:  0.5038565 trainAccurancy:  0.8046875 testCost:  0.50431955 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  866 trainCost:  0.60208 trainAccurancy:  0.828125 testCost:  0.514307 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  867 trainCost:  0.41658407 trainAccurancy:  0.875 testCost:  0.5003582 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  868 trainCost:  0.4722193 trainAccurancy:  0.8671875 testCost:  0.6359901 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  869 trainCost:  0.34114677 trainAccurancy:  0.8828125 testCost:  0.4562297 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  870 trainCost:  0.5392613 trainAccurancy:  0.8515625 testCost:  0.4726048 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  871 trainCost:  0.33798185 trainAccurancy:  0.90625 testCost:  0.53431046 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  872 trainCost:  0.52604675 trainAccurancy:  0.8203125 testCost:  0.43809396 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  873 trainCost:  0.7317457 trainAccurancy:  0.7578125 testCost:  0.43919793 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  874 trainCost:  0.43845585 trainAccurancy:  0.8671875 testCost:  0.52619153 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  875 trainCost:  0.50182873 trainAccurancy:  0.828125 testCost:  0.53858346 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  876 trainCost:  0.5859853 trainAccurancy:  0.8203125 testCost:  0.60253894 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  877 trainCost:  0.42610386 trainAccurancy:  0.875 testCost:  0.631598 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  878 trainCost:  0.505116 trainAccurancy:  0.8515625 testCost:  0.42616218 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  879 trainCost:  0.43935657 trainAccurancy:  0.859375 testCost:  0.34309295 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  880 trainCost:  0.45183858 trainAccurancy:  0.875 testCost:  0.46449465 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  881 trainCost:  0.47124535 trainAccurancy:  0.8359375 testCost:  0.54938823 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  882 trainCost:  0.62825215 trainAccurancy:  0.8359375 testCost:  0.4664441 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  883 trainCost:  0.6519906 trainAccurancy:  0.8125 testCost:  0.6020183 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  884 trainCost:  0.49443126 trainAccurancy:  0.859375 testCost:  0.78089064 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  885 trainCost:  0.45167664 trainAccurancy:  0.859375 testCost:  0.41796553 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  886 trainCost:  0.4153437 trainAccurancy:  0.8515625 testCost:  0.65760005 testAccurancy:  0.7578125\n",
            "\n",
            "Iteration:  887 trainCost:  0.58965147 trainAccurancy:  0.8203125 testCost:  0.45049414 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  888 trainCost:  0.5044478 trainAccurancy:  0.8125 testCost:  0.3284644 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  889 trainCost:  0.70412004 trainAccurancy:  0.8203125 testCost:  0.8374588 testAccurancy:  0.765625\n",
            "\n",
            "Iteration:  890 trainCost:  0.38690296 trainAccurancy:  0.8984375 testCost:  0.5259472 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  891 trainCost:  0.41589832 trainAccurancy:  0.890625 testCost:  0.4097552 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  892 trainCost:  0.5757319 trainAccurancy:  0.8359375 testCost:  0.5149603 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  893 trainCost:  0.37417674 trainAccurancy:  0.84375 testCost:  0.48663297 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  894 trainCost:  0.60768366 trainAccurancy:  0.859375 testCost:  0.36365616 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  895 trainCost:  0.4666857 trainAccurancy:  0.8515625 testCost:  0.51085013 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  896 trainCost:  0.52721584 trainAccurancy:  0.8125 testCost:  0.509661 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  897 trainCost:  0.560191 trainAccurancy:  0.8359375 testCost:  0.29237723 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  898 trainCost:  0.44627005 trainAccurancy:  0.875 testCost:  0.5980289 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  899 trainCost:  0.5311911 trainAccurancy:  0.84375 testCost:  0.67149967 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  900 trainCost:  0.50533044 trainAccurancy:  0.8125 testCost:  0.5817737 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  901 trainCost:  0.47357988 trainAccurancy:  0.875 testCost:  0.48941404 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  902 trainCost:  0.48970062 trainAccurancy:  0.84375 testCost:  0.43025964 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  903 trainCost:  0.37564504 trainAccurancy:  0.8828125 testCost:  0.5745072 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  904 trainCost:  0.46714872 trainAccurancy:  0.8203125 testCost:  0.57244146 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  905 trainCost:  0.4840233 trainAccurancy:  0.875 testCost:  0.45839965 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  906 trainCost:  0.69517475 trainAccurancy:  0.75 testCost:  0.4676051 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  907 trainCost:  0.3999509 trainAccurancy:  0.8515625 testCost:  0.3551554 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  908 trainCost:  0.36027303 trainAccurancy:  0.8984375 testCost:  0.39798516 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  909 trainCost:  0.48435804 trainAccurancy:  0.84375 testCost:  0.41460168 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  910 trainCost:  0.46098635 trainAccurancy:  0.859375 testCost:  0.4923539 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  911 trainCost:  0.6032526 trainAccurancy:  0.828125 testCost:  0.45920223 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  912 trainCost:  0.4162513 trainAccurancy:  0.8671875 testCost:  0.53875315 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  913 trainCost:  0.51098675 trainAccurancy:  0.859375 testCost:  0.3129518 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  914 trainCost:  0.7165035 trainAccurancy:  0.7734375 testCost:  0.54833364 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  915 trainCost:  0.6181365 trainAccurancy:  0.78125 testCost:  0.27529174 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  916 trainCost:  0.7553812 trainAccurancy:  0.8046875 testCost:  0.49209026 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  917 trainCost:  0.48399204 trainAccurancy:  0.84375 testCost:  0.69489807 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  918 trainCost:  0.4132794 trainAccurancy:  0.84375 testCost:  0.5494982 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  919 trainCost:  0.23191032 trainAccurancy:  0.9375 testCost:  0.328636 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  920 trainCost:  0.5940294 trainAccurancy:  0.78125 testCost:  0.44625983 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  921 trainCost:  0.5037924 trainAccurancy:  0.890625 testCost:  0.48010847 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  922 trainCost:  0.5031842 trainAccurancy:  0.8125 testCost:  0.6541276 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  923 trainCost:  0.5619042 trainAccurancy:  0.8125 testCost:  0.22479953 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  924 trainCost:  0.3641733 trainAccurancy:  0.90625 testCost:  0.5032536 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  925 trainCost:  0.42507324 trainAccurancy:  0.875 testCost:  0.43377936 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  926 trainCost:  0.47685203 trainAccurancy:  0.8359375 testCost:  0.51114506 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  927 trainCost:  0.6305651 trainAccurancy:  0.7890625 testCost:  0.47674057 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  928 trainCost:  0.6236628 trainAccurancy:  0.8125 testCost:  0.63805 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  929 trainCost:  0.50061727 trainAccurancy:  0.8515625 testCost:  0.5100644 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  930 trainCost:  0.56478417 trainAccurancy:  0.8203125 testCost:  0.56269175 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  931 trainCost:  0.6328223 trainAccurancy:  0.8203125 testCost:  0.3560501 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  932 trainCost:  0.5361794 trainAccurancy:  0.859375 testCost:  0.5475906 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  933 trainCost:  0.5575613 trainAccurancy:  0.84375 testCost:  0.38244405 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  934 trainCost:  0.43666032 trainAccurancy:  0.84375 testCost:  0.52418655 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  935 trainCost:  0.5502435 trainAccurancy:  0.8203125 testCost:  0.447618 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  936 trainCost:  0.58569634 trainAccurancy:  0.78125 testCost:  0.43319473 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  937 trainCost:  0.43818063 trainAccurancy:  0.90625 testCost:  0.44720593 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  938 trainCost:  0.48952883 trainAccurancy:  0.8203125 testCost:  0.56286466 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  939 trainCost:  0.48791736 trainAccurancy:  0.8515625 testCost:  0.5321959 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  940 trainCost:  0.5201994 trainAccurancy:  0.8359375 testCost:  0.290697 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  941 trainCost:  0.52598304 trainAccurancy:  0.796875 testCost:  0.4838883 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  942 trainCost:  0.4539392 trainAccurancy:  0.8828125 testCost:  0.3224064 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  943 trainCost:  0.55123866 trainAccurancy:  0.8125 testCost:  0.30266368 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  944 trainCost:  0.557665 trainAccurancy:  0.84375 testCost:  0.4413681 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  945 trainCost:  0.38659346 trainAccurancy:  0.875 testCost:  0.562027 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  946 trainCost:  0.44903052 trainAccurancy:  0.8984375 testCost:  0.64131004 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  947 trainCost:  0.44228005 trainAccurancy:  0.890625 testCost:  0.4317678 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  948 trainCost:  0.60133123 trainAccurancy:  0.8203125 testCost:  0.45203683 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  949 trainCost:  0.47948802 trainAccurancy:  0.84375 testCost:  0.4249282 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  950 trainCost:  0.6194148 trainAccurancy:  0.796875 testCost:  0.38989556 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  951 trainCost:  0.50971603 trainAccurancy:  0.8046875 testCost:  0.47289318 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  952 trainCost:  0.4717903 trainAccurancy:  0.84375 testCost:  0.40822294 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  953 trainCost:  0.35059777 trainAccurancy:  0.875 testCost:  0.40736747 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  954 trainCost:  0.32399336 trainAccurancy:  0.8671875 testCost:  0.4839453 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  955 trainCost:  0.38019782 trainAccurancy:  0.859375 testCost:  0.6925361 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  956 trainCost:  0.43559527 trainAccurancy:  0.875 testCost:  0.36563143 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  957 trainCost:  0.5350881 trainAccurancy:  0.8359375 testCost:  0.45109862 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  958 trainCost:  0.3929971 trainAccurancy:  0.890625 testCost:  0.555195 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  959 trainCost:  0.6230318 trainAccurancy:  0.828125 testCost:  0.5846596 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  960 trainCost:  0.47813618 trainAccurancy:  0.859375 testCost:  0.6672262 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  961 trainCost:  0.48118657 trainAccurancy:  0.8125 testCost:  0.5495391 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  962 trainCost:  0.63102007 trainAccurancy:  0.8203125 testCost:  0.42004225 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  963 trainCost:  0.458513 trainAccurancy:  0.8671875 testCost:  0.46204787 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  964 trainCost:  0.5512731 trainAccurancy:  0.828125 testCost:  0.4489645 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  965 trainCost:  0.484429 trainAccurancy:  0.8203125 testCost:  0.2976628 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  966 trainCost:  0.5671808 trainAccurancy:  0.828125 testCost:  0.4278592 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  967 trainCost:  0.5129724 trainAccurancy:  0.8125 testCost:  0.40879124 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  968 trainCost:  0.53972197 trainAccurancy:  0.84375 testCost:  0.33319888 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  969 trainCost:  0.5664514 trainAccurancy:  0.828125 testCost:  0.63281614 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  970 trainCost:  0.41188878 trainAccurancy:  0.859375 testCost:  0.5359904 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  971 trainCost:  0.4557054 trainAccurancy:  0.8359375 testCost:  0.37635934 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  972 trainCost:  0.48325384 trainAccurancy:  0.859375 testCost:  0.62096816 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  973 trainCost:  0.604205 trainAccurancy:  0.8046875 testCost:  0.43513513 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  974 trainCost:  0.53356653 trainAccurancy:  0.84375 testCost:  0.34249508 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  975 trainCost:  0.4849047 trainAccurancy:  0.8203125 testCost:  0.48979253 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  976 trainCost:  0.42248657 trainAccurancy:  0.8671875 testCost:  0.6139783 testAccurancy:  0.78125\n",
            "\n",
            "Iteration:  977 trainCost:  0.4521661 trainAccurancy:  0.859375 testCost:  0.7463063 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  978 trainCost:  0.56989014 trainAccurancy:  0.84375 testCost:  0.3916732 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  979 trainCost:  0.51271874 trainAccurancy:  0.875 testCost:  0.33899146 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  980 trainCost:  0.44682908 trainAccurancy:  0.875 testCost:  0.50502026 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  981 trainCost:  0.3540153 trainAccurancy:  0.8671875 testCost:  0.40428355 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  982 trainCost:  0.6360953 trainAccurancy:  0.8359375 testCost:  0.5343157 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  983 trainCost:  0.48726562 trainAccurancy:  0.859375 testCost:  0.41567627 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  984 trainCost:  0.4365575 trainAccurancy:  0.859375 testCost:  0.41756356 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  985 trainCost:  0.48048687 trainAccurancy:  0.8828125 testCost:  0.6387731 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  986 trainCost:  0.513261 trainAccurancy:  0.8515625 testCost:  0.43428063 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  987 trainCost:  0.54180646 trainAccurancy:  0.84375 testCost:  0.56067485 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  988 trainCost:  0.37073356 trainAccurancy:  0.859375 testCost:  0.3723837 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  989 trainCost:  0.43428785 trainAccurancy:  0.8515625 testCost:  0.4157084 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  990 trainCost:  0.49496838 trainAccurancy:  0.859375 testCost:  0.60743237 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  991 trainCost:  0.37731904 trainAccurancy:  0.8671875 testCost:  0.54328424 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  992 trainCost:  0.5939686 trainAccurancy:  0.8125 testCost:  0.4852466 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  993 trainCost:  0.39491123 trainAccurancy:  0.890625 testCost:  0.40881383 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  994 trainCost:  0.38157183 trainAccurancy:  0.8828125 testCost:  0.45262623 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  995 trainCost:  0.377124 trainAccurancy:  0.8828125 testCost:  0.5754212 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  996 trainCost:  0.53886867 trainAccurancy:  0.84375 testCost:  0.4926972 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  997 trainCost:  0.696806 trainAccurancy:  0.828125 testCost:  0.55753195 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  998 trainCost:  0.3933593 trainAccurancy:  0.8984375 testCost:  0.3922273 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  999 trainCost:  0.3236633 trainAccurancy:  0.890625 testCost:  0.3341396 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1000 trainCost:  0.41677853 trainAccurancy:  0.8984375 testCost:  0.34693438 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1001 trainCost:  0.26711267 trainAccurancy:  0.8984375 testCost:  0.5951612 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1002 trainCost:  0.42145103 trainAccurancy:  0.875 testCost:  0.41068423 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1003 trainCost:  0.34019417 trainAccurancy:  0.90625 testCost:  0.49323583 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1004 trainCost:  0.5756254 trainAccurancy:  0.8203125 testCost:  0.3576694 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1005 trainCost:  0.5225838 trainAccurancy:  0.8359375 testCost:  0.5314736 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1006 trainCost:  0.40887982 trainAccurancy:  0.8984375 testCost:  0.5770235 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1007 trainCost:  0.326567 trainAccurancy:  0.859375 testCost:  0.4364069 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1008 trainCost:  0.36921677 trainAccurancy:  0.890625 testCost:  0.40516347 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1009 trainCost:  0.34863862 trainAccurancy:  0.84375 testCost:  0.39153576 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1010 trainCost:  0.5054853 trainAccurancy:  0.859375 testCost:  0.5795163 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1011 trainCost:  0.59176433 trainAccurancy:  0.828125 testCost:  0.42959154 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1012 trainCost:  0.69658124 trainAccurancy:  0.8046875 testCost:  0.4793063 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1013 trainCost:  0.4298705 trainAccurancy:  0.890625 testCost:  0.3090827 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1014 trainCost:  0.41962817 trainAccurancy:  0.8984375 testCost:  0.550436 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1015 trainCost:  0.385785 trainAccurancy:  0.875 testCost:  0.5532252 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1016 trainCost:  0.50599325 trainAccurancy:  0.8125 testCost:  0.5219117 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1017 trainCost:  0.41501933 trainAccurancy:  0.8671875 testCost:  0.61181206 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  1018 trainCost:  0.593254 trainAccurancy:  0.8203125 testCost:  0.44218215 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1019 trainCost:  0.5401112 trainAccurancy:  0.84375 testCost:  0.46009186 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1020 trainCost:  0.3733077 trainAccurancy:  0.859375 testCost:  0.40170985 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1021 trainCost:  0.48511368 trainAccurancy:  0.859375 testCost:  0.6578269 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1022 trainCost:  0.59464014 trainAccurancy:  0.8203125 testCost:  0.40443522 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1023 trainCost:  0.5431489 trainAccurancy:  0.8515625 testCost:  0.30720833 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1024 trainCost:  0.5705498 trainAccurancy:  0.8046875 testCost:  0.36493638 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1025 trainCost:  0.49830833 trainAccurancy:  0.8515625 testCost:  0.4755595 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1026 trainCost:  0.5862883 trainAccurancy:  0.859375 testCost:  0.6162192 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1027 trainCost:  0.51212436 trainAccurancy:  0.8125 testCost:  0.49199095 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1028 trainCost:  0.4896788 trainAccurancy:  0.8359375 testCost:  0.7569774 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  1029 trainCost:  0.48260075 trainAccurancy:  0.859375 testCost:  0.34332132 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1030 trainCost:  0.5114439 trainAccurancy:  0.8359375 testCost:  0.5491781 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1031 trainCost:  0.46349007 trainAccurancy:  0.890625 testCost:  0.50586855 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1032 trainCost:  0.63026613 trainAccurancy:  0.8203125 testCost:  0.39648342 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1033 trainCost:  0.48046196 trainAccurancy:  0.84375 testCost:  0.4048715 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1034 trainCost:  0.59641695 trainAccurancy:  0.875 testCost:  0.4833824 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1035 trainCost:  0.35996085 trainAccurancy:  0.8828125 testCost:  0.38756552 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1036 trainCost:  0.45563966 trainAccurancy:  0.8671875 testCost:  0.44557345 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1037 trainCost:  0.4681961 trainAccurancy:  0.859375 testCost:  0.4251294 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1038 trainCost:  0.42405176 trainAccurancy:  0.8671875 testCost:  0.607426 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1039 trainCost:  0.31839043 trainAccurancy:  0.9296875 testCost:  0.485045 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1040 trainCost:  0.41895583 trainAccurancy:  0.8671875 testCost:  0.5195614 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1041 trainCost:  0.488652 trainAccurancy:  0.8359375 testCost:  0.5002293 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1042 trainCost:  0.39598837 trainAccurancy:  0.8828125 testCost:  0.5250201 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1043 trainCost:  0.42439103 trainAccurancy:  0.859375 testCost:  0.41410097 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1044 trainCost:  0.4265899 trainAccurancy:  0.875 testCost:  0.33782893 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1045 trainCost:  0.4342665 trainAccurancy:  0.890625 testCost:  0.37317157 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1046 trainCost:  0.537939 trainAccurancy:  0.8515625 testCost:  0.5848807 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1047 trainCost:  0.45963067 trainAccurancy:  0.84375 testCost:  0.40484822 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1048 trainCost:  0.5735018 trainAccurancy:  0.8359375 testCost:  0.3550158 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1049 trainCost:  0.34867644 trainAccurancy:  0.890625 testCost:  0.5328555 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1050 trainCost:  0.6088288 trainAccurancy:  0.8359375 testCost:  0.44708276 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1051 trainCost:  0.3846307 trainAccurancy:  0.84375 testCost:  0.4190107 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1052 trainCost:  0.50505304 trainAccurancy:  0.859375 testCost:  0.51609254 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1053 trainCost:  0.37738058 trainAccurancy:  0.8984375 testCost:  0.40874374 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1054 trainCost:  0.49897742 trainAccurancy:  0.859375 testCost:  0.42679825 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1055 trainCost:  0.45298648 trainAccurancy:  0.84375 testCost:  0.45112494 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1056 trainCost:  0.5060471 trainAccurancy:  0.828125 testCost:  0.63010544 testAccurancy:  0.7890625\n",
            "\n",
            "Iteration:  1057 trainCost:  0.51518613 trainAccurancy:  0.8515625 testCost:  0.53195804 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1058 trainCost:  0.42310405 trainAccurancy:  0.828125 testCost:  0.34770977 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1059 trainCost:  0.53412116 trainAccurancy:  0.8046875 testCost:  0.42907944 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1060 trainCost:  0.49083865 trainAccurancy:  0.8671875 testCost:  0.2714841 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1061 trainCost:  0.7047537 trainAccurancy:  0.8125 testCost:  0.43428117 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1062 trainCost:  0.30295813 trainAccurancy:  0.8984375 testCost:  0.42699796 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1063 trainCost:  0.28661886 trainAccurancy:  0.921875 testCost:  0.50483495 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1064 trainCost:  0.41873306 trainAccurancy:  0.8828125 testCost:  0.3963307 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1065 trainCost:  0.4895244 trainAccurancy:  0.84375 testCost:  0.5441154 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1066 trainCost:  0.44045973 trainAccurancy:  0.8515625 testCost:  0.37648427 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1067 trainCost:  0.37839806 trainAccurancy:  0.875 testCost:  0.5383209 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1068 trainCost:  0.38630182 trainAccurancy:  0.875 testCost:  0.5042666 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1069 trainCost:  0.48973912 trainAccurancy:  0.8203125 testCost:  0.42947325 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1070 trainCost:  0.40222722 trainAccurancy:  0.859375 testCost:  0.36903906 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1071 trainCost:  0.48304808 trainAccurancy:  0.8203125 testCost:  0.3241314 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1072 trainCost:  0.35591474 trainAccurancy:  0.890625 testCost:  0.5924583 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1073 trainCost:  0.48022538 trainAccurancy:  0.859375 testCost:  0.41588104 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1074 trainCost:  0.6322186 trainAccurancy:  0.8125 testCost:  0.35363704 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1075 trainCost:  0.3453471 trainAccurancy:  0.875 testCost:  0.41198978 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1076 trainCost:  0.3684214 trainAccurancy:  0.8828125 testCost:  0.4554807 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1077 trainCost:  0.3344551 trainAccurancy:  0.90625 testCost:  0.40868744 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1078 trainCost:  0.5778142 trainAccurancy:  0.796875 testCost:  0.5085348 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1079 trainCost:  0.33958206 trainAccurancy:  0.8984375 testCost:  0.31842053 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1080 trainCost:  0.59605217 trainAccurancy:  0.8203125 testCost:  0.46483535 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1081 trainCost:  0.41401845 trainAccurancy:  0.8984375 testCost:  0.40954646 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1082 trainCost:  0.35389373 trainAccurancy:  0.8828125 testCost:  0.44240624 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1083 trainCost:  0.46743777 trainAccurancy:  0.859375 testCost:  0.33109263 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1084 trainCost:  0.45132613 trainAccurancy:  0.8515625 testCost:  0.33700556 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1085 trainCost:  0.6955971 trainAccurancy:  0.7890625 testCost:  0.5294897 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1086 trainCost:  0.36721927 trainAccurancy:  0.90625 testCost:  0.33951277 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1087 trainCost:  0.49060643 trainAccurancy:  0.8671875 testCost:  0.44902912 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1088 trainCost:  0.5993713 trainAccurancy:  0.8046875 testCost:  0.37573743 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1089 trainCost:  0.5109904 trainAccurancy:  0.8359375 testCost:  0.35674778 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1090 trainCost:  0.3859133 trainAccurancy:  0.859375 testCost:  0.41664308 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1091 trainCost:  0.4417845 trainAccurancy:  0.8515625 testCost:  0.45222908 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1092 trainCost:  0.43317395 trainAccurancy:  0.9140625 testCost:  0.44622505 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1093 trainCost:  0.3692376 trainAccurancy:  0.8671875 testCost:  0.49288732 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1094 trainCost:  0.49984697 trainAccurancy:  0.8359375 testCost:  0.5088665 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1095 trainCost:  0.3857359 trainAccurancy:  0.8671875 testCost:  0.41615665 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1096 trainCost:  0.45686772 trainAccurancy:  0.859375 testCost:  0.39665532 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1097 trainCost:  0.40811968 trainAccurancy:  0.859375 testCost:  0.21304423 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1098 trainCost:  0.47086623 trainAccurancy:  0.859375 testCost:  0.5316535 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1099 trainCost:  0.4953055 trainAccurancy:  0.8359375 testCost:  0.44566825 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1100 trainCost:  0.44628933 trainAccurancy:  0.8984375 testCost:  0.45956773 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1101 trainCost:  0.42512423 trainAccurancy:  0.8515625 testCost:  0.26979893 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1102 trainCost:  0.47050613 trainAccurancy:  0.8359375 testCost:  0.2965566 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1103 trainCost:  0.40677136 trainAccurancy:  0.890625 testCost:  0.42666554 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1104 trainCost:  0.4232237 trainAccurancy:  0.84375 testCost:  0.43837783 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1105 trainCost:  0.48628008 trainAccurancy:  0.8671875 testCost:  0.6197285 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1106 trainCost:  0.5306517 trainAccurancy:  0.828125 testCost:  0.3880822 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1107 trainCost:  0.34746805 trainAccurancy:  0.859375 testCost:  0.5045117 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1108 trainCost:  0.5840671 trainAccurancy:  0.796875 testCost:  0.38029534 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1109 trainCost:  0.53537446 trainAccurancy:  0.828125 testCost:  0.36113155 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1110 trainCost:  0.4545241 trainAccurancy:  0.8671875 testCost:  0.44121867 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1111 trainCost:  0.5562351 trainAccurancy:  0.8359375 testCost:  0.41037893 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1112 trainCost:  0.37364513 trainAccurancy:  0.9140625 testCost:  0.4043495 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1113 trainCost:  0.39860073 trainAccurancy:  0.859375 testCost:  0.45339602 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1114 trainCost:  0.5045786 trainAccurancy:  0.8515625 testCost:  0.45523924 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1115 trainCost:  0.39561287 trainAccurancy:  0.8515625 testCost:  0.39131224 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1116 trainCost:  0.5145753 trainAccurancy:  0.84375 testCost:  0.40946305 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1117 trainCost:  0.39937612 trainAccurancy:  0.8984375 testCost:  0.37733635 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1118 trainCost:  0.43773663 trainAccurancy:  0.8671875 testCost:  0.38824594 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1119 trainCost:  0.45678633 trainAccurancy:  0.8515625 testCost:  0.4889197 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1120 trainCost:  0.29144928 trainAccurancy:  0.8828125 testCost:  0.5910324 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1121 trainCost:  0.45685673 trainAccurancy:  0.8515625 testCost:  0.47776365 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1122 trainCost:  0.4912225 trainAccurancy:  0.859375 testCost:  0.40395153 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1123 trainCost:  0.54224133 trainAccurancy:  0.828125 testCost:  0.54383534 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1124 trainCost:  0.5503373 trainAccurancy:  0.8203125 testCost:  0.56262934 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1125 trainCost:  0.40776712 trainAccurancy:  0.8828125 testCost:  0.5419303 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1126 trainCost:  0.5308553 trainAccurancy:  0.8515625 testCost:  0.6738316 testAccurancy:  0.7734375\n",
            "\n",
            "Iteration:  1127 trainCost:  0.4497053 trainAccurancy:  0.84375 testCost:  0.52769196 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1128 trainCost:  0.4836165 trainAccurancy:  0.875 testCost:  0.41937172 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1129 trainCost:  0.44060022 trainAccurancy:  0.875 testCost:  0.35478288 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1130 trainCost:  0.41015145 trainAccurancy:  0.8828125 testCost:  0.41362268 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1131 trainCost:  0.4904822 trainAccurancy:  0.875 testCost:  0.39265 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1132 trainCost:  0.45577905 trainAccurancy:  0.8671875 testCost:  0.4262957 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1133 trainCost:  0.27739507 trainAccurancy:  0.8984375 testCost:  0.4155771 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1134 trainCost:  0.4408316 trainAccurancy:  0.8515625 testCost:  0.2635772 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1135 trainCost:  0.44586176 trainAccurancy:  0.859375 testCost:  0.44956428 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1136 trainCost:  0.3533671 trainAccurancy:  0.8984375 testCost:  0.3872757 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1137 trainCost:  0.40809566 trainAccurancy:  0.875 testCost:  0.5578755 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1138 trainCost:  0.35332894 trainAccurancy:  0.921875 testCost:  0.5479198 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1139 trainCost:  0.43779427 trainAccurancy:  0.8671875 testCost:  0.4261197 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1140 trainCost:  0.48670328 trainAccurancy:  0.8671875 testCost:  0.5687243 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1141 trainCost:  0.40412104 trainAccurancy:  0.8671875 testCost:  0.47237897 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1142 trainCost:  0.42703438 trainAccurancy:  0.8671875 testCost:  0.37214208 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1143 trainCost:  0.49766722 trainAccurancy:  0.8515625 testCost:  0.56604517 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1144 trainCost:  0.65548897 trainAccurancy:  0.8515625 testCost:  0.37235138 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1145 trainCost:  0.52096325 trainAccurancy:  0.8359375 testCost:  0.35804662 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1146 trainCost:  0.41644248 trainAccurancy:  0.875 testCost:  0.34065694 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1147 trainCost:  0.31282353 trainAccurancy:  0.90625 testCost:  0.54502046 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1148 trainCost:  0.4350594 trainAccurancy:  0.8671875 testCost:  0.50813913 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1149 trainCost:  0.40786296 trainAccurancy:  0.8828125 testCost:  0.40459833 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1150 trainCost:  0.3964532 trainAccurancy:  0.8515625 testCost:  0.3750162 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1151 trainCost:  0.45688865 trainAccurancy:  0.8984375 testCost:  0.29184952 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1152 trainCost:  0.4800713 trainAccurancy:  0.84375 testCost:  0.49279806 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1153 trainCost:  0.50037545 trainAccurancy:  0.859375 testCost:  0.5048218 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1154 trainCost:  0.30043048 trainAccurancy:  0.90625 testCost:  0.29913068 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1155 trainCost:  0.40292883 trainAccurancy:  0.8515625 testCost:  0.3463067 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1156 trainCost:  0.4199289 trainAccurancy:  0.8828125 testCost:  0.47678065 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1157 trainCost:  0.41184837 trainAccurancy:  0.875 testCost:  0.51648706 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1158 trainCost:  0.4538288 trainAccurancy:  0.875 testCost:  0.35726455 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1159 trainCost:  0.38000003 trainAccurancy:  0.875 testCost:  0.4686255 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1160 trainCost:  0.3387329 trainAccurancy:  0.9140625 testCost:  0.48677918 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1161 trainCost:  0.36545676 trainAccurancy:  0.90625 testCost:  0.45862818 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1162 trainCost:  0.44253016 trainAccurancy:  0.84375 testCost:  0.39138126 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1163 trainCost:  0.3531741 trainAccurancy:  0.9140625 testCost:  0.46373254 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1164 trainCost:  0.3522942 trainAccurancy:  0.90625 testCost:  0.424337 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1165 trainCost:  0.48429385 trainAccurancy:  0.8515625 testCost:  0.254552 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1166 trainCost:  0.52174884 trainAccurancy:  0.8203125 testCost:  0.4308033 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1167 trainCost:  0.58101594 trainAccurancy:  0.8046875 testCost:  0.3947271 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1168 trainCost:  0.28797302 trainAccurancy:  0.9296875 testCost:  0.42055956 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1169 trainCost:  0.40958917 trainAccurancy:  0.8671875 testCost:  0.30300537 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1170 trainCost:  0.40110332 trainAccurancy:  0.8984375 testCost:  0.53981733 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1171 trainCost:  0.35901287 trainAccurancy:  0.8828125 testCost:  0.35690427 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1172 trainCost:  0.42260295 trainAccurancy:  0.8828125 testCost:  0.43382215 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1173 trainCost:  0.42175692 trainAccurancy:  0.875 testCost:  0.48445594 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1174 trainCost:  0.48005986 trainAccurancy:  0.8671875 testCost:  0.4357099 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1175 trainCost:  0.48132622 trainAccurancy:  0.859375 testCost:  0.39411488 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1176 trainCost:  0.40184194 trainAccurancy:  0.828125 testCost:  0.5245169 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1177 trainCost:  0.42705894 trainAccurancy:  0.8984375 testCost:  0.3497105 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1178 trainCost:  0.4134056 trainAccurancy:  0.859375 testCost:  0.36985654 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1179 trainCost:  0.49352956 trainAccurancy:  0.859375 testCost:  0.43345904 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1180 trainCost:  0.42479452 trainAccurancy:  0.8984375 testCost:  0.34073794 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1181 trainCost:  0.48837063 trainAccurancy:  0.8359375 testCost:  0.38414532 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1182 trainCost:  0.33363616 trainAccurancy:  0.875 testCost:  0.48542833 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1183 trainCost:  0.39014828 trainAccurancy:  0.859375 testCost:  0.40255284 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1184 trainCost:  0.4464544 trainAccurancy:  0.8671875 testCost:  0.35981607 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1185 trainCost:  0.40020978 trainAccurancy:  0.890625 testCost:  0.4966981 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1186 trainCost:  0.41702223 trainAccurancy:  0.84375 testCost:  0.50604814 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1187 trainCost:  0.39728487 trainAccurancy:  0.90625 testCost:  0.37170064 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1188 trainCost:  0.4034404 trainAccurancy:  0.859375 testCost:  0.5663332 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1189 trainCost:  0.37143394 trainAccurancy:  0.8828125 testCost:  0.47901633 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1190 trainCost:  0.35093725 trainAccurancy:  0.9375 testCost:  0.3267806 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1191 trainCost:  0.40911388 trainAccurancy:  0.890625 testCost:  0.43800473 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1192 trainCost:  0.34222198 trainAccurancy:  0.875 testCost:  0.3095171 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1193 trainCost:  0.4178963 trainAccurancy:  0.84375 testCost:  0.45899612 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1194 trainCost:  0.40517107 trainAccurancy:  0.8671875 testCost:  0.5001675 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1195 trainCost:  0.5671347 trainAccurancy:  0.8203125 testCost:  0.35462153 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1196 trainCost:  0.36954033 trainAccurancy:  0.890625 testCost:  0.6150057 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1197 trainCost:  0.38160706 trainAccurancy:  0.859375 testCost:  0.39489278 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1198 trainCost:  0.4637135 trainAccurancy:  0.8515625 testCost:  0.26305777 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1199 trainCost:  0.429425 trainAccurancy:  0.8828125 testCost:  0.29188898 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1200 trainCost:  0.32604462 trainAccurancy:  0.8984375 testCost:  0.46952057 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1201 trainCost:  0.37670243 trainAccurancy:  0.859375 testCost:  0.41836724 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1202 trainCost:  0.48780155 trainAccurancy:  0.859375 testCost:  0.43830618 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1203 trainCost:  0.49412513 trainAccurancy:  0.8515625 testCost:  0.30807722 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1204 trainCost:  0.7893455 trainAccurancy:  0.75 testCost:  0.38591674 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1205 trainCost:  0.29612112 trainAccurancy:  0.9140625 testCost:  0.36528587 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1206 trainCost:  0.49696794 trainAccurancy:  0.8359375 testCost:  0.46497715 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1207 trainCost:  0.42696422 trainAccurancy:  0.8828125 testCost:  0.36809507 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1208 trainCost:  0.35110658 trainAccurancy:  0.859375 testCost:  0.49491498 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1209 trainCost:  0.46147305 trainAccurancy:  0.859375 testCost:  0.3601285 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1210 trainCost:  0.47581214 trainAccurancy:  0.8515625 testCost:  0.43224585 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1211 trainCost:  0.49744827 trainAccurancy:  0.84375 testCost:  0.27022743 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1212 trainCost:  0.45170292 trainAccurancy:  0.859375 testCost:  0.3672458 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1213 trainCost:  0.33135206 trainAccurancy:  0.890625 testCost:  0.39534128 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1214 trainCost:  0.38696894 trainAccurancy:  0.8828125 testCost:  0.58030605 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1215 trainCost:  0.35889333 trainAccurancy:  0.8984375 testCost:  0.29222843 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1216 trainCost:  0.4439918 trainAccurancy:  0.828125 testCost:  0.44932646 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1217 trainCost:  0.5858569 trainAccurancy:  0.8515625 testCost:  0.521208 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1218 trainCost:  0.2971568 trainAccurancy:  0.90625 testCost:  0.40113926 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1219 trainCost:  0.5678121 trainAccurancy:  0.7890625 testCost:  0.44005054 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1220 trainCost:  0.49491763 trainAccurancy:  0.8671875 testCost:  0.44695103 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1221 trainCost:  0.45858622 trainAccurancy:  0.8359375 testCost:  0.46153754 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1222 trainCost:  0.37760353 trainAccurancy:  0.90625 testCost:  0.3934813 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1223 trainCost:  0.4493472 trainAccurancy:  0.890625 testCost:  0.51913273 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1224 trainCost:  0.3707125 trainAccurancy:  0.875 testCost:  0.4681656 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1225 trainCost:  0.5314758 trainAccurancy:  0.8515625 testCost:  0.3140502 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1226 trainCost:  0.3906253 trainAccurancy:  0.8671875 testCost:  0.27294052 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1227 trainCost:  0.4896094 trainAccurancy:  0.8515625 testCost:  0.3981483 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1228 trainCost:  0.48427486 trainAccurancy:  0.8203125 testCost:  0.37841848 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1229 trainCost:  0.31076148 trainAccurancy:  0.90625 testCost:  0.29585424 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1230 trainCost:  0.3410993 trainAccurancy:  0.8828125 testCost:  0.4467609 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1231 trainCost:  0.44287613 trainAccurancy:  0.8828125 testCost:  0.2433718 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1232 trainCost:  0.3995433 trainAccurancy:  0.890625 testCost:  0.315662 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1233 trainCost:  0.49273938 trainAccurancy:  0.8671875 testCost:  0.6291172 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  1234 trainCost:  0.2922037 trainAccurancy:  0.8984375 testCost:  0.48787886 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1235 trainCost:  0.4179768 trainAccurancy:  0.8671875 testCost:  0.41925102 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1236 trainCost:  0.4914351 trainAccurancy:  0.875 testCost:  0.42889997 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1237 trainCost:  0.34139428 trainAccurancy:  0.9140625 testCost:  0.39756766 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1238 trainCost:  0.4728123 trainAccurancy:  0.8203125 testCost:  0.4609743 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1239 trainCost:  0.419321 trainAccurancy:  0.8984375 testCost:  0.45385137 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1240 trainCost:  0.34673056 trainAccurancy:  0.890625 testCost:  0.53824335 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1241 trainCost:  0.51581687 trainAccurancy:  0.8671875 testCost:  0.48931125 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1242 trainCost:  0.29046738 trainAccurancy:  0.9296875 testCost:  0.3624118 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1243 trainCost:  0.40186954 trainAccurancy:  0.8671875 testCost:  0.52946293 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1244 trainCost:  0.34457123 trainAccurancy:  0.890625 testCost:  0.26495466 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1245 trainCost:  0.56228435 trainAccurancy:  0.8671875 testCost:  0.40033266 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1246 trainCost:  0.55241585 trainAccurancy:  0.78125 testCost:  0.47455585 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1247 trainCost:  0.46219778 trainAccurancy:  0.875 testCost:  0.4987603 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1248 trainCost:  0.32630467 trainAccurancy:  0.8984375 testCost:  0.34321153 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1249 trainCost:  0.39975816 trainAccurancy:  0.8828125 testCost:  0.40412223 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1250 trainCost:  0.3099891 trainAccurancy:  0.90625 testCost:  0.3698454 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1251 trainCost:  0.3016281 trainAccurancy:  0.875 testCost:  0.5155356 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1252 trainCost:  0.38317567 trainAccurancy:  0.8671875 testCost:  0.42367274 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1253 trainCost:  0.42199677 trainAccurancy:  0.8671875 testCost:  0.2823626 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1254 trainCost:  0.47343668 trainAccurancy:  0.875 testCost:  0.34428924 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1255 trainCost:  0.35879394 trainAccurancy:  0.90625 testCost:  0.49724036 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1256 trainCost:  0.39976978 trainAccurancy:  0.8671875 testCost:  0.31537005 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1257 trainCost:  0.33140087 trainAccurancy:  0.9140625 testCost:  0.38645655 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1258 trainCost:  0.40634322 trainAccurancy:  0.859375 testCost:  0.5272103 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1259 trainCost:  0.34170124 trainAccurancy:  0.8828125 testCost:  0.36346412 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1260 trainCost:  0.38099042 trainAccurancy:  0.875 testCost:  0.5100299 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1261 trainCost:  0.5285535 trainAccurancy:  0.828125 testCost:  0.6073292 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1262 trainCost:  0.33203888 trainAccurancy:  0.90625 testCost:  0.4518879 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1263 trainCost:  0.25205064 trainAccurancy:  0.921875 testCost:  0.46242416 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1264 trainCost:  0.58775806 trainAccurancy:  0.7890625 testCost:  0.23974699 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1265 trainCost:  0.39302683 trainAccurancy:  0.890625 testCost:  0.53172624 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1266 trainCost:  0.41496918 trainAccurancy:  0.8671875 testCost:  0.3358754 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1267 trainCost:  0.37370944 trainAccurancy:  0.921875 testCost:  0.5673108 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1268 trainCost:  0.4962904 trainAccurancy:  0.84375 testCost:  0.35963678 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1269 trainCost:  0.3160923 trainAccurancy:  0.90625 testCost:  0.44055462 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1270 trainCost:  0.42508978 trainAccurancy:  0.875 testCost:  0.32039955 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1271 trainCost:  0.4360639 trainAccurancy:  0.8515625 testCost:  0.37057316 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1272 trainCost:  0.43216163 trainAccurancy:  0.875 testCost:  0.4174604 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1273 trainCost:  0.54148877 trainAccurancy:  0.859375 testCost:  0.4469276 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1274 trainCost:  0.390514 trainAccurancy:  0.875 testCost:  0.5158341 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1275 trainCost:  0.29818296 trainAccurancy:  0.890625 testCost:  0.29957625 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1276 trainCost:  0.43421066 trainAccurancy:  0.84375 testCost:  0.47934696 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1277 trainCost:  0.51220715 trainAccurancy:  0.828125 testCost:  0.487854 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1278 trainCost:  0.28994367 trainAccurancy:  0.90625 testCost:  0.48091084 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1279 trainCost:  0.35744965 trainAccurancy:  0.921875 testCost:  0.31974018 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1280 trainCost:  0.3562853 trainAccurancy:  0.875 testCost:  0.39784923 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1281 trainCost:  0.4843526 trainAccurancy:  0.890625 testCost:  0.39253634 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1282 trainCost:  0.43538913 trainAccurancy:  0.8671875 testCost:  0.4882044 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1283 trainCost:  0.44549417 trainAccurancy:  0.8828125 testCost:  0.30768707 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1284 trainCost:  0.47236317 trainAccurancy:  0.8671875 testCost:  0.3115722 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1285 trainCost:  0.33090663 trainAccurancy:  0.9140625 testCost:  0.2899711 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1286 trainCost:  0.4556164 trainAccurancy:  0.84375 testCost:  0.42060542 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1287 trainCost:  0.39344424 trainAccurancy:  0.8984375 testCost:  0.35822356 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1288 trainCost:  0.4766705 trainAccurancy:  0.859375 testCost:  0.31198478 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1289 trainCost:  0.24296696 trainAccurancy:  0.9296875 testCost:  0.4406205 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1290 trainCost:  0.47621912 trainAccurancy:  0.8671875 testCost:  0.4192411 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1291 trainCost:  0.3400612 trainAccurancy:  0.890625 testCost:  0.34971026 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1292 trainCost:  0.35084262 trainAccurancy:  0.8828125 testCost:  0.40354472 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1293 trainCost:  0.44134387 trainAccurancy:  0.8671875 testCost:  0.3697411 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1294 trainCost:  0.319592 trainAccurancy:  0.8984375 testCost:  0.41766104 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1295 trainCost:  0.2908125 trainAccurancy:  0.9296875 testCost:  0.5024245 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1296 trainCost:  0.37450144 trainAccurancy:  0.8828125 testCost:  0.4719811 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1297 trainCost:  0.44704956 trainAccurancy:  0.859375 testCost:  0.45147955 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1298 trainCost:  0.36246663 trainAccurancy:  0.859375 testCost:  0.44559443 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1299 trainCost:  0.31096834 trainAccurancy:  0.890625 testCost:  0.50233644 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1300 trainCost:  0.63589656 trainAccurancy:  0.828125 testCost:  0.40217498 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1301 trainCost:  0.5434769 trainAccurancy:  0.8203125 testCost:  0.47760573 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1302 trainCost:  0.4766056 trainAccurancy:  0.84375 testCost:  0.35609332 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1303 trainCost:  0.34891164 trainAccurancy:  0.890625 testCost:  0.41715068 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1304 trainCost:  0.37271184 trainAccurancy:  0.90625 testCost:  0.40472245 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1305 trainCost:  0.36641252 trainAccurancy:  0.8984375 testCost:  0.4819157 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1306 trainCost:  0.40101182 trainAccurancy:  0.8828125 testCost:  0.45997214 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1307 trainCost:  0.43966404 trainAccurancy:  0.890625 testCost:  0.41923946 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1308 trainCost:  0.40143746 trainAccurancy:  0.8515625 testCost:  0.52827597 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1309 trainCost:  0.4474035 trainAccurancy:  0.8671875 testCost:  0.33417127 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1310 trainCost:  0.4228363 trainAccurancy:  0.890625 testCost:  0.2845846 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1311 trainCost:  0.37232116 trainAccurancy:  0.8984375 testCost:  0.37032023 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1312 trainCost:  0.356431 trainAccurancy:  0.8984375 testCost:  0.45958918 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1313 trainCost:  0.36440182 trainAccurancy:  0.8984375 testCost:  0.42274624 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1314 trainCost:  0.43117586 trainAccurancy:  0.875 testCost:  0.45458543 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1315 trainCost:  0.37711462 trainAccurancy:  0.8671875 testCost:  0.42932224 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1316 trainCost:  0.43921906 trainAccurancy:  0.859375 testCost:  0.24668045 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1317 trainCost:  0.415343 trainAccurancy:  0.859375 testCost:  0.3402546 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1318 trainCost:  0.37411213 trainAccurancy:  0.890625 testCost:  0.4416579 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1319 trainCost:  0.46899974 trainAccurancy:  0.84375 testCost:  0.35518068 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1320 trainCost:  0.3398436 trainAccurancy:  0.8828125 testCost:  0.3451288 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1321 trainCost:  0.38378245 trainAccurancy:  0.890625 testCost:  0.42075092 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1322 trainCost:  0.43005437 trainAccurancy:  0.890625 testCost:  0.42147997 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1323 trainCost:  0.34408793 trainAccurancy:  0.875 testCost:  0.28780136 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1324 trainCost:  0.5836247 trainAccurancy:  0.8359375 testCost:  0.31927738 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1325 trainCost:  0.27026162 trainAccurancy:  0.90625 testCost:  0.47168806 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1326 trainCost:  0.34959608 trainAccurancy:  0.90625 testCost:  0.2898534 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1327 trainCost:  0.34634057 trainAccurancy:  0.8984375 testCost:  0.2939367 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1328 trainCost:  0.5145823 trainAccurancy:  0.859375 testCost:  0.28242064 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1329 trainCost:  0.40488645 trainAccurancy:  0.875 testCost:  0.64849097 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  1330 trainCost:  0.2307345 trainAccurancy:  0.921875 testCost:  0.37862808 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1331 trainCost:  0.35567063 trainAccurancy:  0.90625 testCost:  0.37568194 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1332 trainCost:  0.50026566 trainAccurancy:  0.84375 testCost:  0.35637802 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1333 trainCost:  0.47518957 trainAccurancy:  0.8515625 testCost:  0.3711 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1334 trainCost:  0.27329156 trainAccurancy:  0.90625 testCost:  0.43658772 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1335 trainCost:  0.3481341 trainAccurancy:  0.890625 testCost:  0.40705895 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1336 trainCost:  0.3279033 trainAccurancy:  0.90625 testCost:  0.35596752 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1337 trainCost:  0.30031723 trainAccurancy:  0.875 testCost:  0.5113491 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1338 trainCost:  0.36774915 trainAccurancy:  0.8984375 testCost:  0.44643635 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1339 trainCost:  0.5046187 trainAccurancy:  0.828125 testCost:  0.3485996 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1340 trainCost:  0.47874618 trainAccurancy:  0.84375 testCost:  0.43121746 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1341 trainCost:  0.38122857 trainAccurancy:  0.8671875 testCost:  0.35289538 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1342 trainCost:  0.28291062 trainAccurancy:  0.9375 testCost:  0.41894418 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1343 trainCost:  0.3855159 trainAccurancy:  0.828125 testCost:  0.36804023 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1344 trainCost:  0.39831215 trainAccurancy:  0.8984375 testCost:  0.44150597 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1345 trainCost:  0.34077394 trainAccurancy:  0.8671875 testCost:  0.23914719 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1346 trainCost:  0.2864903 trainAccurancy:  0.90625 testCost:  0.36138657 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1347 trainCost:  0.50372535 trainAccurancy:  0.8515625 testCost:  0.4010135 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1348 trainCost:  0.37936538 trainAccurancy:  0.859375 testCost:  0.37540913 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1349 trainCost:  0.394553 trainAccurancy:  0.859375 testCost:  0.27297416 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1350 trainCost:  0.519125 trainAccurancy:  0.84375 testCost:  0.36143306 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1351 trainCost:  0.4032455 trainAccurancy:  0.890625 testCost:  0.3902952 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1352 trainCost:  0.39039114 trainAccurancy:  0.90625 testCost:  0.33745748 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1353 trainCost:  0.3503837 trainAccurancy:  0.875 testCost:  0.40854883 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1354 trainCost:  0.36592826 trainAccurancy:  0.875 testCost:  0.38994116 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1355 trainCost:  0.4725568 trainAccurancy:  0.8828125 testCost:  0.34906965 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1356 trainCost:  0.3622786 trainAccurancy:  0.8671875 testCost:  0.34766918 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1357 trainCost:  0.33237863 trainAccurancy:  0.90625 testCost:  0.46975103 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1358 trainCost:  0.34970698 trainAccurancy:  0.8984375 testCost:  0.25709093 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1359 trainCost:  0.45929202 trainAccurancy:  0.8671875 testCost:  0.5809847 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1360 trainCost:  0.40679508 trainAccurancy:  0.8671875 testCost:  0.2727852 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1361 trainCost:  0.2865329 trainAccurancy:  0.890625 testCost:  0.35762754 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1362 trainCost:  0.37499946 trainAccurancy:  0.8984375 testCost:  0.27748024 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1363 trainCost:  0.32806495 trainAccurancy:  0.9140625 testCost:  0.44854882 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1364 trainCost:  0.32673192 trainAccurancy:  0.921875 testCost:  0.41888517 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1365 trainCost:  0.32696927 trainAccurancy:  0.8671875 testCost:  0.53021574 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1366 trainCost:  0.36244127 trainAccurancy:  0.8984375 testCost:  0.39435303 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1367 trainCost:  0.3287425 trainAccurancy:  0.8828125 testCost:  0.28676206 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1368 trainCost:  0.32731992 trainAccurancy:  0.90625 testCost:  0.40529692 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1369 trainCost:  0.38934937 trainAccurancy:  0.9140625 testCost:  0.47043768 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1370 trainCost:  0.44663608 trainAccurancy:  0.8671875 testCost:  0.2528516 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1371 trainCost:  0.4732569 trainAccurancy:  0.8671875 testCost:  0.33705127 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1372 trainCost:  0.35548896 trainAccurancy:  0.90625 testCost:  0.44978 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1373 trainCost:  0.36254832 trainAccurancy:  0.8671875 testCost:  0.67007464 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1374 trainCost:  0.38183492 trainAccurancy:  0.8828125 testCost:  0.30499744 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1375 trainCost:  0.31316447 trainAccurancy:  0.8984375 testCost:  0.47152352 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1376 trainCost:  0.2911891 trainAccurancy:  0.921875 testCost:  0.37325498 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1377 trainCost:  0.29461613 trainAccurancy:  0.890625 testCost:  0.39660025 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1378 trainCost:  0.3608037 trainAccurancy:  0.9140625 testCost:  0.67290306 testAccurancy:  0.8046875\n",
            "\n",
            "Iteration:  1379 trainCost:  0.44427884 trainAccurancy:  0.875 testCost:  0.3316115 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1380 trainCost:  0.3722971 trainAccurancy:  0.90625 testCost:  0.34425047 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1381 trainCost:  0.3935541 trainAccurancy:  0.8984375 testCost:  0.4265551 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1382 trainCost:  0.3982297 trainAccurancy:  0.890625 testCost:  0.2826525 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1383 trainCost:  0.5193677 trainAccurancy:  0.859375 testCost:  0.30970734 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1384 trainCost:  0.3638936 trainAccurancy:  0.875 testCost:  0.36984205 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1385 trainCost:  0.48939827 trainAccurancy:  0.859375 testCost:  0.29309312 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1386 trainCost:  0.4393785 trainAccurancy:  0.890625 testCost:  0.40553123 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1387 trainCost:  0.30350164 trainAccurancy:  0.90625 testCost:  0.27033994 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1388 trainCost:  0.36922026 trainAccurancy:  0.875 testCost:  0.46371907 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1389 trainCost:  0.25678337 trainAccurancy:  0.9140625 testCost:  0.34155488 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1390 trainCost:  0.512463 trainAccurancy:  0.84375 testCost:  0.31549925 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1391 trainCost:  0.37575608 trainAccurancy:  0.8671875 testCost:  0.39734218 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1392 trainCost:  0.3194492 trainAccurancy:  0.890625 testCost:  0.4313029 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1393 trainCost:  0.268949 trainAccurancy:  0.8984375 testCost:  0.4018612 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1394 trainCost:  0.33986425 trainAccurancy:  0.8984375 testCost:  0.60697335 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1395 trainCost:  0.32023287 trainAccurancy:  0.921875 testCost:  0.4282286 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1396 trainCost:  0.32847768 trainAccurancy:  0.90625 testCost:  0.41632068 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1397 trainCost:  0.44086984 trainAccurancy:  0.8515625 testCost:  0.3658147 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1398 trainCost:  0.2268883 trainAccurancy:  0.9140625 testCost:  0.26392955 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1399 trainCost:  0.3199273 trainAccurancy:  0.90625 testCost:  0.45494345 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1400 trainCost:  0.37636897 trainAccurancy:  0.8828125 testCost:  0.47500184 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1401 trainCost:  0.34372717 trainAccurancy:  0.8828125 testCost:  0.35573995 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1402 trainCost:  0.34369296 trainAccurancy:  0.90625 testCost:  0.48689255 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1403 trainCost:  0.39826915 trainAccurancy:  0.859375 testCost:  0.3991009 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1404 trainCost:  0.32134762 trainAccurancy:  0.90625 testCost:  0.3099054 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1405 trainCost:  0.24470861 trainAccurancy:  0.9296875 testCost:  0.4252843 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1406 trainCost:  0.34330618 trainAccurancy:  0.8984375 testCost:  0.45549056 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1407 trainCost:  0.3964979 trainAccurancy:  0.8515625 testCost:  0.48022878 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1408 trainCost:  0.23980515 trainAccurancy:  0.9453125 testCost:  0.44117928 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1409 trainCost:  0.4551168 trainAccurancy:  0.859375 testCost:  0.27831966 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1410 trainCost:  0.45597458 trainAccurancy:  0.859375 testCost:  0.35171193 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1411 trainCost:  0.35309395 trainAccurancy:  0.875 testCost:  0.33901834 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1412 trainCost:  0.36326355 trainAccurancy:  0.8828125 testCost:  0.36391237 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1413 trainCost:  0.36382583 trainAccurancy:  0.875 testCost:  0.36125946 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1414 trainCost:  0.51628613 trainAccurancy:  0.8515625 testCost:  0.42057556 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1415 trainCost:  0.4106751 trainAccurancy:  0.859375 testCost:  0.3184905 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1416 trainCost:  0.3207325 trainAccurancy:  0.8984375 testCost:  0.25089854 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1417 trainCost:  0.45907015 trainAccurancy:  0.8359375 testCost:  0.31437898 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1418 trainCost:  0.36450946 trainAccurancy:  0.8515625 testCost:  0.49004728 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1419 trainCost:  0.37194416 trainAccurancy:  0.8828125 testCost:  0.448107 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1420 trainCost:  0.5212146 trainAccurancy:  0.875 testCost:  0.36308992 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1421 trainCost:  0.32816184 trainAccurancy:  0.9296875 testCost:  0.44212812 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1422 trainCost:  0.39275426 trainAccurancy:  0.8671875 testCost:  0.30941314 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1423 trainCost:  0.3110258 trainAccurancy:  0.8828125 testCost:  0.42505735 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1424 trainCost:  0.36518157 trainAccurancy:  0.890625 testCost:  0.39695764 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1425 trainCost:  0.24667782 trainAccurancy:  0.921875 testCost:  0.26741403 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1426 trainCost:  0.6298344 trainAccurancy:  0.7890625 testCost:  0.48428774 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1427 trainCost:  0.40277776 trainAccurancy:  0.90625 testCost:  0.2869302 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1428 trainCost:  0.5037979 trainAccurancy:  0.828125 testCost:  0.4116468 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1429 trainCost:  0.3184495 trainAccurancy:  0.890625 testCost:  0.38271943 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1430 trainCost:  0.30249536 trainAccurancy:  0.9140625 testCost:  0.4749669 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1431 trainCost:  0.29221553 trainAccurancy:  0.8828125 testCost:  0.41559666 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1432 trainCost:  0.36620954 trainAccurancy:  0.8671875 testCost:  0.29953778 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1433 trainCost:  0.32771313 trainAccurancy:  0.8671875 testCost:  0.26670402 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1434 trainCost:  0.332068 trainAccurancy:  0.90625 testCost:  0.36742395 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1435 trainCost:  0.42581293 trainAccurancy:  0.890625 testCost:  0.22830603 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1436 trainCost:  0.4125527 trainAccurancy:  0.8671875 testCost:  0.33894137 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1437 trainCost:  0.36424938 trainAccurancy:  0.890625 testCost:  0.4398887 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1438 trainCost:  0.19256318 trainAccurancy:  0.9296875 testCost:  0.43041447 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1439 trainCost:  0.4818256 trainAccurancy:  0.828125 testCost:  0.4582503 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1440 trainCost:  0.40150854 trainAccurancy:  0.875 testCost:  0.39913148 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1441 trainCost:  0.3123443 trainAccurancy:  0.9296875 testCost:  0.5002409 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1442 trainCost:  0.35036707 trainAccurancy:  0.9140625 testCost:  0.34483927 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1443 trainCost:  0.30159226 trainAccurancy:  0.90625 testCost:  0.29972667 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1444 trainCost:  0.46247154 trainAccurancy:  0.8828125 testCost:  0.4341522 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1445 trainCost:  0.50008464 trainAccurancy:  0.84375 testCost:  0.37836415 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1446 trainCost:  0.27150005 trainAccurancy:  0.9296875 testCost:  0.43917036 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1447 trainCost:  0.2957217 trainAccurancy:  0.9140625 testCost:  0.32523352 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1448 trainCost:  0.41792807 trainAccurancy:  0.84375 testCost:  0.35179466 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1449 trainCost:  0.22560856 trainAccurancy:  0.9453125 testCost:  0.44371137 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1450 trainCost:  0.5219463 trainAccurancy:  0.859375 testCost:  0.41798365 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1451 trainCost:  0.44715995 trainAccurancy:  0.875 testCost:  0.40181515 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1452 trainCost:  0.20711014 trainAccurancy:  0.9296875 testCost:  0.52618116 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1453 trainCost:  0.4519491 trainAccurancy:  0.859375 testCost:  0.3223254 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1454 trainCost:  0.35973763 trainAccurancy:  0.90625 testCost:  0.3493826 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1455 trainCost:  0.34603655 trainAccurancy:  0.890625 testCost:  0.45433122 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1456 trainCost:  0.4199633 trainAccurancy:  0.84375 testCost:  0.35160318 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1457 trainCost:  0.31011623 trainAccurancy:  0.90625 testCost:  0.2980765 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1458 trainCost:  0.26155874 trainAccurancy:  0.921875 testCost:  0.6714571 testAccurancy:  0.8125\n",
            "\n",
            "Iteration:  1459 trainCost:  0.4959842 trainAccurancy:  0.828125 testCost:  0.2603994 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1460 trainCost:  0.55621326 trainAccurancy:  0.84375 testCost:  0.22610262 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1461 trainCost:  0.4403025 trainAccurancy:  0.890625 testCost:  0.4286278 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1462 trainCost:  0.3716172 trainAccurancy:  0.8828125 testCost:  0.41783127 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1463 trainCost:  0.33426163 trainAccurancy:  0.90625 testCost:  0.336281 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1464 trainCost:  0.2807023 trainAccurancy:  0.9296875 testCost:  0.44078526 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1465 trainCost:  0.37403357 trainAccurancy:  0.8828125 testCost:  0.41953033 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1466 trainCost:  0.26073402 trainAccurancy:  0.9140625 testCost:  0.3937125 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1467 trainCost:  0.4646397 trainAccurancy:  0.8515625 testCost:  0.3143031 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1468 trainCost:  0.33756953 trainAccurancy:  0.890625 testCost:  0.43090466 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1469 trainCost:  0.35250676 trainAccurancy:  0.875 testCost:  0.43382108 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1470 trainCost:  0.35311326 trainAccurancy:  0.8671875 testCost:  0.41781494 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1471 trainCost:  0.55990326 trainAccurancy:  0.8359375 testCost:  0.3665306 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1472 trainCost:  0.37476596 trainAccurancy:  0.8671875 testCost:  0.6178905 testAccurancy:  0.796875\n",
            "\n",
            "Iteration:  1473 trainCost:  0.42012307 trainAccurancy:  0.8984375 testCost:  0.34354886 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1474 trainCost:  0.2752567 trainAccurancy:  0.9375 testCost:  0.38674295 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1475 trainCost:  0.29862306 trainAccurancy:  0.9296875 testCost:  0.3440506 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1476 trainCost:  0.32699424 trainAccurancy:  0.90625 testCost:  0.34884664 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1477 trainCost:  0.39253643 trainAccurancy:  0.8671875 testCost:  0.44958368 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1478 trainCost:  0.41765344 trainAccurancy:  0.8515625 testCost:  0.3170933 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1479 trainCost:  0.37124613 trainAccurancy:  0.890625 testCost:  0.29881898 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1480 trainCost:  0.39226222 trainAccurancy:  0.859375 testCost:  0.39576614 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1481 trainCost:  0.3419586 trainAccurancy:  0.890625 testCost:  0.56153023 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1482 trainCost:  0.3060707 trainAccurancy:  0.90625 testCost:  0.3339694 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1483 trainCost:  0.37806275 trainAccurancy:  0.8984375 testCost:  0.2937585 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1484 trainCost:  0.41216213 trainAccurancy:  0.890625 testCost:  0.24823096 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1485 trainCost:  0.4116346 trainAccurancy:  0.90625 testCost:  0.37440917 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1486 trainCost:  0.28485912 trainAccurancy:  0.90625 testCost:  0.38986573 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1487 trainCost:  0.38753262 trainAccurancy:  0.8671875 testCost:  0.4815829 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1488 trainCost:  0.28456965 trainAccurancy:  0.9140625 testCost:  0.5262065 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1489 trainCost:  0.41399747 trainAccurancy:  0.890625 testCost:  0.35594717 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1490 trainCost:  0.34704667 trainAccurancy:  0.8828125 testCost:  0.36798728 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1491 trainCost:  0.55044067 trainAccurancy:  0.8203125 testCost:  0.4733316 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1492 trainCost:  0.2925114 trainAccurancy:  0.90625 testCost:  0.37565568 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1493 trainCost:  0.35889557 trainAccurancy:  0.8828125 testCost:  0.26551926 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1494 trainCost:  0.4223754 trainAccurancy:  0.8828125 testCost:  0.3490292 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1495 trainCost:  0.416346 trainAccurancy:  0.8671875 testCost:  0.30179235 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1496 trainCost:  0.42388523 trainAccurancy:  0.8515625 testCost:  0.21102649 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1497 trainCost:  0.5974183 trainAccurancy:  0.8203125 testCost:  0.35802636 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1498 trainCost:  0.38725758 trainAccurancy:  0.8671875 testCost:  0.34996948 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1499 trainCost:  0.27109998 trainAccurancy:  0.9140625 testCost:  0.39683792 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1500 trainCost:  0.33133933 trainAccurancy:  0.9140625 testCost:  0.45887327 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1501 trainCost:  0.4263785 trainAccurancy:  0.859375 testCost:  0.40909392 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1502 trainCost:  0.27464625 trainAccurancy:  0.8828125 testCost:  0.3857866 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1503 trainCost:  0.42890126 trainAccurancy:  0.8828125 testCost:  0.32287818 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1504 trainCost:  0.2775346 trainAccurancy:  0.9140625 testCost:  0.26890928 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1505 trainCost:  0.3220805 trainAccurancy:  0.9140625 testCost:  0.28807425 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1506 trainCost:  0.47384378 trainAccurancy:  0.875 testCost:  0.39572272 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1507 trainCost:  0.47125292 trainAccurancy:  0.8515625 testCost:  0.2848043 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1508 trainCost:  0.3292461 trainAccurancy:  0.890625 testCost:  0.47421136 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1509 trainCost:  0.36332625 trainAccurancy:  0.8828125 testCost:  0.4402961 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1510 trainCost:  0.33513117 trainAccurancy:  0.8984375 testCost:  0.44922674 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1511 trainCost:  0.38198608 trainAccurancy:  0.875 testCost:  0.35892355 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1512 trainCost:  0.39476526 trainAccurancy:  0.859375 testCost:  0.25486165 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1513 trainCost:  0.34057575 trainAccurancy:  0.890625 testCost:  0.45529667 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1514 trainCost:  0.41332647 trainAccurancy:  0.8671875 testCost:  0.2990429 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1515 trainCost:  0.35315907 trainAccurancy:  0.8828125 testCost:  0.19619691 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1516 trainCost:  0.31163168 trainAccurancy:  0.90625 testCost:  0.5195322 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1517 trainCost:  0.41341 trainAccurancy:  0.8515625 testCost:  0.4225123 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1518 trainCost:  0.2661008 trainAccurancy:  0.8984375 testCost:  0.37877446 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1519 trainCost:  0.33037248 trainAccurancy:  0.921875 testCost:  0.36664468 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1520 trainCost:  0.37161833 trainAccurancy:  0.9140625 testCost:  0.4087416 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1521 trainCost:  0.4001406 trainAccurancy:  0.9140625 testCost:  0.36174297 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1522 trainCost:  0.24365398 trainAccurancy:  0.90625 testCost:  0.40779138 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1523 trainCost:  0.42525804 trainAccurancy:  0.8671875 testCost:  0.38791794 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1524 trainCost:  0.34079924 trainAccurancy:  0.8828125 testCost:  0.40076786 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1525 trainCost:  0.2712344 trainAccurancy:  0.921875 testCost:  0.15867496 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1526 trainCost:  0.47281718 trainAccurancy:  0.859375 testCost:  0.48184115 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1527 trainCost:  0.39427638 trainAccurancy:  0.875 testCost:  0.48192173 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1528 trainCost:  0.32117507 trainAccurancy:  0.875 testCost:  0.38483885 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1529 trainCost:  0.5057144 trainAccurancy:  0.8671875 testCost:  0.475837 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1530 trainCost:  0.3838546 trainAccurancy:  0.8984375 testCost:  0.48681408 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1531 trainCost:  0.36377317 trainAccurancy:  0.8984375 testCost:  0.5713997 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1532 trainCost:  0.30395836 trainAccurancy:  0.90625 testCost:  0.44145268 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1533 trainCost:  0.40353352 trainAccurancy:  0.875 testCost:  0.28938067 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1534 trainCost:  0.38177568 trainAccurancy:  0.921875 testCost:  0.45746413 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1535 trainCost:  0.43723804 trainAccurancy:  0.875 testCost:  0.3621453 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1536 trainCost:  0.19440986 trainAccurancy:  0.9140625 testCost:  0.2786662 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1537 trainCost:  0.4091696 trainAccurancy:  0.890625 testCost:  0.29031402 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1538 trainCost:  0.25973994 trainAccurancy:  0.90625 testCost:  0.2692597 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1539 trainCost:  0.5098767 trainAccurancy:  0.875 testCost:  0.2690934 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1540 trainCost:  0.39069435 trainAccurancy:  0.890625 testCost:  0.32407326 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1541 trainCost:  0.36232203 trainAccurancy:  0.8984375 testCost:  0.4569831 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1542 trainCost:  0.31737694 trainAccurancy:  0.9140625 testCost:  0.32175016 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1543 trainCost:  0.51232207 trainAccurancy:  0.875 testCost:  0.30312076 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1544 trainCost:  0.5685984 trainAccurancy:  0.84375 testCost:  0.24721205 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1545 trainCost:  0.32284644 trainAccurancy:  0.9296875 testCost:  0.26031262 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1546 trainCost:  0.39696604 trainAccurancy:  0.8984375 testCost:  0.31746006 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1547 trainCost:  0.39348322 trainAccurancy:  0.875 testCost:  0.5125724 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1548 trainCost:  0.35398558 trainAccurancy:  0.8671875 testCost:  0.40609476 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1549 trainCost:  0.27980816 trainAccurancy:  0.921875 testCost:  0.4174556 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1550 trainCost:  0.2953139 trainAccurancy:  0.890625 testCost:  0.275616 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1551 trainCost:  0.49838713 trainAccurancy:  0.8359375 testCost:  0.4147588 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1552 trainCost:  0.44430852 trainAccurancy:  0.8515625 testCost:  0.4158537 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1553 trainCost:  0.43362468 trainAccurancy:  0.8984375 testCost:  0.34629613 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1554 trainCost:  0.3384869 trainAccurancy:  0.8828125 testCost:  0.645864 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1555 trainCost:  0.32101324 trainAccurancy:  0.9140625 testCost:  0.37747127 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1556 trainCost:  0.37144637 trainAccurancy:  0.9140625 testCost:  0.405027 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1557 trainCost:  0.39812213 trainAccurancy:  0.890625 testCost:  0.33359382 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1558 trainCost:  0.3406489 trainAccurancy:  0.875 testCost:  0.43665397 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1559 trainCost:  0.28719693 trainAccurancy:  0.921875 testCost:  0.21352704 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1560 trainCost:  0.4207733 trainAccurancy:  0.90625 testCost:  0.300583 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1561 trainCost:  0.43093926 trainAccurancy:  0.8671875 testCost:  0.34490824 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1562 trainCost:  0.30607492 trainAccurancy:  0.9140625 testCost:  0.37507638 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1563 trainCost:  0.29495788 trainAccurancy:  0.9140625 testCost:  0.40359965 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1564 trainCost:  0.500134 trainAccurancy:  0.8828125 testCost:  0.31940135 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1565 trainCost:  0.44813466 trainAccurancy:  0.8671875 testCost:  0.31581843 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1566 trainCost:  0.27090755 trainAccurancy:  0.8984375 testCost:  0.53722817 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1567 trainCost:  0.2214274 trainAccurancy:  0.9296875 testCost:  0.33167592 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1568 trainCost:  0.38093877 trainAccurancy:  0.8828125 testCost:  0.45910713 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1569 trainCost:  0.43502694 trainAccurancy:  0.8671875 testCost:  0.37170398 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1570 trainCost:  0.33656657 trainAccurancy:  0.8828125 testCost:  0.5018554 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1571 trainCost:  0.3352737 trainAccurancy:  0.859375 testCost:  0.37535012 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1572 trainCost:  0.48776665 trainAccurancy:  0.828125 testCost:  0.35816634 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1573 trainCost:  0.57987666 trainAccurancy:  0.8671875 testCost:  0.39475435 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1574 trainCost:  0.29319623 trainAccurancy:  0.9296875 testCost:  0.2396739 testAccurancy:  0.953125\n",
            "\n",
            "Iteration:  1575 trainCost:  0.4910656 trainAccurancy:  0.8671875 testCost:  0.38308832 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1576 trainCost:  0.2955826 trainAccurancy:  0.90625 testCost:  0.39987653 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1577 trainCost:  0.41266823 trainAccurancy:  0.8828125 testCost:  0.5337403 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1578 trainCost:  0.51072216 trainAccurancy:  0.890625 testCost:  0.2515483 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1579 trainCost:  0.37975731 trainAccurancy:  0.8828125 testCost:  0.3470215 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1580 trainCost:  0.34131375 trainAccurancy:  0.890625 testCost:  0.475995 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1581 trainCost:  0.34031177 trainAccurancy:  0.90625 testCost:  0.37953654 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1582 trainCost:  0.3077444 trainAccurancy:  0.859375 testCost:  0.26952216 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1583 trainCost:  0.34821063 trainAccurancy:  0.9140625 testCost:  0.35983258 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1584 trainCost:  0.4767962 trainAccurancy:  0.84375 testCost:  0.23368648 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1585 trainCost:  0.372448 trainAccurancy:  0.8828125 testCost:  0.23916811 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1586 trainCost:  0.40518785 trainAccurancy:  0.875 testCost:  0.33143294 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1587 trainCost:  0.43474633 trainAccurancy:  0.8828125 testCost:  0.3179711 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1588 trainCost:  0.39750302 trainAccurancy:  0.8515625 testCost:  0.34554952 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1589 trainCost:  0.27701834 trainAccurancy:  0.9296875 testCost:  0.34834218 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1590 trainCost:  0.37752247 trainAccurancy:  0.8671875 testCost:  0.35346627 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1591 trainCost:  0.3885577 trainAccurancy:  0.8828125 testCost:  0.25937235 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1592 trainCost:  0.30604646 trainAccurancy:  0.8828125 testCost:  0.3385726 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1593 trainCost:  0.44180948 trainAccurancy:  0.859375 testCost:  0.4090115 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1594 trainCost:  0.24553663 trainAccurancy:  0.9296875 testCost:  0.35244966 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1595 trainCost:  0.14232378 trainAccurancy:  0.96875 testCost:  0.32823765 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1596 trainCost:  0.4684435 trainAccurancy:  0.8515625 testCost:  0.3869336 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1597 trainCost:  0.19576605 trainAccurancy:  0.9296875 testCost:  0.2813536 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1598 trainCost:  0.3983667 trainAccurancy:  0.90625 testCost:  0.31435603 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1599 trainCost:  0.2406089 trainAccurancy:  0.8984375 testCost:  0.23683828 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1600 trainCost:  0.25105163 trainAccurancy:  0.9453125 testCost:  0.3495522 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1601 trainCost:  0.39059424 trainAccurancy:  0.875 testCost:  0.36002058 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1602 trainCost:  0.4550445 trainAccurancy:  0.8671875 testCost:  0.32410365 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1603 trainCost:  0.38616297 trainAccurancy:  0.8984375 testCost:  0.45939118 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1604 trainCost:  0.37874922 trainAccurancy:  0.8828125 testCost:  0.5216433 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1605 trainCost:  0.20189297 trainAccurancy:  0.9375 testCost:  0.3096009 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1606 trainCost:  0.5663475 trainAccurancy:  0.84375 testCost:  0.44534546 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1607 trainCost:  0.22480518 trainAccurancy:  0.90625 testCost:  0.23281834 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1608 trainCost:  0.37078214 trainAccurancy:  0.9140625 testCost:  0.31207797 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1609 trainCost:  0.33022404 trainAccurancy:  0.8984375 testCost:  0.29731587 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1610 trainCost:  0.37604645 trainAccurancy:  0.8984375 testCost:  0.39966196 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1611 trainCost:  0.297386 trainAccurancy:  0.890625 testCost:  0.24240156 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1612 trainCost:  0.33253852 trainAccurancy:  0.90625 testCost:  0.32290107 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1613 trainCost:  0.34801334 trainAccurancy:  0.875 testCost:  0.4722556 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1614 trainCost:  0.39521432 trainAccurancy:  0.8984375 testCost:  0.4109394 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1615 trainCost:  0.33362934 trainAccurancy:  0.8828125 testCost:  0.30307034 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1616 trainCost:  0.33698276 trainAccurancy:  0.875 testCost:  0.322679 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1617 trainCost:  0.43214297 trainAccurancy:  0.890625 testCost:  0.61596 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1618 trainCost:  0.3914156 trainAccurancy:  0.8984375 testCost:  0.35006922 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1619 trainCost:  0.4220039 trainAccurancy:  0.875 testCost:  0.35146686 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1620 trainCost:  0.27106518 trainAccurancy:  0.90625 testCost:  0.39863575 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1621 trainCost:  0.40687904 trainAccurancy:  0.90625 testCost:  0.24894965 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1622 trainCost:  0.39657047 trainAccurancy:  0.8828125 testCost:  0.37075457 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1623 trainCost:  0.40267915 trainAccurancy:  0.9140625 testCost:  0.2703317 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1624 trainCost:  0.39284223 trainAccurancy:  0.8828125 testCost:  0.33884928 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1625 trainCost:  0.35119647 trainAccurancy:  0.90625 testCost:  0.44184718 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1626 trainCost:  0.3167836 trainAccurancy:  0.9140625 testCost:  0.32288894 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1627 trainCost:  0.34460127 trainAccurancy:  0.921875 testCost:  0.38062364 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1628 trainCost:  0.33755755 trainAccurancy:  0.9375 testCost:  0.47564137 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1629 trainCost:  0.2718925 trainAccurancy:  0.9140625 testCost:  0.2667096 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1630 trainCost:  0.45164084 trainAccurancy:  0.875 testCost:  0.25430703 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1631 trainCost:  0.37574083 trainAccurancy:  0.90625 testCost:  0.25981012 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1632 trainCost:  0.33511406 trainAccurancy:  0.890625 testCost:  0.48444274 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1633 trainCost:  0.31959677 trainAccurancy:  0.8828125 testCost:  0.36924648 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1634 trainCost:  0.31416816 trainAccurancy:  0.90625 testCost:  0.60611457 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1635 trainCost:  0.29907405 trainAccurancy:  0.921875 testCost:  0.478949 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1636 trainCost:  0.2977005 trainAccurancy:  0.8828125 testCost:  0.2831844 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1637 trainCost:  0.38603657 trainAccurancy:  0.890625 testCost:  0.35311925 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1638 trainCost:  0.43490347 trainAccurancy:  0.8515625 testCost:  0.5393251 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1639 trainCost:  0.23953411 trainAccurancy:  0.921875 testCost:  0.36209458 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1640 trainCost:  0.29912794 trainAccurancy:  0.9140625 testCost:  0.31357944 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1641 trainCost:  0.32960042 trainAccurancy:  0.921875 testCost:  0.27451646 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1642 trainCost:  0.30473387 trainAccurancy:  0.8984375 testCost:  0.37439978 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1643 trainCost:  0.26285008 trainAccurancy:  0.921875 testCost:  0.44438 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1644 trainCost:  0.2430667 trainAccurancy:  0.921875 testCost:  0.26980966 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1645 trainCost:  0.45869595 trainAccurancy:  0.875 testCost:  0.23347983 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1646 trainCost:  0.4365792 trainAccurancy:  0.8828125 testCost:  0.4584052 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1647 trainCost:  0.2307356 trainAccurancy:  0.9375 testCost:  0.43435267 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1648 trainCost:  0.48534808 trainAccurancy:  0.890625 testCost:  0.52461743 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1649 trainCost:  0.3165405 trainAccurancy:  0.8984375 testCost:  0.45950076 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1650 trainCost:  0.26519778 trainAccurancy:  0.9140625 testCost:  0.33986053 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1651 trainCost:  0.26890123 trainAccurancy:  0.90625 testCost:  0.3851899 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1652 trainCost:  0.45563826 trainAccurancy:  0.84375 testCost:  0.24107829 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1653 trainCost:  0.31941313 trainAccurancy:  0.890625 testCost:  0.40985423 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1654 trainCost:  0.30321378 trainAccurancy:  0.8984375 testCost:  0.5672643 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1655 trainCost:  0.3612295 trainAccurancy:  0.890625 testCost:  0.44353944 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1656 trainCost:  0.37272766 trainAccurancy:  0.890625 testCost:  0.3571598 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1657 trainCost:  0.37672585 trainAccurancy:  0.8984375 testCost:  0.35352045 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1658 trainCost:  0.33757964 trainAccurancy:  0.8984375 testCost:  0.27511454 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1659 trainCost:  0.4231332 trainAccurancy:  0.875 testCost:  0.32303506 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1660 trainCost:  0.36783743 trainAccurancy:  0.8828125 testCost:  0.4060794 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1661 trainCost:  0.28198543 trainAccurancy:  0.90625 testCost:  0.24098843 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1662 trainCost:  0.34321228 trainAccurancy:  0.9140625 testCost:  0.30672687 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1663 trainCost:  0.48670578 trainAccurancy:  0.84375 testCost:  0.39187208 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1664 trainCost:  0.42395994 trainAccurancy:  0.8828125 testCost:  0.49139065 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1665 trainCost:  0.3484291 trainAccurancy:  0.890625 testCost:  0.3028565 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1666 trainCost:  0.42216682 trainAccurancy:  0.8984375 testCost:  0.20841627 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1667 trainCost:  0.31671116 trainAccurancy:  0.875 testCost:  0.3609882 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1668 trainCost:  0.3986326 trainAccurancy:  0.9140625 testCost:  0.35108247 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1669 trainCost:  0.3747723 trainAccurancy:  0.8515625 testCost:  0.3712594 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1670 trainCost:  0.33669877 trainAccurancy:  0.8984375 testCost:  0.41692984 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1671 trainCost:  0.29311353 trainAccurancy:  0.8984375 testCost:  0.17289504 testAccurancy:  0.953125\n",
            "\n",
            "Iteration:  1672 trainCost:  0.2399309 trainAccurancy:  0.921875 testCost:  0.3569463 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1673 trainCost:  0.30829263 trainAccurancy:  0.90625 testCost:  0.24885097 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1674 trainCost:  0.38450238 trainAccurancy:  0.8984375 testCost:  0.29802856 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1675 trainCost:  0.30899817 trainAccurancy:  0.890625 testCost:  0.3356815 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1676 trainCost:  0.27521127 trainAccurancy:  0.890625 testCost:  0.5553307 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1677 trainCost:  0.3888294 trainAccurancy:  0.8984375 testCost:  0.32876077 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1678 trainCost:  0.2957758 trainAccurancy:  0.9296875 testCost:  0.2651961 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1679 trainCost:  0.53177965 trainAccurancy:  0.8359375 testCost:  0.5651637 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1680 trainCost:  0.26306874 trainAccurancy:  0.9296875 testCost:  0.47605878 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1681 trainCost:  0.4371616 trainAccurancy:  0.8828125 testCost:  0.26304728 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1682 trainCost:  0.39308712 trainAccurancy:  0.8828125 testCost:  0.3319115 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1683 trainCost:  0.26446688 trainAccurancy:  0.90625 testCost:  0.41718027 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1684 trainCost:  0.45404497 trainAccurancy:  0.859375 testCost:  0.4045588 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1685 trainCost:  0.238549 trainAccurancy:  0.9375 testCost:  0.37783027 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1686 trainCost:  0.31310815 trainAccurancy:  0.8984375 testCost:  0.42698747 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1687 trainCost:  0.37315583 trainAccurancy:  0.90625 testCost:  0.25239438 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1688 trainCost:  0.4019727 trainAccurancy:  0.828125 testCost:  0.3636027 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1689 trainCost:  0.45475876 trainAccurancy:  0.8359375 testCost:  0.36521 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1690 trainCost:  0.29838976 trainAccurancy:  0.921875 testCost:  0.32992747 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1691 trainCost:  0.44478247 trainAccurancy:  0.8984375 testCost:  0.22663721 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1692 trainCost:  0.23494098 trainAccurancy:  0.9453125 testCost:  0.48542607 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1693 trainCost:  0.35161826 trainAccurancy:  0.8984375 testCost:  0.32306033 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1694 trainCost:  0.47835273 trainAccurancy:  0.859375 testCost:  0.37412506 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1695 trainCost:  0.3223712 trainAccurancy:  0.921875 testCost:  0.25743806 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1696 trainCost:  0.4909044 trainAccurancy:  0.84375 testCost:  0.26947126 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1697 trainCost:  0.45303118 trainAccurancy:  0.8671875 testCost:  0.2985029 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1698 trainCost:  0.1848763 trainAccurancy:  0.953125 testCost:  0.4493683 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1699 trainCost:  0.29936296 trainAccurancy:  0.9296875 testCost:  0.44355813 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1700 trainCost:  0.39074567 trainAccurancy:  0.890625 testCost:  0.35300758 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1701 trainCost:  0.35149223 trainAccurancy:  0.921875 testCost:  0.42251688 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1702 trainCost:  0.17255142 trainAccurancy:  0.9296875 testCost:  0.24526161 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1703 trainCost:  0.396694 trainAccurancy:  0.8828125 testCost:  0.5737537 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1704 trainCost:  0.39820027 trainAccurancy:  0.890625 testCost:  0.42446953 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1705 trainCost:  0.37798196 trainAccurancy:  0.8828125 testCost:  0.27268693 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1706 trainCost:  0.39305434 trainAccurancy:  0.8984375 testCost:  0.27068597 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1707 trainCost:  0.42387345 trainAccurancy:  0.8515625 testCost:  0.35285044 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1708 trainCost:  0.4256822 trainAccurancy:  0.8671875 testCost:  0.3158328 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1709 trainCost:  0.1680139 trainAccurancy:  0.9609375 testCost:  0.3670261 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1710 trainCost:  0.27058065 trainAccurancy:  0.9140625 testCost:  0.3579974 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1711 trainCost:  0.24640915 trainAccurancy:  0.9140625 testCost:  0.31861392 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1712 trainCost:  0.5246844 trainAccurancy:  0.875 testCost:  0.31374788 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1713 trainCost:  0.23458302 trainAccurancy:  0.9296875 testCost:  0.40920246 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1714 trainCost:  0.34274217 trainAccurancy:  0.8984375 testCost:  0.3062254 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1715 trainCost:  0.3781759 trainAccurancy:  0.8984375 testCost:  0.3248331 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1716 trainCost:  0.4366774 trainAccurancy:  0.8984375 testCost:  0.26201057 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1717 trainCost:  0.5699115 trainAccurancy:  0.8046875 testCost:  0.3222131 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1718 trainCost:  0.20520066 trainAccurancy:  0.9375 testCost:  0.35661432 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1719 trainCost:  0.29736125 trainAccurancy:  0.921875 testCost:  0.18327981 testAccurancy:  0.9609375\n",
            "\n",
            "Iteration:  1720 trainCost:  0.38923898 trainAccurancy:  0.8984375 testCost:  0.3115893 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1721 trainCost:  0.26912045 trainAccurancy:  0.9453125 testCost:  0.42070234 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1722 trainCost:  0.38521042 trainAccurancy:  0.859375 testCost:  0.32916868 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1723 trainCost:  0.39282733 trainAccurancy:  0.890625 testCost:  0.32387757 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1724 trainCost:  0.26870388 trainAccurancy:  0.9140625 testCost:  0.32343802 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1725 trainCost:  0.26988474 trainAccurancy:  0.90625 testCost:  0.30269417 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1726 trainCost:  0.19773728 trainAccurancy:  0.9375 testCost:  0.3607306 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1727 trainCost:  0.3168141 trainAccurancy:  0.90625 testCost:  0.29033116 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1728 trainCost:  0.17473389 trainAccurancy:  0.953125 testCost:  0.4478761 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1729 trainCost:  0.3306998 trainAccurancy:  0.8984375 testCost:  0.39925233 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1730 trainCost:  0.27021396 trainAccurancy:  0.8984375 testCost:  0.60094696 testAccurancy:  0.8203125\n",
            "\n",
            "Iteration:  1731 trainCost:  0.25664157 trainAccurancy:  0.921875 testCost:  0.27272886 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1732 trainCost:  0.41282165 trainAccurancy:  0.9140625 testCost:  0.2825873 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1733 trainCost:  0.40831658 trainAccurancy:  0.890625 testCost:  0.21638969 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1734 trainCost:  0.26114526 trainAccurancy:  0.921875 testCost:  0.2738824 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1735 trainCost:  0.31651306 trainAccurancy:  0.90625 testCost:  0.21340299 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1736 trainCost:  0.44030064 trainAccurancy:  0.8671875 testCost:  0.23929444 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1737 trainCost:  0.14321928 trainAccurancy:  0.9609375 testCost:  0.31114134 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1738 trainCost:  0.22210363 trainAccurancy:  0.9609375 testCost:  0.44797853 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1739 trainCost:  0.3321013 trainAccurancy:  0.8671875 testCost:  0.15519695 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1740 trainCost:  0.38047573 trainAccurancy:  0.890625 testCost:  0.40014404 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1741 trainCost:  0.26375 trainAccurancy:  0.921875 testCost:  0.45713833 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1742 trainCost:  0.20249033 trainAccurancy:  0.9375 testCost:  0.2957811 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1743 trainCost:  0.25596625 trainAccurancy:  0.9296875 testCost:  0.3249658 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1744 trainCost:  0.33428976 trainAccurancy:  0.8671875 testCost:  0.39280823 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1745 trainCost:  0.43271172 trainAccurancy:  0.890625 testCost:  0.33854795 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1746 trainCost:  0.38147083 trainAccurancy:  0.8984375 testCost:  0.3028382 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1747 trainCost:  0.356528 trainAccurancy:  0.890625 testCost:  0.5356916 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1748 trainCost:  0.22656538 trainAccurancy:  0.9140625 testCost:  0.3408512 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1749 trainCost:  0.26941139 trainAccurancy:  0.9296875 testCost:  0.34282523 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1750 trainCost:  0.2844011 trainAccurancy:  0.90625 testCost:  0.31002027 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1751 trainCost:  0.3578757 trainAccurancy:  0.90625 testCost:  0.409663 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1752 trainCost:  0.37129843 trainAccurancy:  0.8671875 testCost:  0.33358687 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1753 trainCost:  0.322452 trainAccurancy:  0.8984375 testCost:  0.32257658 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1754 trainCost:  0.3542233 trainAccurancy:  0.921875 testCost:  0.46782422 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1755 trainCost:  0.25370955 trainAccurancy:  0.921875 testCost:  0.3358624 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1756 trainCost:  0.30011514 trainAccurancy:  0.921875 testCost:  0.31574517 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1757 trainCost:  0.32832626 trainAccurancy:  0.8984375 testCost:  0.49512878 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1758 trainCost:  0.22119163 trainAccurancy:  0.9453125 testCost:  0.30154663 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1759 trainCost:  0.2153109 trainAccurancy:  0.9296875 testCost:  0.26961017 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1760 trainCost:  0.25603074 trainAccurancy:  0.8984375 testCost:  0.49192327 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1761 trainCost:  0.33923438 trainAccurancy:  0.921875 testCost:  0.30759582 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1762 trainCost:  0.25384745 trainAccurancy:  0.9296875 testCost:  0.35394755 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1763 trainCost:  0.26672333 trainAccurancy:  0.9140625 testCost:  0.2645829 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1764 trainCost:  0.3951891 trainAccurancy:  0.890625 testCost:  0.39853203 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1765 trainCost:  0.30841923 trainAccurancy:  0.9296875 testCost:  0.17871475 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1766 trainCost:  0.3168767 trainAccurancy:  0.921875 testCost:  0.45572913 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1767 trainCost:  0.23578869 trainAccurancy:  0.9375 testCost:  0.3623091 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1768 trainCost:  0.5011039 trainAccurancy:  0.84375 testCost:  0.19691142 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1769 trainCost:  0.46473992 trainAccurancy:  0.8515625 testCost:  0.36653107 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1770 trainCost:  0.32099217 trainAccurancy:  0.8984375 testCost:  0.2805925 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1771 trainCost:  0.36995333 trainAccurancy:  0.8828125 testCost:  0.28832304 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1772 trainCost:  0.29416394 trainAccurancy:  0.875 testCost:  0.49193993 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1773 trainCost:  0.44968736 trainAccurancy:  0.8828125 testCost:  0.5558875 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1774 trainCost:  0.52216715 trainAccurancy:  0.8828125 testCost:  0.36357537 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1775 trainCost:  0.3281425 trainAccurancy:  0.90625 testCost:  0.2647491 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1776 trainCost:  0.22476771 trainAccurancy:  0.9296875 testCost:  0.21293384 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1777 trainCost:  0.23762143 trainAccurancy:  0.9375 testCost:  0.3657146 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1778 trainCost:  0.41739026 trainAccurancy:  0.890625 testCost:  0.34447333 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1779 trainCost:  0.21783248 trainAccurancy:  0.90625 testCost:  0.32875502 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1780 trainCost:  0.46516916 trainAccurancy:  0.890625 testCost:  0.23239283 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1781 trainCost:  0.36066526 trainAccurancy:  0.8984375 testCost:  0.25830442 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1782 trainCost:  0.30465537 trainAccurancy:  0.90625 testCost:  0.41407675 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1783 trainCost:  0.42005223 trainAccurancy:  0.8828125 testCost:  0.3192845 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1784 trainCost:  0.32949385 trainAccurancy:  0.8984375 testCost:  0.26723772 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1785 trainCost:  0.2896594 trainAccurancy:  0.8984375 testCost:  0.32195425 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1786 trainCost:  0.21396144 trainAccurancy:  0.9296875 testCost:  0.36686108 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1787 trainCost:  0.39816967 trainAccurancy:  0.8671875 testCost:  0.3175946 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1788 trainCost:  0.42122993 trainAccurancy:  0.8828125 testCost:  0.39104468 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1789 trainCost:  0.31512982 trainAccurancy:  0.890625 testCost:  0.4527911 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1790 trainCost:  0.41196233 trainAccurancy:  0.875 testCost:  0.3987447 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1791 trainCost:  0.3192966 trainAccurancy:  0.9140625 testCost:  0.30437908 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1792 trainCost:  0.27430525 trainAccurancy:  0.921875 testCost:  0.3814385 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1793 trainCost:  0.4232407 trainAccurancy:  0.859375 testCost:  0.46028596 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1794 trainCost:  0.38806778 trainAccurancy:  0.9140625 testCost:  0.48559657 testAccurancy:  0.828125\n",
            "\n",
            "Iteration:  1795 trainCost:  0.2987693 trainAccurancy:  0.8984375 testCost:  0.33818164 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1796 trainCost:  0.37357014 trainAccurancy:  0.8828125 testCost:  0.3321259 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1797 trainCost:  0.3026999 trainAccurancy:  0.9140625 testCost:  0.22336087 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1798 trainCost:  0.32976073 trainAccurancy:  0.890625 testCost:  0.36423272 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1799 trainCost:  0.3712417 trainAccurancy:  0.875 testCost:  0.38677365 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1800 trainCost:  0.28059575 trainAccurancy:  0.8984375 testCost:  0.21980813 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1801 trainCost:  0.36440355 trainAccurancy:  0.890625 testCost:  0.3808868 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1802 trainCost:  0.37848145 trainAccurancy:  0.890625 testCost:  0.2852228 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1803 trainCost:  0.22468902 trainAccurancy:  0.9375 testCost:  0.26424998 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1804 trainCost:  0.28935814 trainAccurancy:  0.8984375 testCost:  0.3047891 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1805 trainCost:  0.30545586 trainAccurancy:  0.8984375 testCost:  0.3317594 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1806 trainCost:  0.3079027 trainAccurancy:  0.90625 testCost:  0.25746343 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1807 trainCost:  0.28099722 trainAccurancy:  0.90625 testCost:  0.16265911 testAccurancy:  0.953125\n",
            "\n",
            "Iteration:  1808 trainCost:  0.35698086 trainAccurancy:  0.921875 testCost:  0.38831568 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1809 trainCost:  0.16976674 trainAccurancy:  0.9296875 testCost:  0.3685635 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1810 trainCost:  0.25697052 trainAccurancy:  0.921875 testCost:  0.49267766 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1811 trainCost:  0.34713787 trainAccurancy:  0.90625 testCost:  0.26818943 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1812 trainCost:  0.3334023 trainAccurancy:  0.921875 testCost:  0.3016394 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1813 trainCost:  0.3209109 trainAccurancy:  0.9140625 testCost:  0.26611376 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1814 trainCost:  0.32377356 trainAccurancy:  0.8828125 testCost:  0.19127452 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1815 trainCost:  0.30769306 trainAccurancy:  0.90625 testCost:  0.24399705 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1816 trainCost:  0.29347956 trainAccurancy:  0.9140625 testCost:  0.39963034 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1817 trainCost:  0.29376677 trainAccurancy:  0.90625 testCost:  0.32858714 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1818 trainCost:  0.4691237 trainAccurancy:  0.8671875 testCost:  0.32438377 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1819 trainCost:  0.2049932 trainAccurancy:  0.921875 testCost:  0.2845618 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1820 trainCost:  0.38491094 trainAccurancy:  0.859375 testCost:  0.211411 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1821 trainCost:  0.2845455 trainAccurancy:  0.8984375 testCost:  0.4484641 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1822 trainCost:  0.2644681 trainAccurancy:  0.9375 testCost:  0.45693243 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1823 trainCost:  0.47630006 trainAccurancy:  0.8515625 testCost:  0.34070587 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1824 trainCost:  0.4243183 trainAccurancy:  0.875 testCost:  0.3361238 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1825 trainCost:  0.39900875 trainAccurancy:  0.8984375 testCost:  0.3437811 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1826 trainCost:  0.40264088 trainAccurancy:  0.875 testCost:  0.21314654 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1827 trainCost:  0.36691046 trainAccurancy:  0.890625 testCost:  0.33836412 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1828 trainCost:  0.32859218 trainAccurancy:  0.90625 testCost:  0.29573473 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1829 trainCost:  0.22081248 trainAccurancy:  0.953125 testCost:  0.36768073 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1830 trainCost:  0.2764965 trainAccurancy:  0.9296875 testCost:  0.4869355 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1831 trainCost:  0.26793253 trainAccurancy:  0.9296875 testCost:  0.5494656 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1832 trainCost:  0.18705347 trainAccurancy:  0.9296875 testCost:  0.24237227 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1833 trainCost:  0.32856503 trainAccurancy:  0.890625 testCost:  0.24142218 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1834 trainCost:  0.2603976 trainAccurancy:  0.9453125 testCost:  0.35235637 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1835 trainCost:  0.23464799 trainAccurancy:  0.921875 testCost:  0.4059812 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1836 trainCost:  0.42042702 trainAccurancy:  0.8984375 testCost:  0.26604205 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1837 trainCost:  0.50388485 trainAccurancy:  0.8515625 testCost:  0.37097335 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1838 trainCost:  0.38364854 trainAccurancy:  0.890625 testCost:  0.46585697 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1839 trainCost:  0.40806007 trainAccurancy:  0.875 testCost:  0.42365313 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1840 trainCost:  0.27297133 trainAccurancy:  0.921875 testCost:  0.3562538 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1841 trainCost:  0.19787918 trainAccurancy:  0.9375 testCost:  0.34131002 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1842 trainCost:  0.29957825 trainAccurancy:  0.9140625 testCost:  0.17357081 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1843 trainCost:  0.35411763 trainAccurancy:  0.890625 testCost:  0.2603426 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1844 trainCost:  0.31536493 trainAccurancy:  0.90625 testCost:  0.39712092 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1845 trainCost:  0.15673591 trainAccurancy:  0.9453125 testCost:  0.38634893 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1846 trainCost:  0.30057168 trainAccurancy:  0.9140625 testCost:  0.47165638 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1847 trainCost:  0.35984278 trainAccurancy:  0.8984375 testCost:  0.35142642 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1848 trainCost:  0.30530646 trainAccurancy:  0.890625 testCost:  0.32239395 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1849 trainCost:  0.2914318 trainAccurancy:  0.921875 testCost:  0.3981868 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1850 trainCost:  0.53347355 trainAccurancy:  0.859375 testCost:  0.3511774 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1851 trainCost:  0.27919757 trainAccurancy:  0.9296875 testCost:  0.43023127 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1852 trainCost:  0.1910121 trainAccurancy:  0.9609375 testCost:  0.39128104 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1853 trainCost:  0.2664338 trainAccurancy:  0.9140625 testCost:  0.37015438 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1854 trainCost:  0.21646854 trainAccurancy:  0.921875 testCost:  0.41874003 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1855 trainCost:  0.3294716 trainAccurancy:  0.890625 testCost:  0.39412868 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1856 trainCost:  0.23052329 trainAccurancy:  0.9296875 testCost:  0.27671945 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1857 trainCost:  0.2494405 trainAccurancy:  0.9140625 testCost:  0.38473883 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1858 trainCost:  0.2906756 trainAccurancy:  0.90625 testCost:  0.33389512 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1859 trainCost:  0.4473517 trainAccurancy:  0.8671875 testCost:  0.35037583 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1860 trainCost:  0.24608664 trainAccurancy:  0.921875 testCost:  0.3303372 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1861 trainCost:  0.28467518 trainAccurancy:  0.9296875 testCost:  0.4332256 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1862 trainCost:  0.48135573 trainAccurancy:  0.8671875 testCost:  0.44435325 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1863 trainCost:  0.25901282 trainAccurancy:  0.9140625 testCost:  0.3584422 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1864 trainCost:  0.43629363 trainAccurancy:  0.875 testCost:  0.4734095 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1865 trainCost:  0.29716468 trainAccurancy:  0.921875 testCost:  0.27162546 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1866 trainCost:  0.28797132 trainAccurancy:  0.9140625 testCost:  0.40475017 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1867 trainCost:  0.22612998 trainAccurancy:  0.9140625 testCost:  0.47151917 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1868 trainCost:  0.24658911 trainAccurancy:  0.921875 testCost:  0.3410635 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1869 trainCost:  0.19593883 trainAccurancy:  0.9453125 testCost:  0.29558697 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1870 trainCost:  0.3004947 trainAccurancy:  0.921875 testCost:  0.2510385 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1871 trainCost:  0.27815306 trainAccurancy:  0.90625 testCost:  0.4015048 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1872 trainCost:  0.38730603 trainAccurancy:  0.8671875 testCost:  0.31182867 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1873 trainCost:  0.26412088 trainAccurancy:  0.8984375 testCost:  0.3410824 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1874 trainCost:  0.2937513 trainAccurancy:  0.890625 testCost:  0.22548497 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1875 trainCost:  0.22497581 trainAccurancy:  0.9375 testCost:  0.43300545 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1876 trainCost:  0.33966085 trainAccurancy:  0.8984375 testCost:  0.34537345 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1877 trainCost:  0.25909248 trainAccurancy:  0.9140625 testCost:  0.3665286 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1878 trainCost:  0.3360438 trainAccurancy:  0.90625 testCost:  0.43376237 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1879 trainCost:  0.23637512 trainAccurancy:  0.9140625 testCost:  0.3001642 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1880 trainCost:  0.26067144 trainAccurancy:  0.9296875 testCost:  0.36290675 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1881 trainCost:  0.38928014 trainAccurancy:  0.84375 testCost:  0.43205604 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1882 trainCost:  0.33094075 trainAccurancy:  0.890625 testCost:  0.2595234 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1883 trainCost:  0.31849495 trainAccurancy:  0.90625 testCost:  0.23051052 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1884 trainCost:  0.27205932 trainAccurancy:  0.890625 testCost:  0.25695032 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1885 trainCost:  0.19024055 trainAccurancy:  0.9296875 testCost:  0.43697143 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1886 trainCost:  0.51762277 trainAccurancy:  0.8515625 testCost:  0.32167363 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1887 trainCost:  0.34920612 trainAccurancy:  0.9140625 testCost:  0.29728246 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1888 trainCost:  0.41112053 trainAccurancy:  0.8671875 testCost:  0.3324474 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1889 trainCost:  0.3037935 trainAccurancy:  0.8984375 testCost:  0.22923465 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1890 trainCost:  0.28729352 trainAccurancy:  0.890625 testCost:  0.45595145 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1891 trainCost:  0.27993047 trainAccurancy:  0.90625 testCost:  0.2878605 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1892 trainCost:  0.19505006 trainAccurancy:  0.9453125 testCost:  0.17097954 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1893 trainCost:  0.39495695 trainAccurancy:  0.875 testCost:  0.26589638 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1894 trainCost:  0.31176755 trainAccurancy:  0.90625 testCost:  0.36149192 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1895 trainCost:  0.399571 trainAccurancy:  0.90625 testCost:  0.19866286 testAccurancy:  0.9609375\n",
            "\n",
            "Iteration:  1896 trainCost:  0.48787063 trainAccurancy:  0.8828125 testCost:  0.3940849 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1897 trainCost:  0.242326 trainAccurancy:  0.9296875 testCost:  0.2860847 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1898 trainCost:  0.24995914 trainAccurancy:  0.9140625 testCost:  0.28293335 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1899 trainCost:  0.31698006 trainAccurancy:  0.9140625 testCost:  0.36972317 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1900 trainCost:  0.42963684 trainAccurancy:  0.90625 testCost:  0.4410686 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1901 trainCost:  0.2991757 trainAccurancy:  0.90625 testCost:  0.3845651 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1902 trainCost:  0.42346364 trainAccurancy:  0.8828125 testCost:  0.38072288 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1903 trainCost:  0.28737617 trainAccurancy:  0.8828125 testCost:  0.39857692 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1904 trainCost:  0.37219203 trainAccurancy:  0.8828125 testCost:  0.30539376 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1905 trainCost:  0.38887838 trainAccurancy:  0.8671875 testCost:  0.21069767 testAccurancy:  0.953125\n",
            "\n",
            "Iteration:  1906 trainCost:  0.45736548 trainAccurancy:  0.890625 testCost:  0.36779732 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1907 trainCost:  0.28390878 trainAccurancy:  0.9296875 testCost:  0.3751521 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1908 trainCost:  0.4811448 trainAccurancy:  0.84375 testCost:  0.41665995 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1909 trainCost:  0.45904735 trainAccurancy:  0.859375 testCost:  0.2571154 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1910 trainCost:  0.3170246 trainAccurancy:  0.8984375 testCost:  0.38635525 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1911 trainCost:  0.3271219 trainAccurancy:  0.8828125 testCost:  0.29646868 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1912 trainCost:  0.32104287 trainAccurancy:  0.8828125 testCost:  0.32346046 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1913 trainCost:  0.2911724 trainAccurancy:  0.90625 testCost:  0.28719765 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1914 trainCost:  0.52826035 trainAccurancy:  0.84375 testCost:  0.32876697 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1915 trainCost:  0.33928913 trainAccurancy:  0.921875 testCost:  0.6932986 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1916 trainCost:  0.40870038 trainAccurancy:  0.9140625 testCost:  0.27654815 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1917 trainCost:  0.20795938 trainAccurancy:  0.9140625 testCost:  0.37887037 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1918 trainCost:  0.22979724 trainAccurancy:  0.90625 testCost:  0.36362708 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1919 trainCost:  0.4003915 trainAccurancy:  0.8828125 testCost:  0.36848682 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1920 trainCost:  0.25577313 trainAccurancy:  0.9140625 testCost:  0.24460997 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1921 trainCost:  0.3354553 trainAccurancy:  0.921875 testCost:  0.38206628 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1922 trainCost:  0.27760825 trainAccurancy:  0.921875 testCost:  0.36884528 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1923 trainCost:  0.2505905 trainAccurancy:  0.9375 testCost:  0.5021875 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1924 trainCost:  0.23446113 trainAccurancy:  0.9296875 testCost:  0.26759183 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1925 trainCost:  0.35329258 trainAccurancy:  0.9296875 testCost:  0.38477767 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1926 trainCost:  0.33499137 trainAccurancy:  0.90625 testCost:  0.43824422 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1927 trainCost:  0.3889602 trainAccurancy:  0.8671875 testCost:  0.29397193 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1928 trainCost:  0.2907908 trainAccurancy:  0.8828125 testCost:  0.25568345 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1929 trainCost:  0.35205534 trainAccurancy:  0.90625 testCost:  0.22635669 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1930 trainCost:  0.33071664 trainAccurancy:  0.8984375 testCost:  0.49120766 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1931 trainCost:  0.22446518 trainAccurancy:  0.9453125 testCost:  0.28775722 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1932 trainCost:  0.40762448 trainAccurancy:  0.890625 testCost:  0.17808193 testAccurancy:  0.9609375\n",
            "\n",
            "Iteration:  1933 trainCost:  0.34421206 trainAccurancy:  0.8984375 testCost:  0.17690943 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1934 trainCost:  0.4876466 trainAccurancy:  0.8984375 testCost:  0.30809456 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1935 trainCost:  0.3861891 trainAccurancy:  0.8671875 testCost:  0.3341292 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1936 trainCost:  0.27908063 trainAccurancy:  0.875 testCost:  0.38605836 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1937 trainCost:  0.42374825 trainAccurancy:  0.8828125 testCost:  0.47612333 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1938 trainCost:  0.4262786 trainAccurancy:  0.859375 testCost:  0.25485557 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1939 trainCost:  0.27085817 trainAccurancy:  0.90625 testCost:  0.31167763 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1940 trainCost:  0.25342774 trainAccurancy:  0.9375 testCost:  0.3825248 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1941 trainCost:  0.24032238 trainAccurancy:  0.8828125 testCost:  0.25885504 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1942 trainCost:  0.3045166 trainAccurancy:  0.921875 testCost:  0.3245203 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1943 trainCost:  0.29143184 trainAccurancy:  0.921875 testCost:  0.5685665 testAccurancy:  0.8515625\n",
            "\n",
            "Iteration:  1944 trainCost:  0.42745382 trainAccurancy:  0.8671875 testCost:  0.2160212 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1945 trainCost:  0.3894307 trainAccurancy:  0.8984375 testCost:  0.34893468 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1946 trainCost:  0.4245202 trainAccurancy:  0.8828125 testCost:  0.3725489 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1947 trainCost:  0.20585474 trainAccurancy:  0.921875 testCost:  0.36556622 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1948 trainCost:  0.36394832 trainAccurancy:  0.8984375 testCost:  0.21719596 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1949 trainCost:  0.41399533 trainAccurancy:  0.859375 testCost:  0.4135034 testAccurancy:  0.859375\n",
            "\n",
            "Iteration:  1950 trainCost:  0.2988513 trainAccurancy:  0.890625 testCost:  0.20712036 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1951 trainCost:  0.24896973 trainAccurancy:  0.9296875 testCost:  0.26981056 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1952 trainCost:  0.20553546 trainAccurancy:  0.9296875 testCost:  0.31493792 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1953 trainCost:  0.3260905 trainAccurancy:  0.890625 testCost:  0.27919576 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1954 trainCost:  0.39355552 trainAccurancy:  0.890625 testCost:  0.35585913 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1955 trainCost:  0.35248002 trainAccurancy:  0.890625 testCost:  0.31030965 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1956 trainCost:  0.23868868 trainAccurancy:  0.9375 testCost:  0.41240588 testAccurancy:  0.8359375\n",
            "\n",
            "Iteration:  1957 trainCost:  0.29946685 trainAccurancy:  0.9140625 testCost:  0.4912375 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1958 trainCost:  0.34460554 trainAccurancy:  0.8828125 testCost:  0.34681052 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1959 trainCost:  0.22032346 trainAccurancy:  0.9453125 testCost:  0.3728499 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1960 trainCost:  0.25015417 trainAccurancy:  0.9296875 testCost:  0.18050335 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1961 trainCost:  0.3296516 trainAccurancy:  0.8984375 testCost:  0.45985356 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1962 trainCost:  0.14670083 trainAccurancy:  0.9765625 testCost:  0.2426466 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1963 trainCost:  0.27442944 trainAccurancy:  0.9140625 testCost:  0.26427424 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1964 trainCost:  0.26366952 trainAccurancy:  0.90625 testCost:  0.3287928 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1965 trainCost:  0.45314538 trainAccurancy:  0.875 testCost:  0.29186982 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1966 trainCost:  0.35198873 trainAccurancy:  0.8828125 testCost:  0.34932613 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1967 trainCost:  0.29170465 trainAccurancy:  0.921875 testCost:  0.49033502 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1968 trainCost:  0.3464251 trainAccurancy:  0.90625 testCost:  0.1689012 testAccurancy:  0.9609375\n",
            "\n",
            "Iteration:  1969 trainCost:  0.33686197 trainAccurancy:  0.875 testCost:  0.42001197 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1970 trainCost:  0.297489 trainAccurancy:  0.9140625 testCost:  0.29359668 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1971 trainCost:  0.29184124 trainAccurancy:  0.90625 testCost:  0.45164847 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1972 trainCost:  0.25524786 trainAccurancy:  0.921875 testCost:  0.33959234 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1973 trainCost:  0.33406138 trainAccurancy:  0.8671875 testCost:  0.31594887 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1974 trainCost:  0.41741258 trainAccurancy:  0.875 testCost:  0.37619063 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1975 trainCost:  0.2801274 trainAccurancy:  0.890625 testCost:  0.38782942 testAccurancy:  0.8671875\n",
            "\n",
            "Iteration:  1976 trainCost:  0.3460935 trainAccurancy:  0.875 testCost:  0.3502111 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1977 trainCost:  0.20057103 trainAccurancy:  0.9453125 testCost:  0.36101368 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1978 trainCost:  0.36715287 trainAccurancy:  0.8671875 testCost:  0.2658109 testAccurancy:  0.8984375\n",
            "\n",
            "Iteration:  1979 trainCost:  0.49466103 trainAccurancy:  0.84375 testCost:  0.26443678 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1980 trainCost:  0.34777766 trainAccurancy:  0.8828125 testCost:  0.38499475 testAccurancy:  0.8828125\n",
            "\n",
            "Iteration:  1981 trainCost:  0.32414076 trainAccurancy:  0.8828125 testCost:  0.2937221 testAccurancy:  0.9140625\n",
            "\n",
            "Iteration:  1982 trainCost:  0.24420112 trainAccurancy:  0.9296875 testCost:  0.22729677 testAccurancy:  0.953125\n",
            "\n",
            "Iteration:  1983 trainCost:  0.22679393 trainAccurancy:  0.9375 testCost:  0.53083026 testAccurancy:  0.84375\n",
            "\n",
            "Iteration:  1984 trainCost:  0.36217982 trainAccurancy:  0.890625 testCost:  0.40189338 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1985 trainCost:  0.23212974 trainAccurancy:  0.9375 testCost:  0.26003206 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1986 trainCost:  0.24793345 trainAccurancy:  0.9375 testCost:  0.2049831 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1987 trainCost:  0.24767241 trainAccurancy:  0.921875 testCost:  0.27093565 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1988 trainCost:  0.30603418 trainAccurancy:  0.921875 testCost:  0.25741917 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1989 trainCost:  0.4314227 trainAccurancy:  0.875 testCost:  0.23971446 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1990 trainCost:  0.29389602 trainAccurancy:  0.8828125 testCost:  0.21393865 testAccurancy:  0.9296875\n",
            "\n",
            "Iteration:  1991 trainCost:  0.21833661 trainAccurancy:  0.9296875 testCost:  0.29004633 testAccurancy:  0.921875\n",
            "\n",
            "Iteration:  1992 trainCost:  0.16442603 trainAccurancy:  0.953125 testCost:  0.16263509 testAccurancy:  0.96875\n",
            "\n",
            "Iteration:  1993 trainCost:  0.22270907 trainAccurancy:  0.9375 testCost:  0.2535887 testAccurancy:  0.9375\n",
            "\n",
            "Iteration:  1994 trainCost:  0.23757519 trainAccurancy:  0.9375 testCost:  0.4344514 testAccurancy:  0.875\n",
            "\n",
            "Iteration:  1995 trainCost:  0.28057456 trainAccurancy:  0.8984375 testCost:  0.3663113 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1996 trainCost:  0.395832 trainAccurancy:  0.8671875 testCost:  0.35185063 testAccurancy:  0.890625\n",
            "\n",
            "Iteration:  1997 trainCost:  0.26236457 trainAccurancy:  0.921875 testCost:  0.17314476 testAccurancy:  0.9453125\n",
            "\n",
            "Iteration:  1998 trainCost:  0.34007445 trainAccurancy:  0.9140625 testCost:  0.45471478 testAccurancy:  0.90625\n",
            "\n",
            "Iteration:  1999 trainCost:  0.30663607 trainAccurancy:  0.9140625 testCost:  0.3544506 testAccurancy:  0.8828125\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}