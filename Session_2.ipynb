{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadhajmosa/Machine-learning-labs/blob/AlessandroFornasier/Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSUExzC-ZBV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWZldyi-Zef",
        "colab_type": "text"
      },
      "source": [
        "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
        "## Session 1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75NLOuwKXSs",
        "colab_type": "text"
      },
      "source": [
        "#Session 2: 05.06 - 13:00 - 14:30 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUtGM-W_ehP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Intro:\n",
        "\n",
        "Tensorflow is a powerful framework for implementing and deploying large-scale deep learning models. Recently, it has been widely used in both reasearch and production. TF objective is to combine scale and flexibility.\n",
        "\n",
        "In the past session, we will learning the following:\n",
        "\n",
        "1. TF programming stack\n",
        "2. TF programming concepts including computatoin graphs, operations and sessions. \n",
        "3. Implementation of linear regression\n",
        "4. Implementation of feed-forward neural networks\n",
        "\n",
        "## TF stack:\n",
        "\n",
        "TensorFlow is a framework composed of two core building blocks — a library for defining computational graphs and a runtime for executing such graphs on a variety of different hardware\n",
        "\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/layers.png)\n",
        "\n",
        "\n",
        "Before goining into details about the stack, let us talk about computational graphs.\n",
        "\n",
        "### Computational Graphs\n",
        "\n",
        "A directed graph is a data structure consisting of nodes (vertices) and edges. It’s a set of vertices connected pairwise by directed edges.\n",
        "\n",
        "Graphs come in many shapes and sizes and are used to solve many real-life problems, such as representing networks including telephone networks, circuit networks, road networks, and even social networks. \n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*V6aYjD3AxDbEKYahkGqVQw.png)\n",
        "\n",
        "TensorFlow uses directed graphs internally to represent computations, and they call this data flow graphs (or computational graphs).\n",
        "\n",
        "The nodes in TF data flow graph mostly represents operations, variables and placeholders.\n",
        "\n",
        "Take for example the following operation:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "\n",
        "To create a computational graph out of this program, we create nodes for each of the operations in our program, along with the input variables a and b. In fact, a and b could be constants if they don’t change. If one node is used as the input to another operation we draw a directed arrow that goes from one node to another.\n",
        "\n",
        "The computational graph for this program might look like this:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*vPb9E0Yd1QUAD0oFmAgaOw.png)\n",
        "\n",
        "Operations create or manipulate data according to specific rules. In TensorFlow those rules are called Ops, short for operations. Variables on the other hand represent shared, persistent state that can be manipulated by running Ops on those variables.\n",
        "\n",
        "The questions now what are the advantages of representing operations as directed graphs: The main advantage of using directed graphs is the ability to do **parallelism** and what is called **dependency driving scheduling**. \n",
        "For example, consider again the follwoing code:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "At the most fundamental level, most computer programs are mainly composed of two things — primitive operations and an order in which these operations are executed, often sequentially, line by line. This means we would first multiply a and b and only when this expression was evaluated we would take their sum. Computational graphs on the otherhand, exclusively specify the dependencies across the operations.\n",
        "If we look at our computational graph we see that we could execute the multiplication and addition in parallel. That’s because these two operations do not depend on each other.\n",
        " So we can use the topology of the graph to drive the scheduling of operations and execute them in the most efficient manner, e.g. using multiple GPUs on a single machine or even distribute the execution across multiple machines.\n",
        " Another key advantage is portability. The graph is a language-independent representation of our code. So we can build the graph in Python, save the model (TensorFlow uses protocol buffers), and restore the model in a different language, say C++, if you want to go really fast.\n",
        " \n",
        " \n",
        "\n",
        "--------------------------------\n",
        "# References:\n",
        "\n",
        "https://medium.com/@d3lm/understand-tensorflow-by-mimicking-its-api-from-scratch-faa55787170d\n",
        "\n",
        "https://www.tensorflow.org/guide/extend/architecture\n",
        "\n",
        "https://www.tensorflow.org/guide/low_level_intro\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-GFJPVDnEwx",
        "colab_type": "text"
      },
      "source": [
        "# placeholder: tensors are feeded externaly for example inputs tensors + output tensors\n",
        "\n",
        "# variables : tensors represent the parameters of the network/graph ie. nn weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmSCbhtoJBs",
        "colab_type": "code",
        "outputId": "0b9a7b9e-a313-43f9-c133-b2ca0f30d56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "\n",
        "num_inputs = 3\n",
        "num_outputs = 4\n",
        "num_samples= 10\n",
        "# Training data\n",
        "x_gr = np.random.rand(num_samples,num_inputs)\n",
        "y_gr = np.random.rand(num_samples,num_outputs)\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "\n",
        "# weights \n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs,num_outputs ]))\n",
        "\n",
        "# model\n",
        "y_p = tf.matmul(x, w_1)\n",
        "\n",
        "\n",
        "# cost\n",
        "\n",
        "cost = tf.reduce_mean(tf.pow(y-y_p,2)) # \n",
        "\n",
        "# optimisation \n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(10):\n",
        "    \n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "    y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    print('predicted ', y_p_p)\n",
        "    print('real ', y_gr)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter:  0 cost:  0.6431273\n",
            "iter:  1 cost:  0.6418297\n",
            "iter:  2 cost:  0.64053476\n",
            "iter:  3 cost:  0.63924253\n",
            "iter:  4 cost:  0.6379529\n",
            "iter:  5 cost:  0.6366661\n",
            "iter:  6 cost:  0.6353822\n",
            "iter:  7 cost:  0.6341011\n",
            "iter:  8 cost:  0.6328229\n",
            "iter:  9 cost:  0.63154775\n",
            "predicted  [[ 0.6446512  -0.20713729  2.1476808  -1.4118636 ]\n",
            " [-0.12064859  0.07385027  0.5683408   0.07175648]\n",
            " [ 0.2990489  -0.06490395  1.4139478  -0.84314406]\n",
            " [ 0.62124217 -0.35937288  0.48357993 -0.37525392]\n",
            " [ 0.16393916 -0.1274146   0.4014422   0.12488011]\n",
            " [ 0.55494636 -0.29376802  0.8285301  -0.49846467]\n",
            " [ 0.3764549  -0.13861422  1.3277904  -0.7060356 ]\n",
            " [ 0.5982744  -0.45127493 -0.2668337   0.29937968]\n",
            " [-0.00946417  0.01262925  0.5629873  -0.01921529]\n",
            " [-0.13898507  0.05959349  0.37287554  0.23871103]]\n",
            "real  [[0.28427788 0.58920269 0.76702838 0.54495026]\n",
            " [0.10077242 0.44421162 0.08474814 0.63117015]\n",
            " [0.01157148 0.14526119 0.81988115 0.22006669]\n",
            " [0.09844534 0.24078169 0.60496677 0.87281952]\n",
            " [0.21494239 0.5097351  0.2950044  0.82441926]\n",
            " [0.41953509 0.88851562 0.17726813 0.39356474]\n",
            " [0.10843995 0.98875919 0.14346219 0.47484879]\n",
            " [0.40487958 0.82369397 0.90377852 0.66008465]\n",
            " [0.94767349 0.42496532 0.47597419 0.79391048]\n",
            " [0.89124593 0.46764663 0.18470877 0.82758744]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}