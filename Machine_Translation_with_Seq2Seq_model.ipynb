{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahmadhajmosa/Machine-learning-labs/blob/master/Machine_Translation_with_Seq2Seq_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOAwWeT0H1FL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bq-55gqyH29A"
   },
   "source": [
    "# Machine Translation with Seq2Seq model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5aSnf0IC9y"
   },
   "source": [
    "# sequence to sequence model\n",
    "\n",
    "\n",
    "![alt text](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2019/01/enc_dec_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LUuPZc7FICG1",
    "outputId": "a2e79e17-30d1-4cab-d7d9-e7a5a1858190"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1RSsaDqsIZg0"
   },
   "source": [
    "# Read the Data into our IDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psJK4BOqIW8K"
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzrVXpb3IgtI"
   },
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EovwSSgIIk9j"
   },
   "outputs": [],
   "source": [
    "#import urllib.request as urllib2\n",
    "#data = urllib2.urlopen('https://raw.githubusercontent.com/Apress/applied-natural-language-processing-w-python/master/data_etc/deu.txt')\n",
    "\n",
    "data = read_text(\"deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znjHR9p0JNz5"
   },
   "source": [
    "deu_eng = deu_eng[:50000,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-MMdTMhlJNAF",
    "outputId": "12795794-4e75-42d4-ba5c-649c999d4baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JD33znyLJp3t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "AOtrMyWOJmJl",
    "outputId": "48b8383e-8d9e-4c7a-81ab-132288e3583c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi', 'Hallo'],\n",
       "       ['Hi', 'Grüß Gott'],\n",
       "       ['Run', 'Lauf'],\n",
       "       ...,\n",
       "       ['At a moment when our economy is growing our businesses are creating jobs at the fastest pace since the 1990s and wages are starting to rise again we have to make some choices about the kind of country we want to be',\n",
       "        'In einem Moment in dem unsere Wirtschaft wächst unsere Betriebe so schnell neue Arbeitsplätze schaffen wie zuletzt in den 90ern und die Gehälter steigen müssen wir Entscheidungen treffen und uns überlegen was für ein Land wir sein wollen'],\n",
       "       ['If someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker In other words you dont really sound like a native speaker',\n",
       "        'Wenn jemand der deine Herkunft nicht kennt sagt dass du wie ein Muttersprachler sprichst bedeutet das dass man wahrscheinlich etwas an deiner Sprechweise bemerkt hat das erkennen ließ dass du kein Muttersprachler bist Mit anderen Worten du hörst dich nicht wirklich wie ein Muttersprachler an'],\n",
       "       ['If someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker In other words you dont really sound like a native speaker',\n",
       "        'Wenn jemand Fremdes dir sagt dass du dich wie ein Muttersprachler anhörst bedeutet das wahrscheinlich Er hat etwas an deinem Sprechen bemerkt dass dich als NichtMuttersprachler verraten hat Mit anderen Worten Du hörst dich nicht wirklich wie ein Muttersprachler an']],\n",
       "      dtype='<U302')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vks2ms25OArm"
   },
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "      deu_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "HU4MmkyzONVU",
    "outputId": "beda843f-4522-480c-efe1-d3d5cdaeb6d9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAYKklEQVR4nO3df7Cc1X3f8ffHyMYEGwzYKCBRiw5qGgzxDxSijmcaJaqLahxDU6iV4iA6mqr1EBtP6cQi/zTtlBkxnbEd7Ni1YhwEsQ0KtotqB6dU+E6bKQiDTUoAMyiGgooCwYAtOWOMyLd/7LlitVrdu4Kr3Xt336+Znd3n+zzn0TnSWX33PD/Ok6pCkqTXjLoCkqT5wYQgSQJMCJKkxoQgSQJMCJKkxoQgSQJMCGMhyfVJ/tOo6yFpYTMhSJIAE4IkqTEhLEBJ3pnkO0n2JLkZeH3XuvcluS/J80n+d5Jf6FpXSc7oWvZQkxaEJKcm+UqSv07yaJKPtPjvJtma5Ib2fXggyYqucu9K8t227o+T3GyfPzQTwgKT5HXAfwVuBE4E/hj4Z23du4AvAP8aOAn4HLAtydGjqa306iV5DfDfgD8HlgCrgY8mOa9t8n7gJuBNwDbg063c64CvAdfT+a58Gfinw6z7QmNCWHhWAq8FPllVL1bVLcC327p/BXyuqnZU1UtVtQV4oZWRFqpfBN5SVf+xqn5aVd8H/gBY29b/WVX9SVW9ROeH0ttbfCWwCLi2fVe+Ctw97MovJItGXQEdtlOB/1cHzkr4f9v7W4F1ST7cte51rYy0UL0VODXJ812xo4D/Rafv/1VX/G+A1ydZRP/vyhNHurILmSOEhWc3sCRJumJ/p70/AVxdVW/qev1MVX25rf8b4Ge6yv3sEOorvVpPAI/29Os3VtV7ZynX77ty2pGr5sJnQlh47gT2AR9JsijJrwPntnV/APybJL+UjmOTnJ/kjW39fcC/SHJUkjXALw+/+tJhuxv4UZKPJTmm9d+zkvziLOXuBF4Cfqt9Vy7g5e+K+jAhLDBV9VPg14HLgOeADwBfbevuoXMe4dNt3c623bQrgF8DngcuoXNyWprX2rmBXwPeATwKPAN8Hjh+lnLT35X1dPr8B4Gv0zmvpj7iA3IkTYokO4D/UlV/OOq6zEeOECSNrSS/nORn2yGjdcAvAN8cdb3mK68ykjTOfg7YCrwB+EvgoqraPdoqzV8eMpIkAR4ykiQ1C/aQ0Zvf/OZatmzZ/uUf//jHHHvssaOr0JDZ3rlx7733PlNVb5nzHR8Bk97nYTLbDHPb7hn7fFXN+qIzR8gtwPeAh4B/QGdukNuBR9r7CV3bX0XnkseHgfO64ucA97d11/LyIaujgZtbfAewbLY6nXPOOdXtW9/6Vk0S2zs3gHtqgO/AfHhNep+vmsw2V81tu2fq84MeMvo94JtV9ffpzBPyELAR2F5Vy4HtbZkkZ9KZY+RtwBrgM0mOavv5LLABWN5ea1p8PfBcVZ0BfAK4ZsB6SZLmyKwJIclxwD8EroPOzR5V9TxwAbClbbYFuLB9vgC4qapeqKpH6fzqPzfJKcBxVXVny1I39JSZ3tctwOqe280lSUfYIOcQ/i7w18AfJnk7cC+dO14XV7t8q6p2Jzm5bb8EuKur/K4We7F97o1Pl3mi7Wtfkh/Smb75me6KJNlAZ4TB4sWLmZqa2r9u7969ByyPO9sraa4NkhAWAe8CPlxVO5L8Hu3w0CH0+2VfM8RnKnNgoGozsBlgxYoVtWrVqv3rpqam6F4ed7ZX0lwb5BzCLmBXVe1oy7fQSRBPtcNAtPenu7bvnlFwKfBkiy/tEz+gTJu29njg2cNtjCTplZs1IVTVXwFPJPm5FloNPEjnyUTrWmwdcGv7vA1Ym+ToJKfTOXl8dzu8tCfJynZ+4NKeMtP7ugi4o51nkCQNyaD3IXwY+GJ7JN33gX9JJ5lsTbIeeBy4GKCqHkiylU7S2AdcXp3ZCgE+ROdxdscAt7UXdE5Y35hkJ52RwfSTkCRJQzJQQqiq+4AVfVatPsT2VwNX94nfA5zVJ/4TWkKRJI2GU1dIkoAFPHXFq7Vs4zcOWH5s0/kjqok0HPZ5zcYRgiQJMCFIkhoTgiQJMCFIkhoTgiQJMCFIkhoTgiQJMCFIkhoTgiQJMCFIfSV5LMn9Se5Lck+LnZjk9iSPtPcTura/KsnOJA8nOa8rfk7bz84k104/CbDNBnxzi+9IsmzYbZR6mRCkQ/uVqnpHVU1P7OhzxDXWTAjS4HyOuMbaxE5uJ82igP+epIDPtce3LujniF959r4DlhfiM6on9dnaw2q3CUHq791V9WT7T//2JN+bYdsF8Rzxy3pnO71k8LLzxaQ+W3tY7faQkdRHVT3Z3p8Gvgaci88R15gzIUg9khyb5I3Tn4F/DPwFPkdcY85DRtLBFgNfa+d4FwFfqqpvJvk2PkdcY8yEIPWoqu8Db+8T/wE+R1xjzENGkiTAhCBJakwIkiTAhCBJakwIkiTAhCBJagZKCE4FLEnj73BGCE4FLElj7NUcMnIqYEkaI4PeqexUwPPMpE0DPGntlUZh0ITgVMDzzKRNAzxp7ZVGYaBDRk4FLEnjb9aE4FTAkjQZBjlk5FTAkjQBZk0ITgUsSZPBO5UlSYAJQZLUmBAkSYAJQZLUmBAkSYAJQZLUmBAkSYAJQZLUmBAkSYAJQZLUmBAkSYAJQZLUDPqAHEkTYFnvg6M2nT+immgUHCFIkgATgnRISY5K8t0kX2/LJya5Pckj7f2Erm2vSrIzycNJzuuKn5Pk/rbu2vZwKNoDpG5u8R1Jlg27fVIvE4J0aFcAD3UtbwS2V9VyYHtbJsmZdB7q9DZgDfCZJEe1Mp8FNtB5cuDyth5gPfBcVZ0BfAK45sg2RZqdCUHqI8lS4Hzg813hC4At7fMW4MKu+E1V9UJVPQrsBM5tzxo/rqrubI+EvaGnzPS+bgFWT48epFExIUj9fRL4beBvu2KL27PBae8nt/gS4Imu7Xa12JL2uTd+QJmq2gf8EDhpbpsgHR6vMpJ6JHkf8HRV3Ztk1SBF+sRqhvhMZXrrsoHOIScWL17M1NTU/nV79+49YHk2V56974DlfmUH2WaUDrfN42JY7TYhSAd7N/D+JO8FXg8cl+SPgKeSnFJVu9vhoKfb9ruA07rKLwWebPGlfeLdZXYlWQQcDzzbW5Gq2gxsBlixYkWtWrVq/7qpqSm6l2dzWe8lpZccXHaQbUbpcNs8LobVbg8ZST2q6qqqWlpVy+icLL6jqj4IbAPWtc3WAbe2z9uAte3KodPpnDy+ux1W2pNkZTs/cGlPmel9XdT+jINGCNIwOUKQBrcJ2JpkPfA4cDFAVT2QZCvwILAPuLyqXmplPgRcDxwD3NZeANcBNybZSWdksHZYjZAOxYQgzaCqpoCp9vkHwOpDbHc1cHWf+D3AWX3iP6ElFGm+8JCRJAkwIUiSGhOCJAkwIUiSmoETghN9SdJ4O5wRghN9SdIYGyghONGXJI2/Qe9DmJ7o641dsQMm+krSPdHXXV3bTU/o9SIDTvSVZHqir2e6KzHseV3ms0mb02XS2iuNwqwJYT5N9DXseV3ms0mb02XS2iuNwiAjhHkz0Zck6ciZNSFU1VXAVQBthPDvquqDSf4zncm5NnHwRF9fSvJx4FRenujrpSR7kqwEdtCZ6OtTXWXWAXcyTyb66n3YOPjAcUnj7dXMZeREX5I0Rg4rITjRlySNL+9UliQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgTpIElen+TuJH+e5IEk/6HFT0xye5JH2vsJXWWuSrIzycNJzuuKn5Pk/rbu2iRp8aOT3NziO5IsG3Y7pV4mBOlgLwC/WlVvB94BrEmyEtgIbK+q5cD2tkySM+k8B/xtwBrgM0mOavv6LLABWN5ea1p8PfBcVZ0BfAK4ZhgNk2ZiQpB6VMfetvja9irgAmBLi28BLmyfLwBuqqoXqupRYCdwbpJTgOOq6s6qKuCGnjLT+7oFWD09epBGZdGoKyDNR+0X/r3AGcDvV9WOJIurajdAVe1OcnLbfAlwV1fxXS32YvvcG58u80Tb174kPwROAp7pqccGOiMMFi9ezNTU1P51e/fuPWB5Nleeve+A5X5lB9lmlA63zeNiWO02IUh9VNVLwDuSvAn4WpKzZti83y/7miE+U5neemwGNgOsWLGiVq1atX/d1NQU3cuzuWzjNw5YfuySg8sOss0oHW6bx8Ww2u0hI2kGVfU8MEXn2P9T7TAQ7f3pttku4LSuYkuBJ1t8aZ/4AWWSLAKOB549Io2QBuQIQeqR5C3Ai1X1fJJjgH9E56TvNmAdsKm939qKbAO+lOTjwKl0Th7fXVUvJdnTTkjvAC4FPtVVZh1wJ3ARcEc7zzA0y3pGA5IJQTrYKcCWdh7hNcDWqvp6kjuBrUnWA48DFwNU1QNJtgIPAvuAy9shJ4APAdcDxwC3tRfAdcCNSXbSGRmsHUrLpBmYEKQeVfV/gHf2if8AWH2IMlcDV/eJ3wMcdP6hqn5CSyjSfOE5BEkSMEBC8K5NSZoMg4wQvGtTkibArAnBuzYlaTIMdFJ5Eu/a7F3fb5tRmrQ7NietvdIoDJQQJuGuTe7/cc8WB//VzKe7Niftjs1Ja680Cod1lZF3bUrS+BrkKqO3tJEBXXdtfo+X77SEg+/aXNuuHDqdl+/a3A3sSbKynR+4tKfM9L5GctemJE26QQ4ZedemJE2AWROCd21K0mTwTmVJEmBCkCQ1JgRJEmBCkCQ1JgRJEmBCkCQ1JgRJEmBCkCQ1JgRJEmBCkCQ1JgRJEmBCkCQ1JgRJEmBCkCQ1JgRJEmBCkCQ1JgRJEmBCkCQ1JgRJEmBCkCQ1JgSpR5LTknwryUNJHkhyRYufmOT2JI+09xO6ylyVZGeSh5Oc1xU/J8n9bd21SdLiRye5ucV3JFk27HZKvUwI0sH2AVdW1c8DK4HLk5wJbAS2V9VyYHtbpq1bC7wNWAN8JslRbV+fBTYAy9trTYuvB56rqjOATwDXDKNh0kxMCFKPqtpdVd9pn/cADwFLgAuALW2zLcCF7fMFwE1V9UJVPQrsBM5NcgpwXFXdWVUF3NBTZnpftwCrp0cP0qgsGnUFpPmsHcp5J7ADWFxVu6GTNJKc3DZbAtzVVWxXi73YPvfGp8s80fa1L8kPgZOAZ3r+/A10RhgsXryYqamp/ev27t17wPJsrjx738DbTjuc/Q/D4bZ5XAyr3SYE6RCSvAH4CvDRqvrRDD/g+62oGeIzlTkwULUZ2AywYsWKWrVq1f51U1NTdC/P5rKN3xh422mPXTL4/ofhcNs8LobVbg8ZSX0keS2dZPDFqvpqCz/VDgPR3p9u8V3AaV3FlwJPtvjSPvEDyiRZBBwPPDv3LZEGN2tC8IoLTZrWL68DHqqqj3et2gasa5/XAbd2xde2fnw6nZPHd7fDS3uSrGz7vLSnzPS+LgLuaOcZpJEZZITgFReaNO8GfhP41ST3tdd7gU3Ae5I8ArynLVNVDwBbgQeBbwKXV9VLbV8fAj5P50TzXwK3tfh1wElJdgL/lvb9kUZp1nMI7VfO9Im0PUm6r7hY1TbbAkwBH6Prigvg0dbhz03yGO2KC4Ak01dc3NbK/G7b1y3Ap5PEX0wahar6M/of4wdYfYgyVwNX94nfA5zVJ/4T4OJXUU1pzh3WSWWvuBh8/0fapF1tMWntlUZh4ITgFRfz64qLSbvaYtLaK43CQFcZecWFJI2/Qa4y8ooLSZoAgxwymr7i4v4k97XY79C5wmJrkvXA47QTZFX1QJLpKy72cfAVF9cDx9A5mdx9xcWN7QT0s3SuUpIkDdEgVxl5xYUkTQDvVJYkASYESVJjQpAkASYESVJjQpAkASYESVJjQpAkASYESVJjQpAkASYESVJjQpAkASYESVJjQpAkASYESVJjQpAkASYESVJjQpAkAYM9QlPSArNs4zdGXQUtQI4QJEmACUGS1JgQJEmACUGS1HhSWdLA+p2sfmzT+SOoiY4EE8Kr4JdD486rlSaLh4ykPpJ8IcnTSf6iK3ZiktuTPNLeT+had1WSnUkeTnJeV/ycJPe3ddcmSYsfneTmFt+RZNkw2yf1Y0KQ+rseWNMT2whsr6rlwPa2TJIzgbXA21qZzyQ5qpX5LLABWN5e0/tcDzxXVWcAnwCuOWItkQZkQpD6qKr/CTzbE74A2NI+bwEu7IrfVFUvVNWjwE7g3CSnAMdV1Z1VVcANPWWm93ULsHp69CCNyqznEJJ8AXgf8HRVndViJwI3A8uAx4B/XlXPtXVX0fn18xLwkar60xY/h86vrmOAPwGuqKpKcjSdL8o5wA+AD1TVY3PWwjnk8dSJt7iqdgNU1e4kJ7f4EuCuru12tdiL7XNvfLrME21f+5L8EDgJeKb7D0yygc4Ig8WLFzM1NbV/3d69ew9Y7nbl2fsOu3Gv1KHqcCTM1OZxNqx2D3JS+Xrg03T+0542PXTelGRjW/5Yz9D5VOB/JPl7VfUSLw+d76KTENYAt9E1dE6yls7Q+QNz0bhp/keuI6zfL/uaIT5TmQMDVZuBzQArVqyoVatW7V83NTVF93K3y4bY5x+7pH8djoSZ2jzOhtXuWQ8ZOXSW9nuq9WXa+9Mtvgs4rWu7pcCTLb60T/yAMkkWAcdz8PdMGqpXetnp0IfO4PC526QNnedJe7cB64BN7f3WrviXknyczsh4OXB3Vb2UZE+SlcAO4FLgUz37uhO4CLij/ViSRmau70M4YkNncPjcbdKGzsNub5IvA6uANyfZBfx7Oolga5L1wOPAxQBV9UCSrcCDwD7g8naYFOBDvHzu7Lb2ArgOuDHJTjojg7VDaJY0o1eaEJ5KckobHczV0HmXQ2fNF1X1G4dYtfoQ218NXN0nfg9wVp/4T2gJRZovXullp9PDXTh46Ly23XRzOi8PnXcDe5KsbOcHLu0pM70vh86SNCKDXHbq0FmSJsCsCcGhsyRNBu9UliQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBJgRJUmNCkCQBAzxTWa/Oso3fOGD5sU3nj6gmGme9/WyUf7Z9fOEyIcyxUX4xJenV8JCRJAlwhCBpCDystDA4QpAkAY4QJM0xz6MtXGOZEOyQknT4PGQkSQLm0QghyRrg94CjgM9X1aYRV+mIGGT04gm3yTEp/V4Lw7xICEmOAn4feA+wC/h2km1V9eBoayYdOZPc7/1hND/Ni4QAnAvsrKrvAyS5CbgAGPsvRj+DfFmuX3PsEGqiI8x+P4N+34Mrz97HZV1xk8bcmi8JYQnwRNfyLuCXejdKsgHY0Bb3Jnm4a/WbgWeOWA3nmV+5ZrLay5H7933rEdjnoGbt9/b5A32kp825ZoSVGa65/Lc+ZJ+fLwkhfWJ1UKBqM7C57w6Se6pqxVxXbL6yvWNh1n5vnz/QJLYZhtfu+XKV0S7gtK7lpcCTI6qLNCz2e80r8yUhfBtYnuT0JK8D1gLbRlwn6Uiz32temReHjKpqX5LfAv6UzuV3X6iqBw5zN32H1WPM9i5wc9Dvx+7vZACT2GYYUrtTddCheknSBJovh4wkSSNmQpAkAWOQEJKsSfJwkp1JNo66PnMtyWlJvpXkoSQPJLmixU9McnuSR9r7CaOu61xKclSS7yb5else6/YejnHv89Mmte/D6Pr/gk4IXbf+/xPgTOA3kpw52lrNuX3AlVX188BK4PLWxo3A9qpaDmxvy+PkCuChruVxb+9AJqTPT5vUvg8j6v8LOiHQdet/Vf0UmL71f2xU1e6q+k77vIdOJ1lCp51b2mZbgAtHU8O5l2QpcD7w+a7w2Lb3MI19n582iX0fRtv/F3pC6Hfr/5IR1eWIS7IMeCewA1hcVbuh88UBTh5dzebcJ4HfBv62KzbO7T0cE9Xnp01Q34cR9v+FnhAGmvJiHCR5A/AV4KNV9aNR1+dISfI+4OmqunfUdZmnJqbPT5uUvg+j7//z4sa0V2Eibv1P8lo6X4gvVtVXW/ipJKdU1e4kpwBPj66Gc+rdwPuTvBd4PXBckj9ifNt7uCaiz0+bsL4PI+7/C32EMPa3/icJcB3wUFV9vGvVNmBd+7wOuHXYdTsSquqqqlpaVcvo/HveUVUfZEzb+wqMfZ+fNml9H0bf/xf0CGGOpryY794N/CZwf5L7Wux3gE3A1iTrgceBi0dUv2GZtPb2NSF9fpp9/2VDabNTV0iSgIV/yEiSNEdMCJIkwIQgSWpMCJIkwIQgSWpMCJIkwIQgSWr+PxMBMQOxyz/nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARZ90ZFVOQG8"
   },
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "      tokenizer = Tokenizer()\n",
    "      tokenizer.fit_on_texts(lines)\n",
    "      return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yyz7RNDHOSze",
    "outputId": "09710dbd-fed4-451f-fccc-f49691d8e616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 15610\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "COPesm56Oge4",
    "outputId": "bb48a7b9-5a30-402c-a6c4-145cca506a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutsch Vocabulary Size: 33312\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutsch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atwmdWuVOqks"
   },
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xW66yhpOrt4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mtRnbTHXO2wp"
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okENg3RqO9xY"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, RepeatVector, Dense\n",
    "\n",
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "      model.add(LSTM(units))\n",
    "      model.add(RepeatVector(out_timesteps))\n",
    "      model.add(LSTM(units, return_sequences=True))\n",
    "      model.add(Dense(out_vocab, activation='softmax'))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "oMzBz4CaPw8P",
    "outputId": "8a48c991-0ed6-48ad-f1d4-a889edc3974d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Stefano Probst\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# model compilation\n",
    "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKcsY1jRP0Ve"
   },
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "WboEG9PmP5L1",
    "outputId": "55a76c97-42b7-4f40-e151-a7394da10d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Stefano Probst\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Stefano Probst\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 108680 samples, validate on 27170 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(512, 512), b.shape=(512, 512), m=512, n=512, k=512\n\t [[{{node lstm_1/while/MatMul_6}}]]\n\t [[{{node loss/mul}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-212595acfee8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n\u001b[0;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                     verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machine-learning-lab\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(512, 512), b.shape=(512, 512), m=512, n=512, k=512\n\t [[{{node lstm_1/while/MatMul_6}}]]\n\t [[{{node loss/mul}}]]"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.24_jan_19'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TMUasvLrP9Bp"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLGYX_UgQH0T"
   },
   "outputs": [],
   "source": [
    "model = load_model('model.h1.24_jan_19')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYWfGSqoQMLA"
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCMTd0NoQMji"
   },
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "       temp = []\n",
    "       for j in range(len(i)):\n",
    "            t = get_word(i[j], eng_tokenizer)\n",
    "            if j > 0:\n",
    "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                     temp.append('')\n",
    "                else:\n",
    "                     temp.append(t)\n",
    "            else:\n",
    "                   if(t == None):\n",
    "                          temp.append('')\n",
    "                   else:\n",
    "                          temp.append(t) \n",
    "\n",
    "       preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gySU0ko6QP9F"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\n",
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfX7W8a1QF8v"
   },
   "source": [
    "model = load_model('model.h1.24_jan_19')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6Zu0ECdIed4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "text",
    "id": "pU6NBCq-H2Ln"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin :D\n"
     ]
    }
   ],
   "source": [
    "print(\"Fin :D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Machine Translation with Seq2Seq model.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
