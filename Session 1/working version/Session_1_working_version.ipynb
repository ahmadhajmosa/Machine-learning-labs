{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 1 working version.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSUExzC-ZBV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPF3d47OoCZE",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 40
        },
        "outputId": "15689bae-5525-4ff6-9756-0bace5d3a37d"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26511acb-08d6-482d-bf77-9fc1510cb163\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-26511acb-08d6-482d-bf77-9fc1510cb163\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWZldyi-Zef",
        "colab_type": "text"
      },
      "source": [
        "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
        "## Session 1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1T4XAd1_fJk",
        "colab_type": "text"
      },
      "source": [
        "### Course Plan:\n",
        "\n",
        "This lab is a continuation to the Machine learning lecture, the objective of this course is to learn how to model and implement neural networks using deep learning python frameworks: \n",
        "1. Tensorflow\n",
        "2. Keras\n",
        "3. Pytorch\n",
        "\n",
        "Useing these frameworks, we will go through the following topics and use cases:\n",
        "\n",
        "#### Session 1: 05.06 - 09:00 - 11:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 09:00 - 10:30:\n",
        ">1. Introduction to deep learning frameworks\n",
        "2. Deep learning in Numpy\n",
        "\n",
        ">#### Break:  05.06 - 10:30 - 10:45\n",
        ">#### Assignment:  05.06 - 10:45 - 11:45 : \n",
        ">* Implementation of backprop using numpy\n",
        "\n",
        ">1. Tensorflow backround \n",
        "2. Implementation of feedforward neural networks using Tensorflow\n",
        "\n",
        ">#### Break:  05.06 - 10:00 - 10:15\n",
        ">#### Assignment:  05.06 - 10:15 - 10:45 : \n",
        "  \n",
        "  >* play around with tensorflow and build your first neural network\n",
        "\n",
        "\n",
        "\n",
        "#### Session 2:  05.06 - 11:00 - 12:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 11:00 - 12:00:\n",
        "\n",
        "\n",
        ">3. Implementation of CNN useing Tensorflow\n",
        "4. Tensorboard\n",
        "\n",
        ">#### Break:  05.06 - 12:00 - 13:00\n",
        ">#### Assignment:  05.06 - 13:00 - 13:30 :\n",
        "\n",
        "\n",
        " #### Session 3:  05.06 - 13:30 - 15:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 13:00 - 14:00:\n",
        "\n",
        ">5. Introduction to Keras\n",
        "6. CNN using Keras\n",
        ">#### Break:  05.06 - 14:00 - 14:15\n",
        ">#### Assignment:  05.06 - 14:15 - 14:45 :\n",
        "\n",
        " #### Session 4:  05.06 - 15:00 - 16:30  :\n",
        "\n",
        ">#### Presentation:  05.06 - 15:00 - 15:45:\n",
        "\n",
        ">7. LSTM using Keras\n",
        "\n",
        ">#### Break:  05.06 - 15:45 - 16:00\n",
        ">#### Assignment:  05.06 - 16:00 - 16:30 :\n",
        "\n",
        "\n",
        "8. VGG, Inceptaion, ResNet models using Keras\n",
        "\n",
        "9. Autoencoders using Keras\n",
        "\n",
        "10. Sequence to Sequence Models using Keras \n",
        "\n",
        "11. Attention Mechanism using Keras\n",
        "12. GANS \n",
        "13. Introduction to Pytorch\n",
        "14. Machine translation using Pytorch\n",
        "15. Introduction to Allennlp\n",
        "16. Deep Reinforcment Learning using Keras\n",
        "17. Use case: building self driving car using Unity and tensorflow\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75NLOuwKXSs",
        "colab_type": "text"
      },
      "source": [
        "#Session 1: 05.06 - 09:00 - 11:00 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUtGM-W_ehP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Deep learning frameworks:\n",
        "\n",
        "In the past decade, many deep learning frameworks have been developed to ease and scale the research and development of AI. Many big technology providers including Google, IBM, Microsoft and Facebook have entered the race to provide the best and most popluar frameworks. To enter such a race, mainly four features are considered in the provided framework:\n",
        "\n",
        "1. Uses a popular language for data scientists (Python, Scale, C++ or R)\n",
        "2. Flexible in creating and adjusting deep learning architectures -> Functional programming\n",
        "3. Easy for computing gradients\n",
        "4. Interface with GPUs for parallel processing\n",
        "\n",
        "\n",
        "In the following we see the most popular provided deep learning frameworks with their providers\n",
        "https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*dYjDEI0mLpsCOySKUuX1VA.png)\n",
        "\n",
        "## Tensorflow\n",
        "TensorFlow is the undisputed heavyweight champion. It has the most GitHub activity, Google searches, Medium articles, books on Amazon and ArXiv articles. It also has the most developers using it and is listed in the most online job descriptions. TensorFlow is backed by Google.\n",
        "\n",
        "## Keras\n",
        "Keras has an “API designed for human beings, not machines.” It is the second most popular framework in nearly all evaluation areas. Keras sits on top of TensorFlow, Theano, or CNTK. Start with Keras if you are new to deep learning.\n",
        "\n",
        "## Pytorch\n",
        "\n",
        "PyTorch is the third most popular overall framework and the second most popular stand-alone framework. It is younger than TensorFlow and has grown rapidly in popularity. It allows customization that TensorFlow does not. It has the backing of Facebook.\n",
        "\n",
        "## Theano\n",
        "\n",
        "Theano was developed at the University of Montreal in 2007 and is the oldest significant Python deep learning framework. It has lost much of its popularity and its leader stated that major releases were no longer on the roadmap. However, updates continue to be made. Theano still the fifth highest scoring framework.\n",
        "\n",
        "# Comparision:\n",
        "\n",
        "## Criteria 1: Online Job Listings\n",
        "\n",
        "TensorFlow is the clear winner when it comes to frameworks mentioned in job listings. Learn it if you want a job doing deep learning.\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*kA8dIgRqLdWgKgs2sd7clA.png)\n",
        "\n",
        "## Criteria 2: Usage\n",
        "\n",
        "\n",
        "Keras showed a surprising amount of use — nearly as much as TensorFlow. It’s interesting that US employers are overwhelmingly looking for TensorFlow skills, when — at least internationally — Keras is used almost as frequently.\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*6b2Tm0oFr99zKaxkr4g52w.png)\n",
        "  \n",
        "  \n",
        "## Criteria 4: Google Search Activity\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*wpA6C9x_Nri42EzbqnS1fQ.png)\n",
        "\n",
        "## Criteria 5: Medium Articles\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*Y1cJUgZTC3u_hU1lmdsroQ.png)\n",
        "\n",
        "\n",
        "## Criteria 6: Amazon Books\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*mtP47q29T6agdkEoJcCw-w.png)\n",
        "\n",
        "## Criteria 7 : ArXiv Articles\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*7jdNoNkGlx_1EnfevQXRvw.png)\n",
        "  \n",
        "## Criteria 8: GitHub Activity\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*eOOYV3C5klsuVBMX31ngxw.png)\n",
        "  \n",
        " --------------------------------\n",
        " \n",
        "\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3V8ztAKDCg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "Before we jump into Tensorflow, we will implemented our first neural network model using Python Numpy package. NumPy is the fundamental package for scientific computing with Python, such as:\n",
        "\n",
        "1. Linear Algebra\n",
        "2. Statistics\n",
        "3. Calculus\n",
        "\n",
        "## A brief intro to Numpy operations:\n",
        "\n",
        "1. Creating a Vector:\n",
        "Here we use Numpy to create a 1-D Array which we then call a vector.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTf7M4r7Lgj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b4f63294-97ab-441d-a06b-452fa3f348dc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "v1 = np.zeros((1,100))\n",
        "#display(v1)\n",
        "v2 = np.zeros((1,100))\n",
        "#display(v2)\n",
        "v2.shape\n",
        "# transport\n",
        "v2.T.shape\n",
        "v4 = np.eye((4))\n",
        "#display(v4)\n",
        "v5 = np.random.randn(100,1) # normal random generator\n",
        "v6 = np.random.rand(100,1) # uniform random generator\n",
        "#display(v6)\n",
        "#display(v5)\n",
        "display('mean of randn:',v5.mean())\n",
        "display('std of randn:',v5.std())\n",
        "\n",
        "display('std of randn:',v6.min())\n",
        "display('std of randn:',v6.min())\n",
        "\n",
        "display('mean of randn:',v6.max())\n",
        "display('std of randn:',v6.max())\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'mean of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.03790170488208862"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1.0044544036633825"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.004692792117357847"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.004692792117357847"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'mean of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9804700440846881"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9804700440846881"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYFjSo0OLqA3",
        "colab_type": "text"
      },
      "source": [
        "2. Creating a Matrix\n",
        "We Create a 2-D Array in Numpy and call it a Matrix. It contains 2 rows and 3 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJlDBq5rLmA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "31b5118a-9d12-4c4f-a7b6-a4e97282a8f0"
      },
      "source": [
        "m1 = np.zeros((2,3))\n",
        "#display(m1)\n",
        "\n",
        "matrix = np.array([[1,2,3],[4,5,6]])\n",
        "display(matrix)\n",
        "display('matrix shape:', matrix.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'matrix shape:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv99hZqULygH",
        "colab_type": "text"
      },
      "source": [
        "3. Selecting Elements\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLQlxFzkPrKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6184cfa4-8f2f-4fab-f2f0-51bef601a205"
      },
      "source": [
        "display(matrix[0,0]) # first row first col\n",
        "display(matrix[0,-1]) # first row last col\n",
        "display(matrix[0,-2]) # first row second last col\n",
        "display(matrix[0,1:]) # first row second last col\n",
        "display(matrix[0,:-1]) # first row second from col 0 -col 1\n",
        "display(matrix[0,0:2]) # first row second from col 0 -col 1"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO3vTGEKQhm7",
        "colab_type": "text"
      },
      "source": [
        "4. Describing a Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8bDjBhhQpg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "41929ad0-fede-4f5c-f4f5-6a6f73457b0c"
      },
      "source": [
        "print(matrix.shape) # view the number of rows and columns\n",
        "print(matrix.size) # view the number of elements (rows*columns)\n",
        "print(matrix.ndim) # view the nubmer of dimensions (2 in this case)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n",
            "6\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKISvY8kQtA0",
        "colab_type": "text"
      },
      "source": [
        "5. Finding the max and min values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abPJd0JrQ4mM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9aa9818c-cefb-4d65-d57a-dd341ee94bd3"
      },
      "source": [
        "#display(matrix)\n",
        "matrix.min(axis=0) # view the min element of row\n",
        "\n",
        "np.min(matrix, axis=1)\n",
        "np.max(matrix, axis=1)\n",
        "#display('arg', np.argmax(matrix, axis=0))\n",
        "#display('max', np.max(matrix, axis=0))\n",
        "\n",
        "np.argwhere(matrix == np.max(matrix))\n",
        "np.argwhere(matrix < np.max(matrix))\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [0, 1],\n",
              "       [0, 2],\n",
              "       [1, 0],\n",
              "       [1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qm64s_eR0zQ",
        "colab_type": "text"
      },
      "source": [
        "6. Reshaping Arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwepq7h_SBBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1030e610-700d-41a0-93a0-e3ce83b75403"
      },
      "source": [
        "matrix.shape\n",
        "matrix.reshape((3,2))\n",
        "matrix.reshape((6,1))\n",
        "matrix.reshape((1,6))\n",
        "matrix.reshape((1,2,3)) # dim 0 size = 1, dim 1=2, dim \n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 2, 3],\n",
              "        [4, 5, 6]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJU3xABuVem_",
        "colab_type": "text"
      },
      "source": [
        "7. Calculating Dot Products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPKg382VVivy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4ed8d478-7c46-40fe-bd85-762702428206"
      },
      "source": [
        "# create matrix\n",
        "vector_1 = np.array([1,2,3])\n",
        "vector_2 = np.array([4,5,6])\n",
        "\n",
        "print(np.dot(vector_1,vector_2))\n",
        "# alternatively you can use @ to calculate dot products\n",
        "\n",
        "\n",
        "print(np.dot(vector_1 @ vector_2))\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-2a3acdddd5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_1\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mvector_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Required argument 'b' (pos 2) not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB-jK7jEXY7F",
        "colab_type": "text"
      },
      "source": [
        "##Linear regression in Numpy:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Write the numpy code for the following model:\n",
        "\n",
        "$Y=WX+B$\n",
        "\n",
        "where $X$ is 3x10 matrix:  10 samples and 3 features\n",
        "\n",
        "$Y$ is 4x10 matrix: 10 samples and 4 outputs\n",
        "\n",
        "$W$ is the weights matrix with the shape 4x3: connecting 3 inputs to 4 outputs\n",
        "\n",
        "$b$ is a vector with a size 4 ( one bias per output)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EtM5LVtWCpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3f18034c-8435-45c0-eb5d-f8efd474c1b4"
      },
      "source": [
        "# inputs of features matrix\n",
        "\n",
        "X = np.random.rand(3,10)\n",
        "display('shape of X', X.shape)\n",
        "\n",
        "# Weights matrix\n",
        "\n",
        "W = np.random.rand(4,3)\n",
        "\n",
        "# bias\n",
        "\n",
        "b = np.zeros((4,1))\n",
        "\n",
        "# regression model\n",
        "\n",
        "Y = np.dot(W,X) + b\n",
        "display(Y)\n",
        "display('Y:', Y.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'shape of X'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3, 10)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.59893439, 0.37267232, 0.66005716, 0.54656477, 0.29742939,\n",
              "        0.30503663, 0.46318925, 0.43961454, 0.53544335, 0.64563852],\n",
              "       [0.68464208, 0.47292609, 0.81835809, 0.63552962, 0.39686407,\n",
              "        0.30724372, 0.6005141 , 0.47477745, 0.72175546, 0.8254916 ],\n",
              "       [0.87024378, 0.46288787, 0.90203691, 0.75251555, 0.36680517,\n",
              "        0.44797393, 0.70482911, 0.69303398, 0.8063879 , 0.92677663],\n",
              "       [0.64568712, 0.25485598, 0.56281747, 0.53137801, 0.17321787,\n",
              "        0.3923898 , 0.43135942, 0.56878687, 0.45103594, 0.56062562]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Y:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(4, 10)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMIoucH9hFfr",
        "colab_type": "text"
      },
      "source": [
        "## One neuron model in numpy:\n",
        "\n",
        "A single neuron has multiple inputs and one output, in addition to the linear regression model, we need to add non linearity through an activation function:\n",
        "\n",
        "$Y= f(WX+B)$\n",
        "\n",
        "where $X$ is n x m matrix:  m samples and n features/inputs\n",
        "\n",
        "$f(g)= \\frac{1}{1+\\exp(-g)}$  is a sigmoid acitavation function\n",
        "\n",
        "$Y$ is nh1 x m matrix: m samples and ny outputs\n",
        "\n",
        "$W$ is the weights matrix with the shape nh1 x n: connecting 3 inputs to 4 outputs\n",
        "\n",
        "$b$ is a vector with a size nh1 ( one bias per output)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qry1JDGEiLmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        },
        "outputId": "3dcaecb7-4b44-48d7-f7c8-f74bb0fd295b"
      },
      "source": [
        "num_inputs = 3\n",
        "num_outputs = 4\n",
        "num_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmod function)\n",
        "\n",
        "X = np.random.rand(num_inputs,num_samples)\n",
        "\n",
        "# Generate a random weights \n",
        "\n",
        "W = np.random.rand(num_outputs, num_inputs)\n",
        "\n",
        "# Generate a rondom bias\n",
        "b = np.zeros((num_outputs,1))\n",
        "\n",
        "# calculate y\n",
        "\n",
        "Y = f(np.dot(W,X) + b)\n",
        "display(Y)\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.66154576, 0.83866781, 0.71215531, 0.81212233, 0.81956725,\n",
              "        0.7249126 , 0.72458121, 0.77342191, 0.81527662, 0.57207404,\n",
              "        0.77693399, 0.77133045, 0.69516122, 0.63177557, 0.76492437,\n",
              "        0.61498484, 0.70432857, 0.82406645, 0.73226071, 0.82952944,\n",
              "        0.68876137, 0.72633858, 0.80781258, 0.75508194, 0.76158457,\n",
              "        0.75637852, 0.80837369, 0.65141928, 0.73332112, 0.79262832,\n",
              "        0.61442165, 0.77112296, 0.72271607, 0.79101449, 0.68345094,\n",
              "        0.76165637, 0.60382765, 0.78735511, 0.78172674, 0.72996252,\n",
              "        0.6867335 , 0.69184839, 0.76387216, 0.62943424, 0.7744539 ,\n",
              "        0.73278428, 0.83082873, 0.83398126, 0.6852579 , 0.68696927,\n",
              "        0.8506456 , 0.80842458, 0.71362367, 0.76043218, 0.79875406,\n",
              "        0.65593601, 0.65639969, 0.81953987, 0.75857445, 0.73984435,\n",
              "        0.61297269, 0.71492148, 0.83871   , 0.72307374, 0.66206972,\n",
              "        0.79567386, 0.59459747, 0.80919605, 0.87767113, 0.74807018,\n",
              "        0.80588877, 0.66306147, 0.69407207, 0.85378003, 0.79299841,\n",
              "        0.67334124, 0.73033872, 0.76488414, 0.65310175, 0.81360095,\n",
              "        0.71542154, 0.63589618, 0.80200638, 0.76782653, 0.75931871,\n",
              "        0.6686239 , 0.71224734, 0.7238897 , 0.7284339 , 0.74613632,\n",
              "        0.66492294, 0.78989624, 0.75368201, 0.80674251, 0.77295058,\n",
              "        0.76782601, 0.74755524, 0.6055386 , 0.75769528, 0.63135688],\n",
              "       [0.65434011, 0.83021201, 0.68364684, 0.81074598, 0.79269139,\n",
              "        0.68240563, 0.70237804, 0.75128582, 0.80771976, 0.5604035 ,\n",
              "        0.76208259, 0.77506449, 0.68602475, 0.62049184, 0.73060674,\n",
              "        0.5985062 , 0.69545305, 0.79160614, 0.69172482, 0.82041386,\n",
              "        0.67550869, 0.6936052 , 0.79019815, 0.72114742, 0.7592073 ,\n",
              "        0.75253705, 0.79060113, 0.66408954, 0.71440794, 0.76008402,\n",
              "        0.60832053, 0.77839161, 0.72330366, 0.76418615, 0.65892774,\n",
              "        0.74984237, 0.60138926, 0.7893357 , 0.78246963, 0.7161601 ,\n",
              "        0.67250175, 0.66131583, 0.74606508, 0.61305274, 0.73742203,\n",
              "        0.71456942, 0.81331366, 0.81372779, 0.66971209, 0.66038384,\n",
              "        0.83491484, 0.80623612, 0.68065115, 0.75451391, 0.77464342,\n",
              "        0.67487315, 0.65803032, 0.81713325, 0.73744845, 0.72518137,\n",
              "        0.61692729, 0.72407294, 0.83113578, 0.71396942, 0.6425435 ,\n",
              "        0.77982149, 0.57906793, 0.79952824, 0.86452023, 0.75355613,\n",
              "        0.78496065, 0.63557071, 0.70167288, 0.83369413, 0.76910082,\n",
              "        0.65630072, 0.69756366, 0.75504039, 0.63841008, 0.79092097,\n",
              "        0.70718927, 0.61308448, 0.7948349 , 0.72911198, 0.75710066,\n",
              "        0.64298038, 0.68620371, 0.70259063, 0.69995865, 0.7217108 ,\n",
              "        0.66124616, 0.78801582, 0.71322046, 0.79788044, 0.73405672,\n",
              "        0.76904431, 0.72834355, 0.59709566, 0.76646681, 0.62972019],\n",
              "       [0.63338286, 0.81128552, 0.66722121, 0.76156397, 0.7710297 ,\n",
              "        0.69159747, 0.6896361 , 0.73854167, 0.77819207, 0.54794976,\n",
              "        0.74756735, 0.74341383, 0.67306184, 0.6107306 , 0.71842114,\n",
              "        0.58490373, 0.66164681, 0.77431221, 0.67719245, 0.80167702,\n",
              "        0.64102089, 0.70072688, 0.7671302 , 0.72289125, 0.74122055,\n",
              "        0.73155369, 0.77930734, 0.63021215, 0.69110216, 0.74816525,\n",
              "        0.58880212, 0.73134133, 0.70291656, 0.73692046, 0.64973014,\n",
              "        0.72060851, 0.5898671 , 0.74486674, 0.75178709, 0.69563954,\n",
              "        0.64579754, 0.6524357 , 0.73436115, 0.59537413, 0.7201025 ,\n",
              "        0.69348236, 0.78256205, 0.78546858, 0.64334864, 0.66579527,\n",
              "        0.8136273 , 0.77834479, 0.67762435, 0.73110291, 0.7512943 ,\n",
              "        0.63999905, 0.62881981, 0.77373169, 0.70119252, 0.7030736 ,\n",
              "        0.59399115, 0.68800129, 0.80094174, 0.67344456, 0.61181004,\n",
              "        0.74568502, 0.56733538, 0.77350444, 0.84010806, 0.72320013,\n",
              "        0.75452538, 0.62335791, 0.6623272 , 0.81009453, 0.76289417,\n",
              "        0.62165329, 0.67614689, 0.72827963, 0.61193705, 0.77412345,\n",
              "        0.66633216, 0.59696691, 0.7538828 , 0.71541285, 0.72403574,\n",
              "        0.65251924, 0.67408926, 0.68298321, 0.68952984, 0.70800465,\n",
              "        0.63294274, 0.73622222, 0.69902505, 0.77240995, 0.73247091,\n",
              "        0.74399545, 0.72740802, 0.58920795, 0.73422726, 0.60461549],\n",
              "       [0.57046315, 0.69451101, 0.62135696, 0.6132387 , 0.68966992,\n",
              "        0.67429719, 0.63148024, 0.66569714, 0.65674695, 0.53108933,\n",
              "        0.66064691, 0.61434962, 0.60428377, 0.57052641, 0.66779698,\n",
              "        0.55761947, 0.57870465, 0.70466216, 0.6445853 , 0.68830966,\n",
              "        0.57095177, 0.66763216, 0.67107855, 0.68118189, 0.63568049,\n",
              "        0.62830504, 0.69164966, 0.53390815, 0.61942871, 0.68805895,\n",
              "        0.5435493 , 0.5849149 , 0.60451927, 0.65871281, 0.61077906,\n",
              "        0.62416465, 0.5465666 , 0.60357242, 0.62504641, 0.61822064,\n",
              "        0.58167709, 0.61991946, 0.65770261, 0.56061895, 0.6687467 ,\n",
              "        0.62199989, 0.67502736, 0.68434885, 0.58203832, 0.63508893,\n",
              "        0.70637931, 0.65010477, 0.64420232, 0.62850024, 0.66875868,\n",
              "        0.53109743, 0.55025502, 0.62930826, 0.61783642, 0.62285779,\n",
              "        0.53245518, 0.56927673, 0.67226936, 0.58017152, 0.56377848,\n",
              "        0.64231532, 0.54745941, 0.66051285, 0.72068351, 0.60082152,\n",
              "        0.6599171 , 0.59502189, 0.55332641, 0.70875147, 0.69205234,\n",
              "        0.56361322, 0.6287725 , 0.62885346, 0.5616375 , 0.6899506 ,\n",
              "        0.57442173, 0.57014498, 0.62733665, 0.67027841, 0.60924347,\n",
              "        0.62839233, 0.6263151 , 0.62022419, 0.64112936, 0.64613202,\n",
              "        0.55977912, 0.59621642, 0.66021877, 0.65905428, 0.69232224,\n",
              "        0.62533939, 0.66368997, 0.55578492, 0.60092923, 0.54326028]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSnbti9ooIIs",
        "colab_type": "text"
      },
      "source": [
        "## Two hidden layer model in numpy:\n",
        "\n",
        "The difference from the one neuron model is simple:  we need only to change the number of output \"ny\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAY3o6zBnpA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2397
        },
        "outputId": "6b796236-e4d0-49d3-8df1-8e3022ed5cc7"
      },
      "source": [
        "num_inputs = 3\n",
        "hidden_layer_1_outputs = 4\n",
        "hidden_layer_2_outputs = 3\n",
        "\n",
        "num_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmod function)\n",
        "\n",
        "X = np.random.rand(num_inputs,num_samples)\n",
        "\n",
        "# Generate a random weights vector for the first hidden layer\n",
        "\n",
        "W_h1 = np.random.rand(hidden_layer_1_outputs, num_inputs)\n",
        "\n",
        "# Generate a random weights vector for the second hidden layer\n",
        "\n",
        "W_h2 = np.random.rand(hidden_layer_2_outputs,hidden_layer_1_outputs)\n",
        "\n",
        "# Generate a random bias\n",
        "b_h1= np.zeros((hidden_layer_1_outputs, 1))\n",
        "\n",
        "b_h2= np.zeros((hidden_layer_2_outputs, 1))\n",
        "\n",
        "\n",
        "\n",
        "# calculate output of hidden layer 1\n",
        "\n",
        "h1 = f(np.dot(W_h1, X) + b_h1)\n",
        "\n",
        "\n",
        "h2 = f(np.dot(W_h2, h1) + b_h2)\n",
        "\n",
        "display(h1)\n",
        "display(h2)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.70784736, 0.64182443, 0.69295024, 0.64039771, 0.7908926 ,\n",
              "        0.60493547, 0.78021846, 0.75342708, 0.79410768, 0.54095002,\n",
              "        0.58826019, 0.74712599, 0.76712062, 0.7305241 , 0.53642035,\n",
              "        0.71861429, 0.71770249, 0.61529636, 0.67093875, 0.65341141,\n",
              "        0.77406355, 0.64751516, 0.79927434, 0.67021042, 0.76767874,\n",
              "        0.80008933, 0.75573312, 0.73566853, 0.73510437, 0.79049952,\n",
              "        0.58895552, 0.67590837, 0.73478152, 0.63326133, 0.62144125,\n",
              "        0.73336719, 0.6891247 , 0.70520184, 0.62330064, 0.58757995,\n",
              "        0.69535474, 0.71335838, 0.63894914, 0.69445006, 0.55927663,\n",
              "        0.60910567, 0.6926463 , 0.71882164, 0.81707526, 0.74446994,\n",
              "        0.67692002, 0.7338295 , 0.56507317, 0.5449019 , 0.77986814,\n",
              "        0.7937947 , 0.75188514, 0.64809893, 0.77740314, 0.63911513,\n",
              "        0.71917781, 0.63323521, 0.68799701, 0.64016563, 0.69792746,\n",
              "        0.79991444, 0.76627341, 0.62463294, 0.72890361, 0.64636723,\n",
              "        0.66320774, 0.68490498, 0.64404154, 0.64962409, 0.6231554 ,\n",
              "        0.57789337, 0.71023188, 0.75163256, 0.83414449, 0.64827089,\n",
              "        0.57019562, 0.68239522, 0.69724956, 0.7098971 , 0.68227214,\n",
              "        0.61771806, 0.80590762, 0.63836286, 0.76898737, 0.71609328,\n",
              "        0.67430353, 0.68893361, 0.72163189, 0.74341988, 0.67801998,\n",
              "        0.76284404, 0.80421523, 0.74531533, 0.80982811, 0.70095515],\n",
              "       [0.67346456, 0.65276364, 0.64827349, 0.63767308, 0.56597234,\n",
              "        0.60961676, 0.62298605, 0.59815776, 0.62274371, 0.54660698,\n",
              "        0.55574758, 0.67199943, 0.57738449, 0.59919159, 0.57560406,\n",
              "        0.67331559, 0.63354714, 0.6105906 , 0.61928644, 0.57640388,\n",
              "        0.54581462, 0.644883  , 0.68434376, 0.68170866, 0.6331244 ,\n",
              "        0.65170552, 0.58442183, 0.58267768, 0.57010112, 0.55273419,\n",
              "        0.6264095 , 0.60125313, 0.63520951, 0.52535272, 0.55731324,\n",
              "        0.58531178, 0.52150144, 0.51887645, 0.65348097, 0.61166248,\n",
              "        0.64565938, 0.60262772, 0.57883372, 0.53980529, 0.52195838,\n",
              "        0.53230912, 0.59269028, 0.68212098, 0.62603696, 0.53977335,\n",
              "        0.61538998, 0.5925203 , 0.55449155, 0.61706946, 0.58728136,\n",
              "        0.57276627, 0.57622842, 0.58683143, 0.5746029 , 0.57183089,\n",
              "        0.54555483, 0.53141767, 0.62926116, 0.60352921, 0.58391677,\n",
              "        0.59466502, 0.59995754, 0.65895005, 0.63401649, 0.64019248,\n",
              "        0.68665694, 0.67807037, 0.56791535, 0.62777444, 0.56566096,\n",
              "        0.63472935, 0.64976088, 0.57769677, 0.69722463, 0.54560793,\n",
              "        0.60204277, 0.62788205, 0.65474595, 0.61463561, 0.637667  ,\n",
              "        0.54996043, 0.66607614, 0.58658901, 0.65302549, 0.54236817,\n",
              "        0.64019718, 0.58689936, 0.61370252, 0.52406432, 0.59593081,\n",
              "        0.63531114, 0.66697816, 0.56382376, 0.63483479, 0.67743333],\n",
              "       [0.66776528, 0.63562243, 0.64263106, 0.6351965 , 0.68994098,\n",
              "        0.58956899, 0.70955269, 0.69824587, 0.70357957, 0.53652214,\n",
              "        0.56457696, 0.71900499, 0.66871254, 0.66372844, 0.54983328,\n",
              "        0.69745819, 0.66555935, 0.58816583, 0.60398617, 0.62278513,\n",
              "        0.68113841, 0.61296039, 0.73497522, 0.64646848, 0.71189792,\n",
              "        0.72177482, 0.6636294 , 0.67045653, 0.66095297, 0.68543671,\n",
              "        0.60033194, 0.61132117, 0.68903795, 0.58840821, 0.58509273,\n",
              "        0.69619285, 0.62803585, 0.64934208, 0.62611362, 0.59128927,\n",
              "        0.65087196, 0.68212359, 0.61877827, 0.65056454, 0.53184485,\n",
              "        0.58047342, 0.63799852, 0.69362655, 0.72975788, 0.65839025,\n",
              "        0.62026347, 0.65400318, 0.55699579, 0.56361064, 0.70822489,\n",
              "        0.68493594, 0.6742899 , 0.58605773, 0.69183579, 0.58473927,\n",
              "        0.63196551, 0.5806287 , 0.61859888, 0.59998992, 0.60898273,\n",
              "        0.72136366, 0.69401068, 0.64520357, 0.67480099, 0.61142394,\n",
              "        0.62790562, 0.65502057, 0.62017644, 0.60848075, 0.60091023,\n",
              "        0.59990305, 0.68484617, 0.69582116, 0.76789742, 0.61799834,\n",
              "        0.58425925, 0.65051607, 0.66742102, 0.67217848, 0.63948148,\n",
              "        0.59367508, 0.74175906, 0.61303349, 0.70113163, 0.6528418 ,\n",
              "        0.61716872, 0.62880613, 0.68732323, 0.675576  , 0.6210638 ,\n",
              "        0.72331964, 0.73329395, 0.63944253, 0.72525833, 0.6719335 ],\n",
              "       [0.64749584, 0.60611717, 0.63172073, 0.60638501, 0.70352937,\n",
              "        0.57376119, 0.70300688, 0.68662802, 0.70755315, 0.52905706,\n",
              "        0.5598532 , 0.6881647 , 0.68207709, 0.66106534, 0.53085991,\n",
              "        0.6654072 , 0.65372337, 0.57745345, 0.60754065, 0.61072205,\n",
              "        0.69252159, 0.59935079, 0.71988222, 0.62096607, 0.69724128,\n",
              "        0.71661365, 0.67394399, 0.66734149, 0.66383977, 0.70223385,\n",
              "        0.57054303, 0.61403775, 0.67160776, 0.59086705, 0.58234729,\n",
              "        0.6771718 , 0.63205689, 0.64837208, 0.5941018 , 0.56712059,\n",
              "        0.63650498, 0.66090201, 0.60266873, 0.64280192, 0.53629145,\n",
              "        0.57684906, 0.63330971, 0.66319409, 0.73048603, 0.6690354 ,\n",
              "        0.61731277, 0.65893716, 0.54711722, 0.5373127 , 0.70436432,\n",
              "        0.70259685, 0.67702989, 0.59220139, 0.69696647, 0.58877105,\n",
              "        0.64583072, 0.58718898, 0.62061005, 0.59353222, 0.62408813,\n",
              "        0.71966154, 0.69089   , 0.60262429, 0.66281462, 0.59853093,\n",
              "        0.60952969, 0.631391  , 0.60615272, 0.59954691, 0.58922549,\n",
              "        0.56519498, 0.65764599, 0.6859597 , 0.7521026 , 0.60848078,\n",
              "        0.55759008, 0.63180744, 0.64388746, 0.65426305, 0.62634928,\n",
              "        0.58489671, 0.72739343, 0.59944883, 0.69199656, 0.65333465,\n",
              "        0.61315443, 0.62813847, 0.6662029 , 0.67665717, 0.61943144,\n",
              "        0.69979346, 0.72278241, 0.6601628 , 0.72420566, 0.64593711]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.87863914, 0.86647612, 0.87174418, 0.86470498, 0.87845975,\n",
              "        0.85190042, 0.88513809, 0.8791219 , 0.88565828, 0.82938383,\n",
              "        0.84018161, 0.88781633, 0.87482114, 0.87294962, 0.83457805,\n",
              "        0.88305475, 0.87539166, 0.85289095, 0.86164893, 0.8577505 ,\n",
              "        0.87385129, 0.86324965, 0.89493384, 0.87345027, 0.88524386,\n",
              "        0.89077625, 0.87383052, 0.87260749, 0.87009869, 0.87660123,\n",
              "        0.85364649, 0.86117781, 0.8799062 , 0.84498982, 0.84698731,\n",
              "        0.87580648, 0.85604186, 0.86026912, 0.86352438, 0.85056405,\n",
              "        0.87272835, 0.87395989, 0.85600243, 0.86161646, 0.8276343 ,\n",
              "        0.8420179 , 0.86541412, 0.8834473 , 0.89082141, 0.86755852,\n",
              "        0.86396369, 0.87138697, 0.83629794, 0.84263958, 0.88163073,\n",
              "        0.8787936 , 0.87395576, 0.85332487, 0.87827489, 0.85049492,\n",
              "        0.86224853, 0.84457176, 0.86628602, 0.85629244, 0.86120608,\n",
              "        0.88559492, 0.87995348, 0.86671361, 0.8775728 , 0.86243562,\n",
              "        0.87099027, 0.8754831 , 0.85550074, 0.86103739, 0.8503915 ,\n",
              "        0.85338352, 0.87861102, 0.87668812, 0.90211927, 0.85313334,\n",
              "        0.84660926, 0.8696735 , 0.87582864, 0.87361098, 0.86926706,\n",
              "        0.84696567, 0.89463509, 0.85601581, 0.88596126, 0.86433359,\n",
              "        0.86591482, 0.86324059, 0.87644266, 0.86801367, 0.86210575,\n",
              "        0.88631828, 0.89367971, 0.86772801, 0.89049322, 0.8788996 ],\n",
              "       [0.82579638, 0.81569284, 0.81785473, 0.81341364, 0.81717419,\n",
              "        0.80047009, 0.82778335, 0.82167052, 0.82733906, 0.77889541,\n",
              "        0.78714346, 0.83464845, 0.81451893, 0.81552951, 0.78585053,\n",
              "        0.83067048, 0.82025237, 0.8007285 , 0.80660449, 0.802752  ,\n",
              "        0.81221341, 0.81105349, 0.84031566, 0.82239933, 0.82907939,\n",
              "        0.83417453, 0.81429368, 0.81442224, 0.81103147, 0.81453951,\n",
              "        0.80429483, 0.80532127, 0.82473578, 0.78816483, 0.79219932,\n",
              "        0.81885067, 0.79653207, 0.80037185, 0.81365729, 0.80049199,\n",
              "        0.81887844, 0.81838105, 0.80194457, 0.80336688, 0.77462644,\n",
              "        0.78699263, 0.80907227, 0.83127133, 0.83257519, 0.80647693,\n",
              "        0.80893639, 0.81311449, 0.78476285, 0.79510395, 0.82265019,\n",
              "        0.81746031, 0.814691  , 0.79787711, 0.81819686, 0.79502033,\n",
              "        0.80197738, 0.78773989, 0.81107274, 0.80252013, 0.80311193,\n",
              "        0.82643295, 0.82170874, 0.81756883, 0.82215132, 0.81007901,\n",
              "        0.81993682, 0.82370657, 0.80070314, 0.80787909, 0.79632115,\n",
              "        0.80510058, 0.82527579, 0.8183429 , 0.84780475, 0.79706361,\n",
              "        0.7972307 , 0.81586881, 0.82282304, 0.81837667, 0.815484  ,\n",
              "        0.79242852, 0.8391826 , 0.80211859, 0.83017199, 0.80490301,\n",
              "        0.81196003, 0.80656163, 0.82104267, 0.80695995, 0.80623165,\n",
              "        0.83094474, 0.83800896, 0.80694003, 0.83280883, 0.82675767],\n",
              "       [0.87617416, 0.86261278, 0.86986867, 0.86140418, 0.88272828,\n",
              "        0.84872411, 0.88668834, 0.88083627, 0.8877219 , 0.82700553,\n",
              "        0.8390272 , 0.88647331, 0.8780922 , 0.874168  , 0.83048102,\n",
              "        0.88082276, 0.87480355, 0.85008101, 0.8604387 , 0.85759651,\n",
              "        0.87848912, 0.86003724, 0.89476438, 0.8694353 , 0.88599954,\n",
              "        0.89184107, 0.87649174, 0.87460109, 0.87268137, 0.88143972,\n",
              "        0.84904909, 0.86085775, 0.87966862, 0.84676264, 0.8468499 ,\n",
              "        0.8773907 , 0.85953327, 0.86417432, 0.85898458, 0.84660926,\n",
              "        0.87098914, 0.87431718, 0.85525131, 0.86422755, 0.82730333,\n",
              "        0.84263984, 0.86582383, 0.88092007, 0.89327253, 0.8717526 ,\n",
              "        0.86300916, 0.87307678, 0.83434671, 0.83686391, 0.88451978,\n",
              "        0.88294758, 0.87670886, 0.85283213, 0.88174326, 0.850356  ,\n",
              "        0.86565334, 0.84613883, 0.86516817, 0.85465045, 0.86244673,\n",
              "        0.88871562, 0.88205289, 0.86192883, 0.87728222, 0.85938424,\n",
              "        0.86660469, 0.87209814, 0.85540453, 0.8586468 , 0.84979417,\n",
              "        0.84799153, 0.87702894, 0.87916342, 0.9024521 , 0.85420776,\n",
              "        0.84243791, 0.86818707, 0.87370707, 0.87345105, 0.86745444,\n",
              "        0.84695116, 0.89525005, 0.85494798, 0.88611383, 0.86753626,\n",
              "        0.86385894, 0.8638453 , 0.87660322, 0.87263658, 0.86200618,\n",
              "        0.88676127, 0.89426665, 0.8711545 , 0.89243907, 0.87602693]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11fqb_bQvIEi",
        "colab_type": "text"
      },
      "source": [
        "## Gradient descent in Numpy:\n",
        "Let us now start training a neural network\n",
        "We start by implementing a simple gradient descent for linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzBJxwb7FFZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaQyLoxk2FyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqCCVlmFIZl",
        "colab_type": "text"
      },
      "source": [
        "##Assignment 1\n",
        "### Backpropagation in Numpy:\n"
      ]
    }
  ]
}