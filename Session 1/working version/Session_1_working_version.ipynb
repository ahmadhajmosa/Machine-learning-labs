{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 1 working version.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSUExzC-ZBV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPF3d47OoCZE",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 40
        },
        "outputId": "15689bae-5525-4ff6-9756-0bace5d3a37d"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26511acb-08d6-482d-bf77-9fc1510cb163\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-26511acb-08d6-482d-bf77-9fc1510cb163\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWZldyi-Zef",
        "colab_type": "text"
      },
      "source": [
        "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
        "## Session 1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1T4XAd1_fJk",
        "colab_type": "text"
      },
      "source": [
        "### Course Plan:\n",
        "\n",
        "This lab is a continuation to the Machine learning lecture, the objective of this course is to learn how to model and implement neural networks using deep learning python frameworks: \n",
        "1. Tensorflow\n",
        "2. Keras\n",
        "3. Pytorch\n",
        "\n",
        "Useing these frameworks, we will go through the following topics and use cases:\n",
        "\n",
        "#### Session 1: 05.06 - 09:00 - 11:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 09:00 - 10:30:\n",
        ">1. Introduction to deep learning frameworks\n",
        "2. Deep learning in Numpy\n",
        "\n",
        ">#### Break:  05.06 - 10:30 - 10:45\n",
        ">#### Assignment:  05.06 - 10:45 - 11:45 : \n",
        ">* Implementation of backprop using numpy\n",
        "\n",
        ">1. Tensorflow backround \n",
        "2. Implementation of feedforward neural networks using Tensorflow\n",
        "\n",
        ">#### Break:  05.06 - 10:00 - 10:15\n",
        ">#### Assignment:  05.06 - 10:15 - 10:45 : \n",
        "  \n",
        "  >* play around with tensorflow and build your first neural network\n",
        "\n",
        "\n",
        "\n",
        "#### Session 2:  05.06 - 11:00 - 12:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 11:00 - 12:00:\n",
        "\n",
        "\n",
        ">3. Implementation of CNN useing Tensorflow\n",
        "4. Tensorboard\n",
        "\n",
        ">#### Break:  05.06 - 12:00 - 13:00\n",
        ">#### Assignment:  05.06 - 13:00 - 13:30 :\n",
        "\n",
        "\n",
        " #### Session 3:  05.06 - 13:30 - 15:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 13:00 - 14:00:\n",
        "\n",
        ">5. Introduction to Keras\n",
        "6. CNN using Keras\n",
        ">#### Break:  05.06 - 14:00 - 14:15\n",
        ">#### Assignment:  05.06 - 14:15 - 14:45 :\n",
        "\n",
        " #### Session 4:  05.06 - 15:00 - 16:30  :\n",
        "\n",
        ">#### Presentation:  05.06 - 15:00 - 15:45:\n",
        "\n",
        ">7. LSTM using Keras\n",
        "\n",
        ">#### Break:  05.06 - 15:45 - 16:00\n",
        ">#### Assignment:  05.06 - 16:00 - 16:30 :\n",
        "\n",
        "\n",
        "8. VGG, Inceptaion, ResNet models using Keras\n",
        "\n",
        "9. Autoencoders using Keras\n",
        "\n",
        "10. Sequence to Sequence Models using Keras \n",
        "\n",
        "11. Attention Mechanism using Keras\n",
        "12. GANS \n",
        "13. Introduction to Pytorch\n",
        "14. Machine translation using Pytorch\n",
        "15. Introduction to Allennlp\n",
        "16. Deep Reinforcment Learning using Keras\n",
        "17. Use case: building self driving car using Unity and tensorflow\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75NLOuwKXSs",
        "colab_type": "text"
      },
      "source": [
        "#Session 1: 05.06 - 09:00 - 11:00 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUtGM-W_ehP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Deep learning frameworks:\n",
        "\n",
        "In the past decade, many deep learning frameworks have been developed to ease and scale the research and development of AI. Many big technology providers including Google, IBM, Microsoft and Facebook have entered the race to provide the best and most popluar frameworks. To enter such a race, mainly four features are considered in the provided framework:\n",
        "\n",
        "1. Uses a popular language for data scientists (Python, Scale, C++ or R)\n",
        "2. Flexible in creating and adjusting deep learning architectures -> Functional programming\n",
        "3. Easy for computing gradients\n",
        "4. Interface with GPUs for parallel processing\n",
        "\n",
        "\n",
        "In the following we see the most popular provided deep learning frameworks with their providers\n",
        "https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*dYjDEI0mLpsCOySKUuX1VA.png)\n",
        "\n",
        "## Tensorflow\n",
        "TensorFlow is the undisputed heavyweight champion. It has the most GitHub activity, Google searches, Medium articles, books on Amazon and ArXiv articles. It also has the most developers using it and is listed in the most online job descriptions. TensorFlow is backed by Google.\n",
        "\n",
        "## Keras\n",
        "Keras has an “API designed for human beings, not machines.” It is the second most popular framework in nearly all evaluation areas. Keras sits on top of TensorFlow, Theano, or CNTK. Start with Keras if you are new to deep learning.\n",
        "\n",
        "## Pytorch\n",
        "\n",
        "PyTorch is the third most popular overall framework and the second most popular stand-alone framework. It is younger than TensorFlow and has grown rapidly in popularity. It allows customization that TensorFlow does not. It has the backing of Facebook.\n",
        "\n",
        "## Theano\n",
        "\n",
        "Theano was developed at the University of Montreal in 2007 and is the oldest significant Python deep learning framework. It has lost much of its popularity and its leader stated that major releases were no longer on the roadmap. However, updates continue to be made. Theano still the fifth highest scoring framework.\n",
        "\n",
        "# Comparision:\n",
        "\n",
        "## Criteria 1: Online Job Listings\n",
        "\n",
        "TensorFlow is the clear winner when it comes to frameworks mentioned in job listings. Learn it if you want a job doing deep learning.\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*kA8dIgRqLdWgKgs2sd7clA.png)\n",
        "\n",
        "## Criteria 2: Usage\n",
        "\n",
        "\n",
        "Keras showed a surprising amount of use — nearly as much as TensorFlow. It’s interesting that US employers are overwhelmingly looking for TensorFlow skills, when — at least internationally — Keras is used almost as frequently.\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*6b2Tm0oFr99zKaxkr4g52w.png)\n",
        "  \n",
        "  \n",
        "## Criteria 4: Google Search Activity\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*wpA6C9x_Nri42EzbqnS1fQ.png)\n",
        "\n",
        "## Criteria 5: Medium Articles\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*Y1cJUgZTC3u_hU1lmdsroQ.png)\n",
        "\n",
        "\n",
        "## Criteria 6: Amazon Books\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*mtP47q29T6agdkEoJcCw-w.png)\n",
        "\n",
        "## Criteria 7 : ArXiv Articles\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*7jdNoNkGlx_1EnfevQXRvw.png)\n",
        "  \n",
        "## Criteria 8: GitHub Activity\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*eOOYV3C5klsuVBMX31ngxw.png)\n",
        "  \n",
        " --------------------------------\n",
        " \n",
        "\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3V8ztAKDCg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "Before we jump into Tensorflow, we will implemented our first neural network model using Python Numpy package. NumPy is the fundamental package for scientific computing with Python, such as:\n",
        "\n",
        "1. Linear Algebra\n",
        "2. Statistics\n",
        "3. Calculus\n",
        "\n",
        "## A brief intro to Numpy operations:\n",
        "\n",
        "1. Creating a Vector:\n",
        "Here we use Numpy to create a 1-D Array which we then call a vector.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTf7M4r7Lgj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b4f63294-97ab-441d-a06b-452fa3f348dc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "v1 = np.zeros((1,100))\n",
        "#display(v1)\n",
        "v2 = np.zeros((1,100))\n",
        "#display(v2)\n",
        "v2.shape\n",
        "# transport\n",
        "v2.T.shape\n",
        "v4 = np.eye((4))\n",
        "#display(v4)\n",
        "v5 = np.random.randn(100,1) # normal random generator\n",
        "v6 = np.random.rand(100,1) # uniform random generator\n",
        "#display(v6)\n",
        "#display(v5)\n",
        "display('mean of randn:',v5.mean())\n",
        "display('std of randn:',v5.std())\n",
        "\n",
        "display('std of randn:',v6.min())\n",
        "display('std of randn:',v6.min())\n",
        "\n",
        "display('mean of randn:',v6.max())\n",
        "display('std of randn:',v6.max())\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'mean of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.03790170488208862"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1.0044544036633825"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.004692792117357847"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.004692792117357847"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'mean of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9804700440846881"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9804700440846881"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYFjSo0OLqA3",
        "colab_type": "text"
      },
      "source": [
        "2. Creating a Matrix\n",
        "We Create a 2-D Array in Numpy and call it a Matrix. It contains 2 rows and 3 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJlDBq5rLmA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "31b5118a-9d12-4c4f-a7b6-a4e97282a8f0"
      },
      "source": [
        "m1 = np.zeros((2,3))\n",
        "#display(m1)\n",
        "\n",
        "matrix = np.array([[1,2,3],[4,5,6]])\n",
        "display(matrix)\n",
        "display('matrix shape:', matrix.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'matrix shape:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv99hZqULygH",
        "colab_type": "text"
      },
      "source": [
        "3. Selecting Elements\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLQlxFzkPrKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6184cfa4-8f2f-4fab-f2f0-51bef601a205"
      },
      "source": [
        "display(matrix[0,0]) # first row first col\n",
        "display(matrix[0,-1]) # first row last col\n",
        "display(matrix[0,-2]) # first row second last col\n",
        "display(matrix[0,1:]) # first row second last col\n",
        "display(matrix[0,:-1]) # first row second from col 0 -col 1\n",
        "display(matrix[0,0:2]) # first row second from col 0 -col 1"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO3vTGEKQhm7",
        "colab_type": "text"
      },
      "source": [
        "4. Describing a Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8bDjBhhQpg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "41929ad0-fede-4f5c-f4f5-6a6f73457b0c"
      },
      "source": [
        "print(matrix.shape) # view the number of rows and columns\n",
        "print(matrix.size) # view the number of elements (rows*columns)\n",
        "print(matrix.ndim) # view the nubmer of dimensions (2 in this case)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n",
            "6\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKISvY8kQtA0",
        "colab_type": "text"
      },
      "source": [
        "5. Finding the max and min values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abPJd0JrQ4mM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9aa9818c-cefb-4d65-d57a-dd341ee94bd3"
      },
      "source": [
        "#display(matrix)\n",
        "matrix.min(axis=0) # view the min element of row\n",
        "\n",
        "np.min(matrix, axis=1)\n",
        "np.max(matrix, axis=1)\n",
        "#display('arg', np.argmax(matrix, axis=0))\n",
        "#display('max', np.max(matrix, axis=0))\n",
        "\n",
        "np.argwhere(matrix == np.max(matrix))\n",
        "np.argwhere(matrix < np.max(matrix))\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [0, 1],\n",
              "       [0, 2],\n",
              "       [1, 0],\n",
              "       [1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qm64s_eR0zQ",
        "colab_type": "text"
      },
      "source": [
        "6. Reshaping Arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwepq7h_SBBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1030e610-700d-41a0-93a0-e3ce83b75403"
      },
      "source": [
        "matrix.shape\n",
        "matrix.reshape((3,2))\n",
        "matrix.reshape((6,1))\n",
        "matrix.reshape((1,6))\n",
        "matrix.reshape((1,2,3)) # dim 0 size = 1, dim 1=2, dim \n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 2, 3],\n",
              "        [4, 5, 6]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJU3xABuVem_",
        "colab_type": "text"
      },
      "source": [
        "7. Calculating Dot Products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPKg382VVivy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4ed8d478-7c46-40fe-bd85-762702428206"
      },
      "source": [
        "# create matrix\n",
        "vector_1 = np.array([1,2,3])\n",
        "vector_2 = np.array([4,5,6])\n",
        "\n",
        "print(np.dot(vector_1,vector_2))\n",
        "# alternatively you can use @ to calculate dot products\n",
        "\n",
        "\n",
        "print(np.dot(vector_1 @ vector_2))\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-2a3acdddd5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_1\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mvector_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Required argument 'b' (pos 2) not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB-jK7jEXY7F",
        "colab_type": "text"
      },
      "source": [
        "##Linear regression in Numpy:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Write the numpy code for the following model:\n",
        "\n",
        "$Y=WX+B$\n",
        "\n",
        "where $X$ is 3x10 matrix:  10 samples and 3 features\n",
        "\n",
        "$Y$ is 4x10 matrix: 10 samples and 4 outputs\n",
        "\n",
        "$W$ is the weights matrix with the shape 4x3: connecting 3 inputs to 4 outputs\n",
        "\n",
        "$b$ is a vector with a size 4 ( one bias per output)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EtM5LVtWCpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3f18034c-8435-45c0-eb5d-f8efd474c1b4"
      },
      "source": [
        "# inputs of features matrix\n",
        "\n",
        "X = np.random.rand(3,10)\n",
        "display('shape of X', X.shape)\n",
        "\n",
        "# Weights matrix\n",
        "\n",
        "W = np.random.rand(4,3)\n",
        "\n",
        "# bias\n",
        "\n",
        "b = np.zeros((4,1))\n",
        "\n",
        "# regression model\n",
        "\n",
        "Y = np.dot(W,X) + b\n",
        "display(Y)\n",
        "display('Y:', Y.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'shape of X'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3, 10)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.59893439, 0.37267232, 0.66005716, 0.54656477, 0.29742939,\n",
              "        0.30503663, 0.46318925, 0.43961454, 0.53544335, 0.64563852],\n",
              "       [0.68464208, 0.47292609, 0.81835809, 0.63552962, 0.39686407,\n",
              "        0.30724372, 0.6005141 , 0.47477745, 0.72175546, 0.8254916 ],\n",
              "       [0.87024378, 0.46288787, 0.90203691, 0.75251555, 0.36680517,\n",
              "        0.44797393, 0.70482911, 0.69303398, 0.8063879 , 0.92677663],\n",
              "       [0.64568712, 0.25485598, 0.56281747, 0.53137801, 0.17321787,\n",
              "        0.3923898 , 0.43135942, 0.56878687, 0.45103594, 0.56062562]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Y:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(4, 10)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMIoucH9hFfr",
        "colab_type": "text"
      },
      "source": [
        "## One neuron model in numpy:\n",
        "\n",
        "A single neuron has multiple inputs and one output, in addition to the linear regression model, we need to add non linearity through an activation function:\n",
        "\n",
        "$Y= f(WX+B)$\n",
        "\n",
        "where $X$ is n x m matrix:  m samples and n features/inputs\n",
        "\n",
        "$f(g)= \\frac{1}{1+\\exp(-g)}$  is a sigmoid acitavation function\n",
        "\n",
        "$Y$ is nh1 x m matrix: m samples and ny outputs\n",
        "\n",
        "$W$ is the weights matrix with the shape nh1 x n: connecting 3 inputs to 4 outputs\n",
        "\n",
        "$b$ is a vector with a size nh1 ( one bias per output)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qry1JDGEiLmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        },
        "outputId": "3dcaecb7-4b44-48d7-f7c8-f74bb0fd295b"
      },
      "source": [
        "num_inputs = 3\n",
        "num_outputs = 4\n",
        "num_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmod function)\n",
        "\n",
        "X = np.random.rand(num_inputs,num_samples)\n",
        "\n",
        "# Generate a random weights \n",
        "\n",
        "W = np.random.rand(num_outputs, num_inputs)\n",
        "\n",
        "# Generate a rondom bias\n",
        "b = np.zeros((num_outputs,1))\n",
        "\n",
        "# calculate y\n",
        "\n",
        "Y = f(np.dot(W,X) + b)\n",
        "display(Y)\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.66154576, 0.83866781, 0.71215531, 0.81212233, 0.81956725,\n",
              "        0.7249126 , 0.72458121, 0.77342191, 0.81527662, 0.57207404,\n",
              "        0.77693399, 0.77133045, 0.69516122, 0.63177557, 0.76492437,\n",
              "        0.61498484, 0.70432857, 0.82406645, 0.73226071, 0.82952944,\n",
              "        0.68876137, 0.72633858, 0.80781258, 0.75508194, 0.76158457,\n",
              "        0.75637852, 0.80837369, 0.65141928, 0.73332112, 0.79262832,\n",
              "        0.61442165, 0.77112296, 0.72271607, 0.79101449, 0.68345094,\n",
              "        0.76165637, 0.60382765, 0.78735511, 0.78172674, 0.72996252,\n",
              "        0.6867335 , 0.69184839, 0.76387216, 0.62943424, 0.7744539 ,\n",
              "        0.73278428, 0.83082873, 0.83398126, 0.6852579 , 0.68696927,\n",
              "        0.8506456 , 0.80842458, 0.71362367, 0.76043218, 0.79875406,\n",
              "        0.65593601, 0.65639969, 0.81953987, 0.75857445, 0.73984435,\n",
              "        0.61297269, 0.71492148, 0.83871   , 0.72307374, 0.66206972,\n",
              "        0.79567386, 0.59459747, 0.80919605, 0.87767113, 0.74807018,\n",
              "        0.80588877, 0.66306147, 0.69407207, 0.85378003, 0.79299841,\n",
              "        0.67334124, 0.73033872, 0.76488414, 0.65310175, 0.81360095,\n",
              "        0.71542154, 0.63589618, 0.80200638, 0.76782653, 0.75931871,\n",
              "        0.6686239 , 0.71224734, 0.7238897 , 0.7284339 , 0.74613632,\n",
              "        0.66492294, 0.78989624, 0.75368201, 0.80674251, 0.77295058,\n",
              "        0.76782601, 0.74755524, 0.6055386 , 0.75769528, 0.63135688],\n",
              "       [0.65434011, 0.83021201, 0.68364684, 0.81074598, 0.79269139,\n",
              "        0.68240563, 0.70237804, 0.75128582, 0.80771976, 0.5604035 ,\n",
              "        0.76208259, 0.77506449, 0.68602475, 0.62049184, 0.73060674,\n",
              "        0.5985062 , 0.69545305, 0.79160614, 0.69172482, 0.82041386,\n",
              "        0.67550869, 0.6936052 , 0.79019815, 0.72114742, 0.7592073 ,\n",
              "        0.75253705, 0.79060113, 0.66408954, 0.71440794, 0.76008402,\n",
              "        0.60832053, 0.77839161, 0.72330366, 0.76418615, 0.65892774,\n",
              "        0.74984237, 0.60138926, 0.7893357 , 0.78246963, 0.7161601 ,\n",
              "        0.67250175, 0.66131583, 0.74606508, 0.61305274, 0.73742203,\n",
              "        0.71456942, 0.81331366, 0.81372779, 0.66971209, 0.66038384,\n",
              "        0.83491484, 0.80623612, 0.68065115, 0.75451391, 0.77464342,\n",
              "        0.67487315, 0.65803032, 0.81713325, 0.73744845, 0.72518137,\n",
              "        0.61692729, 0.72407294, 0.83113578, 0.71396942, 0.6425435 ,\n",
              "        0.77982149, 0.57906793, 0.79952824, 0.86452023, 0.75355613,\n",
              "        0.78496065, 0.63557071, 0.70167288, 0.83369413, 0.76910082,\n",
              "        0.65630072, 0.69756366, 0.75504039, 0.63841008, 0.79092097,\n",
              "        0.70718927, 0.61308448, 0.7948349 , 0.72911198, 0.75710066,\n",
              "        0.64298038, 0.68620371, 0.70259063, 0.69995865, 0.7217108 ,\n",
              "        0.66124616, 0.78801582, 0.71322046, 0.79788044, 0.73405672,\n",
              "        0.76904431, 0.72834355, 0.59709566, 0.76646681, 0.62972019],\n",
              "       [0.63338286, 0.81128552, 0.66722121, 0.76156397, 0.7710297 ,\n",
              "        0.69159747, 0.6896361 , 0.73854167, 0.77819207, 0.54794976,\n",
              "        0.74756735, 0.74341383, 0.67306184, 0.6107306 , 0.71842114,\n",
              "        0.58490373, 0.66164681, 0.77431221, 0.67719245, 0.80167702,\n",
              "        0.64102089, 0.70072688, 0.7671302 , 0.72289125, 0.74122055,\n",
              "        0.73155369, 0.77930734, 0.63021215, 0.69110216, 0.74816525,\n",
              "        0.58880212, 0.73134133, 0.70291656, 0.73692046, 0.64973014,\n",
              "        0.72060851, 0.5898671 , 0.74486674, 0.75178709, 0.69563954,\n",
              "        0.64579754, 0.6524357 , 0.73436115, 0.59537413, 0.7201025 ,\n",
              "        0.69348236, 0.78256205, 0.78546858, 0.64334864, 0.66579527,\n",
              "        0.8136273 , 0.77834479, 0.67762435, 0.73110291, 0.7512943 ,\n",
              "        0.63999905, 0.62881981, 0.77373169, 0.70119252, 0.7030736 ,\n",
              "        0.59399115, 0.68800129, 0.80094174, 0.67344456, 0.61181004,\n",
              "        0.74568502, 0.56733538, 0.77350444, 0.84010806, 0.72320013,\n",
              "        0.75452538, 0.62335791, 0.6623272 , 0.81009453, 0.76289417,\n",
              "        0.62165329, 0.67614689, 0.72827963, 0.61193705, 0.77412345,\n",
              "        0.66633216, 0.59696691, 0.7538828 , 0.71541285, 0.72403574,\n",
              "        0.65251924, 0.67408926, 0.68298321, 0.68952984, 0.70800465,\n",
              "        0.63294274, 0.73622222, 0.69902505, 0.77240995, 0.73247091,\n",
              "        0.74399545, 0.72740802, 0.58920795, 0.73422726, 0.60461549],\n",
              "       [0.57046315, 0.69451101, 0.62135696, 0.6132387 , 0.68966992,\n",
              "        0.67429719, 0.63148024, 0.66569714, 0.65674695, 0.53108933,\n",
              "        0.66064691, 0.61434962, 0.60428377, 0.57052641, 0.66779698,\n",
              "        0.55761947, 0.57870465, 0.70466216, 0.6445853 , 0.68830966,\n",
              "        0.57095177, 0.66763216, 0.67107855, 0.68118189, 0.63568049,\n",
              "        0.62830504, 0.69164966, 0.53390815, 0.61942871, 0.68805895,\n",
              "        0.5435493 , 0.5849149 , 0.60451927, 0.65871281, 0.61077906,\n",
              "        0.62416465, 0.5465666 , 0.60357242, 0.62504641, 0.61822064,\n",
              "        0.58167709, 0.61991946, 0.65770261, 0.56061895, 0.6687467 ,\n",
              "        0.62199989, 0.67502736, 0.68434885, 0.58203832, 0.63508893,\n",
              "        0.70637931, 0.65010477, 0.64420232, 0.62850024, 0.66875868,\n",
              "        0.53109743, 0.55025502, 0.62930826, 0.61783642, 0.62285779,\n",
              "        0.53245518, 0.56927673, 0.67226936, 0.58017152, 0.56377848,\n",
              "        0.64231532, 0.54745941, 0.66051285, 0.72068351, 0.60082152,\n",
              "        0.6599171 , 0.59502189, 0.55332641, 0.70875147, 0.69205234,\n",
              "        0.56361322, 0.6287725 , 0.62885346, 0.5616375 , 0.6899506 ,\n",
              "        0.57442173, 0.57014498, 0.62733665, 0.67027841, 0.60924347,\n",
              "        0.62839233, 0.6263151 , 0.62022419, 0.64112936, 0.64613202,\n",
              "        0.55977912, 0.59621642, 0.66021877, 0.65905428, 0.69232224,\n",
              "        0.62533939, 0.66368997, 0.55578492, 0.60092923, 0.54326028]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSnbti9ooIIs",
        "colab_type": "text"
      },
      "source": [
        "## Two hidden layers model in numpy:\n",
        "\n",
        "The difference from the one neuron model is simple:  we need only to change the number of output \"ny\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAY3o6zBnpA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4bb05c6e-51da-4026-83b9-d428c7744abf"
      },
      "source": [
        "num_inputs = 3\n",
        "hidden_layer_1_outputs = 4\n",
        "hidden_layer_2_outputs = 3\n",
        "\n",
        "num_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmod function)\n",
        "\n",
        "X = np.random.rand(num_inputs,num_samples)\n",
        "\n",
        "# Generate a random weights vector for the first hidden layer\n",
        "\n",
        "W_h1 = np.random.rand(hidden_layer_1_outputs, num_inputs)\n",
        "\n",
        "# Generate a random weights vector for the second hidden layer\n",
        "\n",
        "W_h2 = np.random.rand(hidden_layer_2_outputs,hidden_layer_1_outputs)\n",
        "\n",
        "# Generate a random bias\n",
        "b_h1= np.zeros((hidden_layer_1_outputs, 1))\n",
        "\n",
        "b_h2= np.zeros((hidden_layer_2_outputs, 1))\n",
        "\n",
        "\n",
        "\n",
        "# calculate output of hidden layer 1\n",
        "\n",
        "h1 = f(np.dot(W_h1, X) + b_h1)\n",
        "\n",
        "\n",
        "h2 = f(np.dot(W_h2, h1) + b_h2)\n",
        "\n",
        "display(h1.shape)\n",
        "display(h2.shape)\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(4, 100)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3, 100)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11fqb_bQvIEi",
        "colab_type": "text"
      },
      "source": [
        "## Gradient descent in Numpy:\n",
        "Let us now start training a neural network\n",
        "We start by implementing a simple gradient descent for linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzBJxwb7FFZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2754
        },
        "outputId": "a55c4673-f84d-4c6a-eb8d-9ad27f8b80d7"
      },
      "source": [
        "\n",
        "converged = False\n",
        "iter = 0\n",
        "m = 10 # Number of samples\n",
        "ni= 1 # Number of input neurons\n",
        "h = 1 # Number of hidden layers\n",
        "no =1 # Number of neurons in the output layer\n",
        "\n",
        "# Generate a random X (we do not have a real data)\n",
        "X = np.random.rand(m)\n",
        "display(X)\n",
        "\n",
        "# learning rate\n",
        "alpha =0.01\n",
        "\n",
        "# early stop criteria \n",
        "ep=0.001\n",
        "\n",
        "# maximum number of training iterations\n",
        "max_iter=100\n",
        "\n",
        "# Generate a random weights vector for the output layer\n",
        "W1 = np.random.rand()\n",
        "\n",
        "# Generate a random bias for the output layer \n",
        "b1 = np.random.rand()\n",
        "\n",
        "# Generate a random ground truth\n",
        "Y_gr = np.random.rand(m)\n",
        "\n",
        "\n",
        "J = sum([(b1 + W1*X[i] - Y_gr[i])**2 for i in range(m)]) #cost function sum of squared error\n",
        "\n",
        "while not converged:\n",
        "        print('Interations:' , iter)\n",
        "        \n",
        "        # for each training sample, compute the gradient (d/d_theta j(theta))\n",
        "        grad0 = 1.0/m * sum([(b1 + W1*X[i] - Y_gr[i]) for i in range(m)]) \n",
        "        grad1 = 1.0/m * sum([(b1 + W1*X[i] - Y_gr[i])*X[i] for i in range(m)])\n",
        "        \n",
        "        # update the theta_temp\n",
        "        temp0 = b1 - alpha * grad0\n",
        "        temp1 = W1 - alpha * grad1\n",
        "        # update theta\n",
        "        b1 = temp0\n",
        "        W1 = temp1\n",
        "        \n",
        "        # sum squared error\n",
        "        e = sum([(b1 + W1*X[i] - Y_gr[i])**2 for i in range(m)]) \n",
        "        print('Error:', e)\n",
        "\n",
        "        if abs(J-e) <= ep:\n",
        "            print('Converged, iterations: ', iter, '!!!')\n",
        "            converged = True\n",
        "    \n",
        "        J = e   # update error \n",
        "        iter += 1  # update iter\n",
        "    \n",
        "        if iter == max_iter:\n",
        "            print('Max interactions exceeded!')\n",
        "            converged = True"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.65158367, 0.59275324, 0.55797387, 0.72800422, 0.06123583,\n",
              "       0.45424021, 0.76800388, 0.38562263, 0.06658242, 0.1171803 ])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Interations: 0\n",
            "Error: 1.6264258872181683\n",
            "Interations: 1\n",
            "Error: 1.6220444873792421\n",
            "Interations: 2\n",
            "Error: 1.6177586584947963\n",
            "Interations: 3\n",
            "Error: 1.613566124526418\n",
            "Interations: 4\n",
            "Error: 1.6094646638710521\n",
            "Interations: 5\n",
            "Error: 1.6054521080588349\n",
            "Interations: 6\n",
            "Error: 1.6015263404820725\n",
            "Interations: 7\n",
            "Error: 1.5976852951546243\n",
            "Interations: 8\n",
            "Error: 1.5939269555009647\n",
            "Interations: 9\n",
            "Error: 1.5902493531742137\n",
            "Interations: 10\n",
            "Error: 1.5866505669024404\n",
            "Interations: 11\n",
            "Error: 1.5831287213625655\n",
            "Interations: 12\n",
            "Error: 1.5796819860812006\n",
            "Interations: 13\n",
            "Error: 1.5763085743617846\n",
            "Interations: 14\n",
            "Error: 1.5730067422373806\n",
            "Interations: 15\n",
            "Error: 1.569774787448526\n",
            "Interations: 16\n",
            "Error: 1.5666110484455353\n",
            "Interations: 17\n",
            "Error: 1.563513903414663\n",
            "Interations: 18\n",
            "Error: 1.5604817693275734\n",
            "Interations: 19\n",
            "Error: 1.5575131010135383\n",
            "Interations: 20\n",
            "Error: 1.5546063902538316\n",
            "Interations: 21\n",
            "Error: 1.5517601648977948\n",
            "Interations: 22\n",
            "Error: 1.5489729880000358\n",
            "Interations: 23\n",
            "Error: 1.546243456978276\n",
            "Interations: 24\n",
            "Error: 1.5435702027913414\n",
            "Interations: 25\n",
            "Error: 1.540951889136815\n",
            "Interations: 26\n",
            "Error: 1.538387211667885\n",
            "Interations: 27\n",
            "Error: 1.535874897228925\n",
            "Interations: 28\n",
            "Error: 1.5334137031093635\n",
            "Interations: 29\n",
            "Error: 1.5310024163153995\n",
            "Interations: 30\n",
            "Error: 1.528639852859141\n",
            "Interations: 31\n",
            "Error: 1.5263248570647483\n",
            "Interations: 32\n",
            "Error: 1.5240563008911738\n",
            "Interations: 33\n",
            "Error: 1.5218330832711071\n",
            "Interations: 34\n",
            "Error: 1.519654129465728\n",
            "Interations: 35\n",
            "Error: 1.5175183904349006\n",
            "Interations: 36\n",
            "Error: 1.5154248422224295\n",
            "Interations: 37\n",
            "Error: 1.5133724853560206\n",
            "Interations: 38\n",
            "Error: 1.511360344261603\n",
            "Interations: 39\n",
            "Error: 1.5093874666916514\n",
            "Interations: 40\n",
            "Error: 1.50745292316719\n",
            "Interations: 41\n",
            "Error: 1.5055558064331467\n",
            "Interations: 42\n",
            "Error: 1.5036952309267275\n",
            "Interations: 43\n",
            "Error: 1.5018703322585167\n",
            "Interations: 44\n",
            "Error: 1.5000802667059878\n",
            "Interations: 45\n",
            "Error: 1.4983242107191255\n",
            "Interations: 46\n",
            "Error: 1.4966013604378816\n",
            "Interations: 47\n",
            "Error: 1.4949109312211701\n",
            "Interations: 48\n",
            "Error: 1.4932521571871273\n",
            "Interations: 49\n",
            "Error: 1.4916242907643762\n",
            "Interations: 50\n",
            "Error: 1.4900266022540172\n",
            "Interations: 51\n",
            "Error: 1.4884583794021038\n",
            "Interations: 52\n",
            "Error: 1.4869189269823422\n",
            "Interations: 53\n",
            "Error: 1.485407566388773\n",
            "Interations: 54\n",
            "Error: 1.4839236352381957\n",
            "Interations: 55\n",
            "Error: 1.4824664869821094\n",
            "Interations: 56\n",
            "Error: 1.4810354905279277\n",
            "Interations: 57\n",
            "Error: 1.4796300298692657\n",
            "Interations: 58\n",
            "Error: 1.478249503725057\n",
            "Interations: 59\n",
            "Error: 1.476893325187319\n",
            "Interations: 60\n",
            "Error: 1.4755609213773326\n",
            "Interations: 61\n",
            "Error: 1.4742517331100524\n",
            "Interations: 62\n",
            "Error: 1.4729652145665426\n",
            "Interations: 63\n",
            "Error: 1.471700832974249\n",
            "Interations: 64\n",
            "Error: 1.4704580682949209\n",
            "Interations: 65\n",
            "Error: 1.4692364129199964\n",
            "Interations: 66\n",
            "Error: 1.4680353713732759\n",
            "Interations: 67\n",
            "Error: 1.4668544600207074\n",
            "Interations: 68\n",
            "Error: 1.465693206787113\n",
            "Interations: 69\n",
            "Error: 1.4645511508796971\n",
            "Interations: 70\n",
            "Error: 1.4634278425181606\n",
            "Interations: 71\n",
            "Error: 1.4623228426712775\n",
            "Interations: 72\n",
            "Error: 1.4612357227997708\n",
            "Interations: 73\n",
            "Error: 1.4601660646053387\n",
            "Interations: 74\n",
            "Error: 1.4591134597856872\n",
            "Interations: 75\n",
            "Error: 1.4580775097954162\n",
            "Interations: 76\n",
            "Error: 1.4570578256126363\n",
            "Interations: 77\n",
            "Error: 1.456054027511155\n",
            "Interations: 78\n",
            "Error: 1.4550657448381272\n",
            "Converged, iterations:  78 !!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaQyLoxk2FyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqCCVlmFIZl",
        "colab_type": "text"
      },
      "source": [
        "##Assignment 1\n",
        "### Backpropagation in Numpy:\n"
      ]
    }
  ]
}