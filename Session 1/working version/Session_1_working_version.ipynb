{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 1 working version.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSUExzC-ZBV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPF3d47OoCZE",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 40
        },
        "outputId": "15689bae-5525-4ff6-9756-0bace5d3a37d"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26511acb-08d6-482d-bf77-9fc1510cb163\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-26511acb-08d6-482d-bf77-9fc1510cb163\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWZldyi-Zef",
        "colab_type": "text"
      },
      "source": [
        "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
        "## Session 1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1T4XAd1_fJk",
        "colab_type": "text"
      },
      "source": [
        "### Course Plan:\n",
        "\n",
        "This lab is a continuation to the Machine learning lecture, the objective of this course is to learn how to model and implement neural networks using deep learning python frameworks: \n",
        "1. Tensorflow\n",
        "2. Keras\n",
        "3. Pytorch\n",
        "\n",
        "Useing these frameworks, we will go through the following topics and use cases:\n",
        "\n",
        "#### Session 1: 05.06 - 09:00 - 11:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 09:00 - 10:30:\n",
        ">1. Introduction to deep learning frameworks\n",
        "2. Deep learning in Numpy\n",
        "\n",
        ">#### Break:  05.06 - 10:30 - 10:45\n",
        ">#### Assignment:  05.06 - 10:45 - 11:45 : \n",
        ">* Implementation of backprop using numpy\n",
        "\n",
        ">1. Tensorflow backround \n",
        "2. Implementation of feedforward neural networks using Tensorflow\n",
        "\n",
        ">#### Break:  05.06 - 10:00 - 10:15\n",
        ">#### Assignment:  05.06 - 10:15 - 10:45 : \n",
        "  \n",
        "  >* play around with tensorflow and build your first neural network\n",
        "\n",
        "\n",
        "\n",
        "#### Session 2:  05.06 - 11:00 - 12:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 11:00 - 12:00:\n",
        "\n",
        "\n",
        ">3. Implementation of CNN useing Tensorflow\n",
        "4. Tensorboard\n",
        "\n",
        ">#### Break:  05.06 - 12:00 - 13:00\n",
        ">#### Assignment:  05.06 - 13:00 - 13:30 :\n",
        "\n",
        "\n",
        " #### Session 3:  05.06 - 13:30 - 15:00  :\n",
        "\n",
        ">#### Presentation:  05.06 - 13:00 - 14:00:\n",
        "\n",
        ">5. Introduction to Keras\n",
        "6. CNN using Keras\n",
        ">#### Break:  05.06 - 14:00 - 14:15\n",
        ">#### Assignment:  05.06 - 14:15 - 14:45 :\n",
        "\n",
        " #### Session 4:  05.06 - 15:00 - 16:30  :\n",
        "\n",
        ">#### Presentation:  05.06 - 15:00 - 15:45:\n",
        "\n",
        ">7. LSTM using Keras\n",
        "\n",
        ">#### Break:  05.06 - 15:45 - 16:00\n",
        ">#### Assignment:  05.06 - 16:00 - 16:30 :\n",
        "\n",
        "\n",
        "8. VGG, Inceptaion, ResNet models using Keras\n",
        "\n",
        "9. Autoencoders using Keras\n",
        "\n",
        "10. Sequence to Sequence Models using Keras \n",
        "\n",
        "11. Attention Mechanism using Keras\n",
        "12. GANS \n",
        "13. Introduction to Pytorch\n",
        "14. Machine translation using Pytorch\n",
        "15. Introduction to Allennlp\n",
        "16. Deep Reinforcment Learning using Keras\n",
        "17. Use case: building self driving car using Unity and tensorflow\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75NLOuwKXSs",
        "colab_type": "text"
      },
      "source": [
        "#Session 1: 05.06 - 09:00 - 11:00 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUtGM-W_ehP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Deep learning frameworks:\n",
        "\n",
        "In the past decade, many deep learning frameworks have been developed to ease and scale the research and development of AI. Many big technology providers including Google, IBM, Microsoft and Facebook have entered the race to provide the best and most popluar frameworks. To enter such a race, mainly four features are considered in the provided framework:\n",
        "\n",
        "1. Uses a popular language for data scientists (Python, Scale, C++ or R)\n",
        "2. Flexible in creating and adjusting deep learning architectures -> Functional programming\n",
        "3. Easy for computing gradients\n",
        "4. Interface with GPUs for parallel processing\n",
        "\n",
        "\n",
        "In the following we see the most popular provided deep learning frameworks with their providers\n",
        "https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*dYjDEI0mLpsCOySKUuX1VA.png)\n",
        "\n",
        "## Tensorflow\n",
        "TensorFlow is the undisputed heavyweight champion. It has the most GitHub activity, Google searches, Medium articles, books on Amazon and ArXiv articles. It also has the most developers using it and is listed in the most online job descriptions. TensorFlow is backed by Google.\n",
        "\n",
        "## Keras\n",
        "Keras has an “API designed for human beings, not machines.” It is the second most popular framework in nearly all evaluation areas. Keras sits on top of TensorFlow, Theano, or CNTK. Start with Keras if you are new to deep learning.\n",
        "\n",
        "## Pytorch\n",
        "\n",
        "PyTorch is the third most popular overall framework and the second most popular stand-alone framework. It is younger than TensorFlow and has grown rapidly in popularity. It allows customization that TensorFlow does not. It has the backing of Facebook.\n",
        "\n",
        "## Theano\n",
        "\n",
        "Theano was developed at the University of Montreal in 2007 and is the oldest significant Python deep learning framework. It has lost much of its popularity and its leader stated that major releases were no longer on the roadmap. However, updates continue to be made. Theano still the fifth highest scoring framework.\n",
        "\n",
        "# Comparision:\n",
        "\n",
        "## Criteria 1: Online Job Listings\n",
        "\n",
        "TensorFlow is the clear winner when it comes to frameworks mentioned in job listings. Learn it if you want a job doing deep learning.\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*kA8dIgRqLdWgKgs2sd7clA.png)\n",
        "\n",
        "## Criteria 2: Usage\n",
        "\n",
        "\n",
        "Keras showed a surprising amount of use — nearly as much as TensorFlow. It’s interesting that US employers are overwhelmingly looking for TensorFlow skills, when — at least internationally — Keras is used almost as frequently.\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*6b2Tm0oFr99zKaxkr4g52w.png)\n",
        "  \n",
        "  \n",
        "## Criteria 4: Google Search Activity\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*wpA6C9x_Nri42EzbqnS1fQ.png)\n",
        "\n",
        "## Criteria 5: Medium Articles\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*Y1cJUgZTC3u_hU1lmdsroQ.png)\n",
        "\n",
        "\n",
        "## Criteria 6: Amazon Books\n",
        "\n",
        ">> ![alt text](https://cdn-images-1.medium.com/max/800/1*mtP47q29T6agdkEoJcCw-w.png)\n",
        "\n",
        "## Criteria 7 : ArXiv Articles\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*7jdNoNkGlx_1EnfevQXRvw.png)\n",
        "  \n",
        "## Criteria 8: GitHub Activity\n",
        "\n",
        "  >> ![alt text](https://cdn-images-1.medium.com/max/800/1*eOOYV3C5klsuVBMX31ngxw.png)\n",
        "  \n",
        " --------------------------------\n",
        " \n",
        "\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3V8ztAKDCg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "Before we jump into Tensorflow, we will implemented our first neural network model using Python Numpy package. NumPy is the fundamental package for scientific computing with Python, such as:\n",
        "\n",
        "1. Linear Algebra\n",
        "2. Statistics\n",
        "3. Calculus\n",
        "\n",
        "## A brief intro to Numpy operations:\n",
        "\n",
        "1. Creating a Vector:\n",
        "Here we use Numpy to create a 1-D Array which we then call a vector.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTf7M4r7Lgj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b4f63294-97ab-441d-a06b-452fa3f348dc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "v1 = np.zeros((1,100))\n",
        "#display(v1)\n",
        "v2 = np.zeros((1,100))\n",
        "#display(v2)\n",
        "v2.shape\n",
        "# transport\n",
        "v2.T.shape\n",
        "v4 = np.eye((4))\n",
        "#display(v4)\n",
        "v5 = np.random.randn(100,1) # normal random generator\n",
        "v6 = np.random.rand(100,1) # uniform random generator\n",
        "#display(v6)\n",
        "#display(v5)\n",
        "display('mean of randn:',v5.mean())\n",
        "display('std of randn:',v5.std())\n",
        "\n",
        "display('std of randn:',v6.min())\n",
        "display('std of randn:',v6.min())\n",
        "\n",
        "display('mean of randn:',v6.max())\n",
        "display('std of randn:',v6.max())\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'mean of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.03790170488208862"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1.0044544036633825"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.004692792117357847"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.004692792117357847"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'mean of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9804700440846881"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'std of randn:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9804700440846881"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYFjSo0OLqA3",
        "colab_type": "text"
      },
      "source": [
        "2. Creating a Matrix\n",
        "We Create a 2-D Array in Numpy and call it a Matrix. It contains 2 rows and 3 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJlDBq5rLmA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "31b5118a-9d12-4c4f-a7b6-a4e97282a8f0"
      },
      "source": [
        "m1 = np.zeros((2,3))\n",
        "#display(m1)\n",
        "\n",
        "matrix = np.array([[1,2,3],[4,5,6]])\n",
        "display(matrix)\n",
        "display('matrix shape:', matrix.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'matrix shape:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv99hZqULygH",
        "colab_type": "text"
      },
      "source": [
        "3. Selecting Elements\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLQlxFzkPrKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6184cfa4-8f2f-4fab-f2f0-51bef601a205"
      },
      "source": [
        "display(matrix[0,0]) # first row first col\n",
        "display(matrix[0,-1]) # first row last col\n",
        "display(matrix[0,-2]) # first row second last col\n",
        "display(matrix[0,1:]) # first row second last col\n",
        "display(matrix[0,:-1]) # first row second from col 0 -col 1\n",
        "display(matrix[0,0:2]) # first row second from col 0 -col 1"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO3vTGEKQhm7",
        "colab_type": "text"
      },
      "source": [
        "4. Describing a Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8bDjBhhQpg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "41929ad0-fede-4f5c-f4f5-6a6f73457b0c"
      },
      "source": [
        "print(matrix.shape) # view the number of rows and columns\n",
        "print(matrix.size) # view the number of elements (rows*columns)\n",
        "print(matrix.ndim) # view the nubmer of dimensions (2 in this case)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n",
            "6\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKISvY8kQtA0",
        "colab_type": "text"
      },
      "source": [
        "5. Finding the max and min values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abPJd0JrQ4mM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9aa9818c-cefb-4d65-d57a-dd341ee94bd3"
      },
      "source": [
        "#display(matrix)\n",
        "matrix.min(axis=0) # view the min element of row\n",
        "\n",
        "np.min(matrix, axis=1)\n",
        "np.max(matrix, axis=1)\n",
        "#display('arg', np.argmax(matrix, axis=0))\n",
        "#display('max', np.max(matrix, axis=0))\n",
        "\n",
        "np.argwhere(matrix == np.max(matrix))\n",
        "np.argwhere(matrix < np.max(matrix))\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [0, 1],\n",
              "       [0, 2],\n",
              "       [1, 0],\n",
              "       [1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qm64s_eR0zQ",
        "colab_type": "text"
      },
      "source": [
        "6. Reshaping Arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwepq7h_SBBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1030e610-700d-41a0-93a0-e3ce83b75403"
      },
      "source": [
        "matrix.shape\n",
        "matrix.reshape((3,2))\n",
        "matrix.reshape((6,1))\n",
        "matrix.reshape((1,6))\n",
        "matrix.reshape((1,2,3)) # dim 0 size = 1, dim 1=2, dim \n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 2, 3],\n",
              "        [4, 5, 6]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJU3xABuVem_",
        "colab_type": "text"
      },
      "source": [
        "7. Calculating Dot Products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPKg382VVivy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4ed8d478-7c46-40fe-bd85-762702428206"
      },
      "source": [
        "# create matrix\n",
        "vector_1 = np.array([1,2,3])\n",
        "vector_2 = np.array([4,5,6])\n",
        "\n",
        "print(np.dot(vector_1,vector_2))\n",
        "# alternatively you can use @ to calculate dot products\n",
        "\n",
        "\n",
        "print(np.dot(vector_1 @ vector_2))\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-2a3acdddd5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_1\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mvector_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Required argument 'b' (pos 2) not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB-jK7jEXY7F",
        "colab_type": "text"
      },
      "source": [
        "##Linear regression in Numpy:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Write the numpy code for the following model:\n",
        "\n",
        "$Y=WX+B$\n",
        "\n",
        "where $X$ is 3x10 matrix:  10 samples and 3 features\n",
        "\n",
        "$Y$ is 4x10 matrix: 10 samples and 4 outputs\n",
        "\n",
        "$W$ is the weights matrix with the shape 4x3: connecting 3 inputs to 4 outputs\n",
        "\n",
        "$b$ is a vector with a size 4 ( one bias per output)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EtM5LVtWCpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3f18034c-8435-45c0-eb5d-f8efd474c1b4"
      },
      "source": [
        "# inputs of features matrix\n",
        "\n",
        "X = np.random.rand(3,10)\n",
        "display('shape of X', X.shape)\n",
        "\n",
        "# Weights matrix\n",
        "\n",
        "W = np.random.rand(4,3)\n",
        "\n",
        "# bias\n",
        "\n",
        "b = np.zeros((4,1))\n",
        "\n",
        "# regression model\n",
        "\n",
        "Y = np.dot(W,X) + b\n",
        "display(Y)\n",
        "display('Y:', Y.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'shape of X'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3, 10)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.59893439, 0.37267232, 0.66005716, 0.54656477, 0.29742939,\n",
              "        0.30503663, 0.46318925, 0.43961454, 0.53544335, 0.64563852],\n",
              "       [0.68464208, 0.47292609, 0.81835809, 0.63552962, 0.39686407,\n",
              "        0.30724372, 0.6005141 , 0.47477745, 0.72175546, 0.8254916 ],\n",
              "       [0.87024378, 0.46288787, 0.90203691, 0.75251555, 0.36680517,\n",
              "        0.44797393, 0.70482911, 0.69303398, 0.8063879 , 0.92677663],\n",
              "       [0.64568712, 0.25485598, 0.56281747, 0.53137801, 0.17321787,\n",
              "        0.3923898 , 0.43135942, 0.56878687, 0.45103594, 0.56062562]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Y:'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(4, 10)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMIoucH9hFfr",
        "colab_type": "text"
      },
      "source": [
        "## One neuron model in numpy:\n",
        "\n",
        "A single neuron has multiple inputs and one output, in addition to the linear regression model, we need to add non linearity through an activation function:\n",
        "\n",
        "$Y= f(WX+B)$\n",
        "\n",
        "where $X$ is n x m matrix:  m samples and n features/inputs\n",
        "\n",
        "$f(g)= \\frac{1}{1+\\exp(-g)}$  is a sigmoid acitavation function\n",
        "\n",
        "$Y$ is nh1 x m matrix: m samples and ny outputs\n",
        "\n",
        "$W$ is the weights matrix with the shape nh1 x n: connecting 3 inputs to 4 outputs\n",
        "\n",
        "$b$ is a vector with a size nh1 ( one bias per output)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qry1JDGEiLmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        },
        "outputId": "3dcaecb7-4b44-48d7-f7c8-f74bb0fd295b"
      },
      "source": [
        "num_inputs = 3\n",
        "num_outputs = 4\n",
        "num_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmod function)\n",
        "\n",
        "X = np.random.rand(num_inputs,num_samples)\n",
        "\n",
        "# Generate a random weights \n",
        "\n",
        "W = np.random.rand(num_outputs, num_inputs)\n",
        "\n",
        "# Generate a rondom bias\n",
        "b = np.zeros((num_outputs,1))\n",
        "\n",
        "# calculate y\n",
        "\n",
        "Y = f(np.dot(W,X) + b)\n",
        "display(Y)\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.66154576, 0.83866781, 0.71215531, 0.81212233, 0.81956725,\n",
              "        0.7249126 , 0.72458121, 0.77342191, 0.81527662, 0.57207404,\n",
              "        0.77693399, 0.77133045, 0.69516122, 0.63177557, 0.76492437,\n",
              "        0.61498484, 0.70432857, 0.82406645, 0.73226071, 0.82952944,\n",
              "        0.68876137, 0.72633858, 0.80781258, 0.75508194, 0.76158457,\n",
              "        0.75637852, 0.80837369, 0.65141928, 0.73332112, 0.79262832,\n",
              "        0.61442165, 0.77112296, 0.72271607, 0.79101449, 0.68345094,\n",
              "        0.76165637, 0.60382765, 0.78735511, 0.78172674, 0.72996252,\n",
              "        0.6867335 , 0.69184839, 0.76387216, 0.62943424, 0.7744539 ,\n",
              "        0.73278428, 0.83082873, 0.83398126, 0.6852579 , 0.68696927,\n",
              "        0.8506456 , 0.80842458, 0.71362367, 0.76043218, 0.79875406,\n",
              "        0.65593601, 0.65639969, 0.81953987, 0.75857445, 0.73984435,\n",
              "        0.61297269, 0.71492148, 0.83871   , 0.72307374, 0.66206972,\n",
              "        0.79567386, 0.59459747, 0.80919605, 0.87767113, 0.74807018,\n",
              "        0.80588877, 0.66306147, 0.69407207, 0.85378003, 0.79299841,\n",
              "        0.67334124, 0.73033872, 0.76488414, 0.65310175, 0.81360095,\n",
              "        0.71542154, 0.63589618, 0.80200638, 0.76782653, 0.75931871,\n",
              "        0.6686239 , 0.71224734, 0.7238897 , 0.7284339 , 0.74613632,\n",
              "        0.66492294, 0.78989624, 0.75368201, 0.80674251, 0.77295058,\n",
              "        0.76782601, 0.74755524, 0.6055386 , 0.75769528, 0.63135688],\n",
              "       [0.65434011, 0.83021201, 0.68364684, 0.81074598, 0.79269139,\n",
              "        0.68240563, 0.70237804, 0.75128582, 0.80771976, 0.5604035 ,\n",
              "        0.76208259, 0.77506449, 0.68602475, 0.62049184, 0.73060674,\n",
              "        0.5985062 , 0.69545305, 0.79160614, 0.69172482, 0.82041386,\n",
              "        0.67550869, 0.6936052 , 0.79019815, 0.72114742, 0.7592073 ,\n",
              "        0.75253705, 0.79060113, 0.66408954, 0.71440794, 0.76008402,\n",
              "        0.60832053, 0.77839161, 0.72330366, 0.76418615, 0.65892774,\n",
              "        0.74984237, 0.60138926, 0.7893357 , 0.78246963, 0.7161601 ,\n",
              "        0.67250175, 0.66131583, 0.74606508, 0.61305274, 0.73742203,\n",
              "        0.71456942, 0.81331366, 0.81372779, 0.66971209, 0.66038384,\n",
              "        0.83491484, 0.80623612, 0.68065115, 0.75451391, 0.77464342,\n",
              "        0.67487315, 0.65803032, 0.81713325, 0.73744845, 0.72518137,\n",
              "        0.61692729, 0.72407294, 0.83113578, 0.71396942, 0.6425435 ,\n",
              "        0.77982149, 0.57906793, 0.79952824, 0.86452023, 0.75355613,\n",
              "        0.78496065, 0.63557071, 0.70167288, 0.83369413, 0.76910082,\n",
              "        0.65630072, 0.69756366, 0.75504039, 0.63841008, 0.79092097,\n",
              "        0.70718927, 0.61308448, 0.7948349 , 0.72911198, 0.75710066,\n",
              "        0.64298038, 0.68620371, 0.70259063, 0.69995865, 0.7217108 ,\n",
              "        0.66124616, 0.78801582, 0.71322046, 0.79788044, 0.73405672,\n",
              "        0.76904431, 0.72834355, 0.59709566, 0.76646681, 0.62972019],\n",
              "       [0.63338286, 0.81128552, 0.66722121, 0.76156397, 0.7710297 ,\n",
              "        0.69159747, 0.6896361 , 0.73854167, 0.77819207, 0.54794976,\n",
              "        0.74756735, 0.74341383, 0.67306184, 0.6107306 , 0.71842114,\n",
              "        0.58490373, 0.66164681, 0.77431221, 0.67719245, 0.80167702,\n",
              "        0.64102089, 0.70072688, 0.7671302 , 0.72289125, 0.74122055,\n",
              "        0.73155369, 0.77930734, 0.63021215, 0.69110216, 0.74816525,\n",
              "        0.58880212, 0.73134133, 0.70291656, 0.73692046, 0.64973014,\n",
              "        0.72060851, 0.5898671 , 0.74486674, 0.75178709, 0.69563954,\n",
              "        0.64579754, 0.6524357 , 0.73436115, 0.59537413, 0.7201025 ,\n",
              "        0.69348236, 0.78256205, 0.78546858, 0.64334864, 0.66579527,\n",
              "        0.8136273 , 0.77834479, 0.67762435, 0.73110291, 0.7512943 ,\n",
              "        0.63999905, 0.62881981, 0.77373169, 0.70119252, 0.7030736 ,\n",
              "        0.59399115, 0.68800129, 0.80094174, 0.67344456, 0.61181004,\n",
              "        0.74568502, 0.56733538, 0.77350444, 0.84010806, 0.72320013,\n",
              "        0.75452538, 0.62335791, 0.6623272 , 0.81009453, 0.76289417,\n",
              "        0.62165329, 0.67614689, 0.72827963, 0.61193705, 0.77412345,\n",
              "        0.66633216, 0.59696691, 0.7538828 , 0.71541285, 0.72403574,\n",
              "        0.65251924, 0.67408926, 0.68298321, 0.68952984, 0.70800465,\n",
              "        0.63294274, 0.73622222, 0.69902505, 0.77240995, 0.73247091,\n",
              "        0.74399545, 0.72740802, 0.58920795, 0.73422726, 0.60461549],\n",
              "       [0.57046315, 0.69451101, 0.62135696, 0.6132387 , 0.68966992,\n",
              "        0.67429719, 0.63148024, 0.66569714, 0.65674695, 0.53108933,\n",
              "        0.66064691, 0.61434962, 0.60428377, 0.57052641, 0.66779698,\n",
              "        0.55761947, 0.57870465, 0.70466216, 0.6445853 , 0.68830966,\n",
              "        0.57095177, 0.66763216, 0.67107855, 0.68118189, 0.63568049,\n",
              "        0.62830504, 0.69164966, 0.53390815, 0.61942871, 0.68805895,\n",
              "        0.5435493 , 0.5849149 , 0.60451927, 0.65871281, 0.61077906,\n",
              "        0.62416465, 0.5465666 , 0.60357242, 0.62504641, 0.61822064,\n",
              "        0.58167709, 0.61991946, 0.65770261, 0.56061895, 0.6687467 ,\n",
              "        0.62199989, 0.67502736, 0.68434885, 0.58203832, 0.63508893,\n",
              "        0.70637931, 0.65010477, 0.64420232, 0.62850024, 0.66875868,\n",
              "        0.53109743, 0.55025502, 0.62930826, 0.61783642, 0.62285779,\n",
              "        0.53245518, 0.56927673, 0.67226936, 0.58017152, 0.56377848,\n",
              "        0.64231532, 0.54745941, 0.66051285, 0.72068351, 0.60082152,\n",
              "        0.6599171 , 0.59502189, 0.55332641, 0.70875147, 0.69205234,\n",
              "        0.56361322, 0.6287725 , 0.62885346, 0.5616375 , 0.6899506 ,\n",
              "        0.57442173, 0.57014498, 0.62733665, 0.67027841, 0.60924347,\n",
              "        0.62839233, 0.6263151 , 0.62022419, 0.64112936, 0.64613202,\n",
              "        0.55977912, 0.59621642, 0.66021877, 0.65905428, 0.69232224,\n",
              "        0.62533939, 0.66368997, 0.55578492, 0.60092923, 0.54326028]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSnbti9ooIIs",
        "colab_type": "text"
      },
      "source": [
        "## Two hidden layer model in numpy:\n",
        "\n",
        "The difference from the one neuron model is simple:  we need only to change the number of output \"ny\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAY3o6zBnpA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2397
        },
        "outputId": "973bfdf8-e179-473b-efb1-fc3cdd308342"
      },
      "source": [
        "num_inputs = 3\n",
        "hidden_layer_1_outputs = 4\n",
        "hidden_layer_2_outputs = 3\n",
        "\n",
        "num_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmod function)\n",
        "\n",
        "X = np.random.rand(num_inputs,num_samples)\n",
        "\n",
        "# Generate a random weights vector for the first hidden layer\n",
        "\n",
        "W_h1 = np.random.rand(hidden_layer_1_outputs, num_inputs)\n",
        "\n",
        "W_h2 = np.random.rand(hidden_layer_2_outputs,hidden_layer_1_outputs)\n",
        "\n",
        "# Generate a rondom bias\n",
        "b_h1= np.zeros((hidden_layer_1_outputs, 1))\n",
        "\n",
        "b_h2= np.zeros((hidden_layer_2_outputs, 1))\n",
        "\n",
        "\n",
        "\n",
        "# calculate output of hidden layer 1\n",
        "\n",
        "h1 = f(np.dot(W_h1, X) + b_h1)\n",
        "\n",
        "\n",
        "h2 = f(np.dot(W_h2, h1) + b_h2)\n",
        "\n",
        "display(h1)\n",
        "display(h2)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.58766768, 0.55634598, 0.59965145, 0.61010294, 0.61997024,\n",
              "        0.64368948, 0.59666925, 0.54618992, 0.62909348, 0.55066033,\n",
              "        0.55780465, 0.5436638 , 0.53450326, 0.55139379, 0.56265462,\n",
              "        0.57856766, 0.57981059, 0.58277868, 0.56330796, 0.54530949,\n",
              "        0.58843763, 0.54174447, 0.5878357 , 0.53790817, 0.5838159 ,\n",
              "        0.62100309, 0.56650418, 0.61087469, 0.53635625, 0.55497256,\n",
              "        0.58961452, 0.54262859, 0.5847808 , 0.61704827, 0.56142206,\n",
              "        0.58712571, 0.59424062, 0.58403033, 0.59701509, 0.58250551,\n",
              "        0.56181739, 0.5245739 , 0.57988425, 0.63900796, 0.56931274,\n",
              "        0.58632844, 0.56341805, 0.56733156, 0.61690554, 0.62249177,\n",
              "        0.61873988, 0.6107249 , 0.55542641, 0.58737867, 0.54278985,\n",
              "        0.60839217, 0.60298466, 0.57118113, 0.56376897, 0.58728383,\n",
              "        0.63169066, 0.58671438, 0.61338106, 0.58709555, 0.55325975,\n",
              "        0.58681532, 0.59635076, 0.5666064 , 0.56620085, 0.58833909,\n",
              "        0.58109848, 0.52709539, 0.64209041, 0.57752262, 0.52586522,\n",
              "        0.5950154 , 0.56232716, 0.60528488, 0.62084725, 0.59311239,\n",
              "        0.57811511, 0.61908497, 0.54354268, 0.59107895, 0.58011187,\n",
              "        0.59270451, 0.63617275, 0.54130773, 0.53821359, 0.5854551 ,\n",
              "        0.54605875, 0.58673888, 0.55147096, 0.55173731, 0.61416892,\n",
              "        0.57840764, 0.59144721, 0.5736443 , 0.61631413, 0.54464446],\n",
              "       [0.69321731, 0.58909118, 0.65165621, 0.67834194, 0.73412   ,\n",
              "        0.80183263, 0.69173945, 0.55971338, 0.74970407, 0.63834769,\n",
              "        0.60088793, 0.70040335, 0.6596354 , 0.57047118, 0.64388111,\n",
              "        0.75127609, 0.65808601, 0.68654115, 0.55833101, 0.60019487,\n",
              "        0.71951167, 0.5637143 , 0.70578581, 0.66717793, 0.5872003 ,\n",
              "        0.79799209, 0.63366435, 0.64043064, 0.6120714 , 0.65027679,\n",
              "        0.65228208, 0.65217946, 0.66932571, 0.69963693, 0.57369246,\n",
              "        0.68857307, 0.73870366, 0.74179353, 0.7606178 , 0.61850155,\n",
              "        0.65055905, 0.58646968, 0.70726567, 0.73255278, 0.58778275,\n",
              "        0.73972502, 0.59242751, 0.72553206, 0.67903924, 0.7241634 ,\n",
              "        0.7141861 , 0.66617148, 0.58919801, 0.74849999, 0.65909357,\n",
              "        0.72633105, 0.66051632, 0.59499514, 0.66342152, 0.75674969,\n",
              "        0.77239281, 0.64315425, 0.74252492, 0.69786701, 0.64978939,\n",
              "        0.68957663, 0.68470676, 0.76275794, 0.67393765, 0.71699153,\n",
              "        0.7811092 , 0.56254787, 0.80115432, 0.69158582, 0.59334368,\n",
              "        0.70729863, 0.62126563, 0.74057294, 0.74327844, 0.61937023,\n",
              "        0.6014569 , 0.73772058, 0.68256609, 0.72402945, 0.77492808,\n",
              "        0.60966142, 0.82450879, 0.58948277, 0.60643341, 0.71480533,\n",
              "        0.64498615, 0.79844598, 0.72944394, 0.63808294, 0.67492468,\n",
              "        0.7220327 , 0.68935004, 0.74093745, 0.76019249, 0.63194586],\n",
              "       [0.68169919, 0.60306867, 0.67250055, 0.70695005, 0.73720971,\n",
              "        0.74786228, 0.59430844, 0.58740404, 0.67225044, 0.54102981,\n",
              "        0.60999851, 0.57752383, 0.58618639, 0.61685405, 0.67579462,\n",
              "        0.59617738, 0.62946275, 0.54751692, 0.63374498, 0.54872901,\n",
              "        0.63257692, 0.5689314 , 0.60061916, 0.58416488, 0.70700123,\n",
              "        0.67999587, 0.57836765, 0.68976847, 0.60129353, 0.50659211,\n",
              "        0.7088615 , 0.53114179, 0.67682005, 0.64348425, 0.60915001,\n",
              "        0.65534797, 0.69799365, 0.63089033, 0.63947184, 0.65650271,\n",
              "        0.64636876, 0.56300269, 0.64560011, 0.68767537, 0.63910184,\n",
              "        0.66967259, 0.66409916, 0.53459673, 0.6897703 , 0.7137388 ,\n",
              "        0.70836209, 0.66388904, 0.58718454, 0.56993852, 0.56597435,\n",
              "        0.72537579, 0.64301081, 0.66265743, 0.63852231, 0.61294071,\n",
              "        0.7516338 , 0.72479629, 0.74469461, 0.60147484, 0.62490672,\n",
              "        0.71818535, 0.72161176, 0.58838792, 0.56007659, 0.65820405,\n",
              "        0.57206088, 0.52459396, 0.74262936, 0.66120146, 0.56734788,\n",
              "        0.61061328, 0.6458929 , 0.64771148, 0.75538686, 0.67857032,\n",
              "        0.6705628 , 0.73788366, 0.61521305, 0.64162499, 0.60509973,\n",
              "        0.72036486, 0.69931162, 0.61520082, 0.57550791, 0.63458281,\n",
              "        0.61198351, 0.57957811, 0.58231632, 0.63044694, 0.68314416,\n",
              "        0.64096559, 0.67542415, 0.54089421, 0.72662217, 0.53154316],\n",
              "       [0.71413801, 0.62955092, 0.71875691, 0.74373019, 0.77391144,\n",
              "        0.81980155, 0.71627816, 0.6034499 , 0.78202778, 0.62687405,\n",
              "        0.63593231, 0.63909654, 0.61342441, 0.61843383, 0.66363058,\n",
              "        0.70857198, 0.6870901 , 0.68991085, 0.63595646, 0.60850405,\n",
              "        0.71682705, 0.59511009, 0.70849884, 0.62078507, 0.68413817,\n",
              "        0.78650589, 0.6544622 , 0.73343504, 0.60432043, 0.63288773,\n",
              "        0.70937533, 0.61713948, 0.70300697, 0.75113495, 0.63402671,\n",
              "        0.70895548, 0.73771841, 0.71710256, 0.7412122 , 0.68376622,\n",
              "        0.66044337, 0.57314176, 0.70284298, 0.79112538, 0.65374114,\n",
              "        0.72406753, 0.64921782, 0.67748535, 0.75085573, 0.77182126,\n",
              "        0.76402232, 0.73656695, 0.62615463, 0.71710023, 0.62372652,\n",
              "        0.75599175, 0.72222458, 0.66150446, 0.66601621, 0.72414247,\n",
              "        0.79926858, 0.70502147, 0.76887244, 0.70531508, 0.64452899,\n",
              "        0.71653782, 0.72873924, 0.6945353 , 0.66324698, 0.71890153,\n",
              "        0.71916051, 0.56548988, 0.81738534, 0.69688714, 0.57776645,\n",
              "        0.72003438, 0.6530206 , 0.74712126, 0.77947391, 0.70209435,\n",
              "        0.67460518, 0.77382937, 0.63807793, 0.72277384, 0.71930903,\n",
              "        0.70443835, 0.81341212, 0.60756256, 0.60236511, 0.71156003,\n",
              "        0.63041259, 0.73348417, 0.66075138, 0.63955187, 0.74550017,\n",
              "        0.70451852, 0.71757584, 0.69221386, 0.77510414, 0.61442354]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.88572412, 0.86114129, 0.88364126, 0.89070427, 0.89943698,\n",
              "        0.90947506, 0.88136779, 0.85353052, 0.89838148, 0.86012454,\n",
              "        0.86344777, 0.86837588, 0.86197501, 0.85879808, 0.87460003,\n",
              "        0.88352877, 0.8766655 , 0.87421326, 0.86206833, 0.85477717,\n",
              "        0.88502537, 0.851107  , 0.88126756, 0.86360043, 0.87619028,\n",
              "        0.9016087 , 0.86683213, 0.88618616, 0.85817435, 0.85982444,\n",
              "        0.88410805, 0.85872229, 0.88240979, 0.88980383, 0.86126002,\n",
              "        0.88329243, 0.89249888, 0.88616908, 0.8912419 , 0.87524859,\n",
              "        0.87283434, 0.84832267, 0.88286385, 0.89961527, 0.86735954,\n",
              "        0.88910236, 0.8683614 , 0.87373574, 0.89097343, 0.89757002,\n",
              "        0.89566969, 0.88678013, 0.85957519, 0.88332256, 0.86247659,\n",
              "        0.8958918 , 0.88313595, 0.87048701, 0.87407897, 0.8871032 ,\n",
              "        0.90547579, 0.88373662, 0.89944602, 0.88036134, 0.86892682,\n",
              "        0.88774445, 0.88950134, 0.88152301, 0.86975904, 0.8865372 ,\n",
              "        0.88545125, 0.84255802, 0.90888866, 0.8818842 , 0.84994823,\n",
              "        0.88370308, 0.8697687 , 0.89153579, 0.90148797, 0.87945851,\n",
              "        0.87349689, 0.89962793, 0.86932104, 0.88665576, 0.88688123,\n",
              "        0.88148181, 0.9074365 , 0.85808066, 0.8558204 , 0.88405631,\n",
              "        0.86548964, 0.88889951, 0.87394473, 0.86768304, 0.88960802,\n",
              "        0.88369092, 0.88571876, 0.877365  , 0.90036181, 0.85691079],\n",
              "       [0.85287123, 0.82657143, 0.84995405, 0.85828435, 0.86795068,\n",
              "        0.87752947, 0.84289181, 0.81914446, 0.86291796, 0.82143052,\n",
              "        0.82905664, 0.8317782 , 0.82702922, 0.82568845, 0.84329762,\n",
              "        0.84567626, 0.84146899, 0.83353134, 0.82926464, 0.81743263,\n",
              "        0.84909568, 0.81584434, 0.84353116, 0.82819227, 0.84594312,\n",
              "        0.86671153, 0.82952243, 0.85300028, 0.82467138, 0.81843887,\n",
              "        0.85300934, 0.8197848 , 0.84962073, 0.85332517, 0.82689294,\n",
              "        0.84898577, 0.85992627, 0.85020326, 0.85508688, 0.84185978,\n",
              "        0.83979973, 0.81374081, 0.8482198 , 0.86472317, 0.83409847,\n",
              "        0.85529379, 0.83692944, 0.83277578, 0.85727738, 0.86476123,\n",
              "        0.86276   , 0.85195163, 0.8240788 , 0.84345219, 0.82568654,\n",
              "        0.86427781, 0.84749013, 0.83841751, 0.84032336, 0.84982317,\n",
              "        0.87417696, 0.85375669, 0.86857311, 0.84276747, 0.83517595,\n",
              "        0.85699749, 0.85850121, 0.84370103, 0.83092596, 0.85213092,\n",
              "        0.8458124 , 0.80564473, 0.87671724, 0.84840198, 0.81542824,\n",
              "        0.84621471, 0.83699776, 0.855615  , 0.87088503, 0.84673024,\n",
              "        0.84137171, 0.86819492, 0.83524629, 0.85110454, 0.84934266,\n",
              "        0.85122697, 0.87307134, 0.82537306, 0.82064477, 0.84842388,\n",
              "        0.83150162, 0.84938738, 0.83686322, 0.83450473, 0.85568036,\n",
              "        0.84873699, 0.85234572, 0.83636766, 0.86832844, 0.81809746],\n",
              "       [0.89407987, 0.8706718 , 0.8928277 , 0.89970197, 0.90763041,\n",
              "        0.91658969, 0.88886171, 0.86346988, 0.90573574, 0.86762183,\n",
              "        0.87280217, 0.87495113, 0.86943488, 0.86890889, 0.88379998,\n",
              "        0.88971013, 0.88514268, 0.88112479, 0.87276741, 0.86319479,\n",
              "        0.89232972, 0.8606473 , 0.88847909, 0.87090769, 0.88709728,\n",
              "        0.90812654, 0.87511404, 0.89581801, 0.86694821, 0.86661599,\n",
              "        0.89360349, 0.86566199, 0.8911968 , 0.89779059, 0.87127488,\n",
              "        0.89146282, 0.90014796, 0.89298448, 0.89788989, 0.88491271,\n",
              "        0.88154113, 0.85701734, 0.89049701, 0.90746328, 0.87745703,\n",
              "        0.89639722, 0.87860403, 0.87950919, 0.8998189 , 0.90575688,\n",
              "        0.90399058, 0.89562101, 0.86888852, 0.88932635, 0.86976717,\n",
              "        0.90409721, 0.89184871, 0.8806959 , 0.88242736, 0.89345563,\n",
              "        0.9131101 , 0.89357406, 0.90752722, 0.88773744, 0.87731842,\n",
              "        0.89653762, 0.89846231, 0.887267  , 0.87692175, 0.89416979,\n",
              "        0.89080706, 0.85128437, 0.91596974, 0.88999534, 0.8585585 ,\n",
              "        0.8910544 , 0.87912797, 0.89870306, 0.90966351, 0.88938189,\n",
              "        0.8836778 , 0.90775663, 0.8767786 , 0.8939886 , 0.89273817,\n",
              "        0.8920295 , 0.91374135, 0.86762532, 0.86438846, 0.89145502,\n",
              "        0.87375416, 0.89409226, 0.88008592, 0.87639162, 0.89846662,\n",
              "        0.8909642 , 0.89410877, 0.88299734, 0.90796432, 0.86433755]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11fqb_bQvIEi",
        "colab_type": "text"
      },
      "source": [
        "## Gradient descent in Numpy:\n",
        "Let us now start training a neural network\n",
        "We start by implementing a simple gradient descent for linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzBJxwb7FFZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaQyLoxk2FyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqCCVlmFIZl",
        "colab_type": "text"
      },
      "source": [
        "##Assignment 1\n",
        "### Backpropagation in Numpy:\n"
      ]
    }
  ]
}