{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Machine Translation with Seq2Seq model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadhajmosa/Machine-learning-labs/blob/daurmax/Copy_of_Machine_Translation_with_Seq2Seq_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOAwWeT0H1FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq-55gqyH29A",
        "colab_type": "text"
      },
      "source": [
        "# Machine Translation with Seq2Seq model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5aSnf0IC9y",
        "colab_type": "text"
      },
      "source": [
        "# sequence to sequence model\n",
        "\n",
        "\n",
        "![alt text](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2019/01/enc_dec_2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUuPZc7FICG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RSsaDqsIZg0",
        "colab_type": "text"
      },
      "source": [
        "# Read the Data into our IDE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psJK4BOqIW8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "        # open the file\n",
        "        file = open(filename, mode='rt', encoding='utf-8')\n",
        "        \n",
        "        # read all text\n",
        "        text = file.read()\n",
        "        file.close()\n",
        "        return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzrVXpb3IgtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a text into sentences\n",
        "def to_lines(text):\n",
        "      sents = text.strip().split('\\n')\n",
        "      sents = [i.split('\\t') for i in sents]\n",
        "      return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EovwSSgIIk9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_text(\"deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)\n",
        "#mport urllib.request as urllib2\n",
        "\n",
        "#data = urllib2.urlopen('https://raw.githubusercontent.com/Apress/applied-natural-language-processing-w-python/master/data_etc/deu.txt')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znjHR9p0JNz5",
        "colab_type": "text"
      },
      "source": [
        "deu_eng = deu_eng[:50000,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MMdTMhlJNAF",
        "colab_type": "code",
        "outputId": "d11380c5-df2f-4916-c265-4ad2e542157e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "display(deu_eng[100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array(['Go away!', 'Mach ’ne Fliege!'], dtype='<U302')"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD33znyLJp3t",
        "colab_type": "code",
        "outputId": "ece91aeb-b277-49d1-d6fd-84427a2b4d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "deu_eng = np.reshape(deu_eng,(-1,2))\n",
        "\n",
        "deu_eng[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Hi.', 'Hallo!'], dtype='<U302')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOtrMyWOJmJl",
        "colab_type": "code",
        "outputId": "75fb4c5c-45a7-46d2-e538-910dec595e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Remove punctuation\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
        "\n",
        "deu_eng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Hi', 'Hallo'],\n",
              "       ['Hi', 'Grüß Gott'],\n",
              "       ['Run', 'Lauf'],\n",
              "       ...,\n",
              "       ['At a moment when our economy is growing our businesses are creating jobs at the fastest pace since the 1990s and wages are starting to rise again we have to make some choices about the kind of country we want to be',\n",
              "        'In einem Moment in dem unsere Wirtschaft wächst unsere Betriebe so schnell neue Arbeitsplätze schaffen wie zuletzt in den 90ern und die Gehälter steigen müssen wir Entscheidungen treffen und uns überlegen was für ein Land wir sein wollen'],\n",
              "       ['If someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker In other words you dont really sound like a native speaker',\n",
              "        'Wenn jemand der deine Herkunft nicht kennt sagt dass du wie ein Muttersprachler sprichst bedeutet das dass man wahrscheinlich etwas an deiner Sprechweise bemerkt hat das erkennen ließ dass du kein Muttersprachler bist Mit anderen Worten du hörst dich nicht wirklich wie ein Muttersprachler an'],\n",
              "       ['If someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker In other words you dont really sound like a native speaker',\n",
              "        'Wenn jemand Fremdes dir sagt dass du dich wie ein Muttersprachler anhörst bedeutet das wahrscheinlich Er hat etwas an deinem Sprechen bemerkt dass dich als NichtMuttersprachler verraten hat Mit anderen Worten Du hörst dich nicht wirklich wie ein Muttersprachler an']],\n",
              "      dtype='<U302')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vks2ms25OArm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# empty lists\n",
        "eng_l = []\n",
        "deu_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in deu_eng[:,0]:\n",
        "      eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "      deu_l.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU4MmkyzONVU",
        "colab_type": "code",
        "outputId": "dd60684d-f5de-43d1-cfae-956ad8f0a6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZ90ZFVOQG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "      tokenizer = Tokenizer()\n",
        "      tokenizer.fit_on_texts(lines)\n",
        "      return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyz7RNDHOSze",
        "colab_type": "code",
        "outputId": "b9f7bdf1-57a4-4e34-9100-89879e02a4e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 15610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COPesm56Oge4",
        "colab_type": "code",
        "outputId": "2b426986-391f-4c68-fd60-291f187f252d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# prepare Deutch tokenizer\n",
        "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "deu_length = 8\n",
        "print('Deutsch Vocabulary Size: %d' % deu_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deutsch Vocabulary Size: 33312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atwmdWuVOqks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "         # integer encode sequences\n",
        "         seq = tokenizer.texts_to_sequences(lines)\n",
        "         # pad sequences with 0 values\n",
        "         # padding -> [0,0,0,0,0,......,1,2]\n",
        "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "         return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xW66yhpOrt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into train and test set\n",
        "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtRnbTHXO2wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSdhJQRzV6T0",
        "colab_type": "code",
        "outputId": "c825d0a8-2e08-41a8-8a1e-6ef0a58a886c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trainX[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,  310,   25, 2344,    3, 3858,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okENg3RqO9xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, RepeatVector, Dense\n",
        "\n",
        "# build NMT model\n",
        "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
        "      model = Sequential()\n",
        "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "      model.add(LSTM(units))\n",
        "      model.add(RepeatVector(out_timesteps))\n",
        "      model.add(LSTM(units, return_sequences=True))\n",
        "      model.add(Dense(out_vocab, activation='softmax'))\n",
        "      return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMzBz4CaPw8P",
        "colab_type": "code",
        "outputId": "44143ac7-b05d-4f08-ad33-a3fc127037db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "# model compilation\n",
        "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKcsY1jRP0Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WboEG9PmP5L1",
        "colab_type": "code",
        "outputId": "cc2232a2-4ffd-4523-dbfc-fdfc25d0c7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "filename = 'model.h1.24_jan_19'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
        "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 108680 samples, validate on 27170 samples\n",
            "Epoch 1/30\n",
            "  5120/108680 [>.............................] - ETA: 29:31 - loss: 6.9788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-212595acfee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMUasvLrP9Bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLGYX_UgQH0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('model.h1.24_jan_19')\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYWfGSqoQMLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "          if index == n:\n",
        "              return word\n",
        "      return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCMTd0NoQMji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_text = []\n",
        "for i in preds:\n",
        "       temp = []\n",
        "       for j in range(len(i)):\n",
        "            t = get_word(i[j], eng_tokenizer)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                     temp.append('')\n",
        "                else:\n",
        "                     temp.append(t)\n",
        "            else:\n",
        "                   if(t == None):\n",
        "                          temp.append('')\n",
        "                   else:\n",
        "                          temp.append(t) \n",
        "\n",
        "       preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gySU0ko6QP9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\n",
        "# print 15 rows randomly\n",
        "pred_df.sample(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfX7W8a1QF8v",
        "colab_type": "text"
      },
      "source": [
        "model = load_model('model.h1.24_jan_19')\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6Zu0ECdIed4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU6NBCq-H2Ln",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}